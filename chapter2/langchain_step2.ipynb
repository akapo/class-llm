{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMUEV1ewxsMZOON29yWCuBk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akapo/class-llm/blob/main/chapter2/langchain_step2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 실습 환경 설정"
      ],
      "metadata": {
        "id": "rrczJuswLJyB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**필요한 패키지 설치**"
      ],
      "metadata": {
        "id": "JBYrFgQ5LONB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU openai\n",
        "!pip install -qU langchain langchain-openai langchain-community langchainhub langchain-experimental\n",
        "!pip install -qU huggingface_hub langchain-google-genai langchain-anthropic\n",
        "!pip install -Uq sentence-transformers\n",
        "!pip install -qU python-dotenv\n",
        "!pip install -qU pymupdf pypdf\n",
        "!pip install -qU numexpr\n",
        "!pip install -qU faiss-cpu\n",
        "!pip install -qU chromadb\n",
        "!pip install -qU bs4\n",
        "!pip install -qU google-search-results duckduckgo-search wikipedia\n",
        "#!pip install -qU streamlit\n",
        "#!pip install -qU streamlit-chat"
      ],
      "metadata": {
        "id": "S4gEcjJcl28t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aeb75a7-807a-4433-8040-55751fdeee7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/337.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.0/337.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.3/990.3 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.3/377.3 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.2/417.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.5/865.5 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.3/584.3 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install python-dotenv\n",
        "import dotenv\n",
        "dotenv.load_dotenv()\n",
        "\n",
        "import os\n",
        "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
        "ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')\n",
        "\n",
        "# 주의: API_KEY를 깃허브에 노출하면 LLM 업체는 해당키를 즉시 삭제함.\n",
        "print(\"GOOGLE_API_KEY: \" + GOOGLE_API_KEY[:20])\n",
        "print(\"OPENAI_API_KEY: \" + OPENAI_API_KEY[:20])\n",
        "print(\"ANTHROPIC_API_KEY: \" + ANTHROPIC_API_KEY[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wxb0Alj2mDMZ",
        "outputId": "d61ef358-add3-477b-bd34-acaecc444990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GOOGLE_API_KEY: AIzaSyCCtFS9bml5jdGI\n",
            "OPENAI_API_KEY: sk-proj-FEDi6Ge6iQyR\n",
            "ANTHROPIC_API_KEY: sk-ant-api03-YcGqyQQ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **[LangChain]　3. Memory**"
      ],
      "metadata": {
        "id": "O3nQ0rQ-mSSm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**기억력을 구현하지 않았을 때 예시**"
      ],
      "metadata": {
        "id": "I52VyhG3-0Sw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM은 붕어인가? 왜 아무것도 기억을 못하는가?\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "while True:\n",
        "    user_message = input(\"You: \")\n",
        "    message = HumanMessage(content=user_message)\n",
        "\n",
        "    if user_message == \"끝\":\n",
        "        print(\"(대화 종료)\")\n",
        "        break\n",
        "\n",
        "    ai_message = llm.invoke([message])\n",
        "    print(f\"AI: {ai_message.content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9TF1-A_-ztJ",
        "outputId": "33ecb4a3-6997-4df4-9008-a9c72941a94e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: 안녕? 나는 정진이야.\n",
            "AI: 안녕하세요, 정진님! 어떻게 도와드릴까요?\n",
            "You: 내 이름 기억해?\n",
            "AI: 죄송하지만, 저는 개인적인 정보를 기억할 수 없습니다. 하지만 도움이 필요하시면 언제든지 말씀해 주세요!\n",
            "You: 끝\n",
            "(대화 종료)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**기억력 직접 구현**"
      ],
      "metadata": {
        "id": "fuUuq4UhB9Mx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 메시지 리스트로 기억력 직접구현\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import HumanMessage, AIMessage\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "message = []\n",
        "while True:\n",
        "    user_message = input(\"You: \")\n",
        "    message.append(HumanMessage(content=user_message))\n",
        "\n",
        "    if user_message == \"끝\":\n",
        "        print(\"(대화 종료)\")\n",
        "        break\n",
        "\n",
        "    response = llm.invoke(message).content\n",
        "    print(f\"AI: {response}\")\n",
        "    ai_message = AIMessage(content=response)\n",
        "    message.append(ai_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNkVnCWc_-aT",
        "outputId": "bcff1350-9fa8-4550-8824-960e5758958d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: 안녕? 나는 정진이야.\n",
            "AI: 안녕하세요, 정진님! 어떻게 도와드릴까요?\n",
            "You: 내 이름 기억해?\n",
            "AI: 네, 정진님! 당신의 이름을 기억하고 있습니다. 어떻게 도와드릴까요?\n",
            "You: 끝\n",
            "(대화 종료)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ConversationBufferMemory 예제1**"
      ],
      "metadata": {
        "id": "XMxy75d6NOZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ConversationBufferMemory를 이용한 기억력 구현\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=ConversationBufferMemory(),\n",
        ")\n",
        "\n",
        "while True:\n",
        "    user_message = input(\"You: \")\n",
        "\n",
        "    if user_message == \"끝\":\n",
        "        print(\"(대화 종료)\")\n",
        "        break\n",
        "\n",
        "    ai_message = conversation.invoke(input=user_message)[\"response\"]\n",
        "    print(f\"AI: {ai_message}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdO1Lpo_mQgY",
        "outputId": "105c441b-7e6d-4c75-f477-c45b67ec174c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: 안녕? 나는 정진이야.\n",
            "AI: 안녕, 정진! 만나서 반가워! 나는 AI야. 오늘 기분이 어때? 혹시 특별한 계획이 있니?\n",
            "You: 아직 계획은 없어... 너 내 이름 기억해?\n",
            "AI: 네, 정진! 너의 이름을 기억하고 있어. 앞으로도 계속 기억할게. 혹시 어떤 취미나 관심사가 있어? 함께 이야기해보면 좋을 것 같아!\n",
            "You: 끝\n",
            "(대화 종료)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ConversationBufferMemory 예제2**"
      ],
      "metadata": {
        "id": "Ck5fZkS5NSfU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN6HP_PjlnN1",
        "outputId": "cad85ab2-160c-4d6c-fb8a-02adf8b09923"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: 너는 지금 사람과 '1 to 50 게임'을 하는 AI야.\n",
            "Human: 내가 생각한 숫자가 무엇인지 맞춰봐\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "AI: 좋아요! 1부터 50 사이의 숫자를 맞춰볼게요. 제 첫 번째 추측은 25입니다. 맞혔나요?\n",
            "You: 보다커\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: 너는 지금 사람과 '1 to 50 게임'을 하는 AI야.\n",
            "Human: 내가 생각한 숫자가 무엇인지 맞춰봐\n",
            "AI: 좋아요! 1부터 50 사이의 숫자를 맞춰볼게요. 제 첫 번째 추측은 25입니다. 맞혔나요?\n",
            "Human: 보다커\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "AI: 알겠어요! 그럼 제 다음 추측은 38입니다. 이 숫자는 어떤가요?\n",
            "You: 보다 작아\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: 너는 지금 사람과 '1 to 50 게임'을 하는 AI야.\n",
            "Human: 내가 생각한 숫자가 무엇인지 맞춰봐\n",
            "AI: 좋아요! 1부터 50 사이의 숫자를 맞춰볼게요. 제 첫 번째 추측은 25입니다. 맞혔나요?\n",
            "Human: 보다커\n",
            "AI: 알겠어요! 그럼 제 다음 추측은 38입니다. 이 숫자는 어떤가요?\n",
            "Human: 보다 작아\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "AI: 좋아요! 그럼 32는 어떤가요?\n",
            "You: 정답이야\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: 너는 지금 사람과 '1 to 50 게임'을 하는 AI야.\n",
            "Human: 내가 생각한 숫자가 무엇인지 맞춰봐\n",
            "AI: 좋아요! 1부터 50 사이의 숫자를 맞춰볼게요. 제 첫 번째 추측은 25입니다. 맞혔나요?\n",
            "Human: 보다커\n",
            "AI: 알겠어요! 그럼 제 다음 추측은 38입니다. 이 숫자는 어떤가요?\n",
            "Human: 보다 작아\n",
            "AI: 좋아요! 그럼 32는 어떤가요?\n",
            "Human: 정답이야\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "AI: 와! 32를 맞췄군요! 정말 기뻐요. 다시 한 번 할까요, 아니면 다른 게임을 해볼까요?\n",
            "You: 끝\n",
            "(대화 종료)\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "# 1) 시스템 설정: 역할부여 정의\n",
        "system_template = SystemMessagePromptTemplate.from_template(\"너는 지금 사람과 '1 to 50 게임'을 하는 AI야.\")\n",
        "\n",
        "# 2) ChatPromptTemplate 템플릿 정의\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    system_template,                                       # 역할부여\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),     # 메모리 저장소 설정. ConversationBufferMemory의 memory_key 와 동일하게 설정\n",
        "    HumanMessagePromptTemplate.from_template(\"{input}\"),   # 사용자 메시지 injection\n",
        "])\n",
        "\n",
        "# 3) 메모리 정의\n",
        "# `return_messages=True`를 사용해야 MessagesPlaceholder에 주입됨\n",
        "# `chat_history`가 MessagesPlaceholder 이름과 일치해야함\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\",\n",
        "                                  ai_prefix=\"AI\",\n",
        "                                  human_prefix=\"Human\",\n",
        "                                  return_messages=True)\n",
        "\n",
        "# 4) LLM 모델 정의\n",
        "llm = ChatOpenAI(model_name='gpt-4o-mini')\n",
        "\n",
        "# 5) LLMChain 정의\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,       # LLM\n",
        "    prompt=prompt, # Prompt\n",
        "    memory=memory, # 메모리\n",
        "    verbose=True,  # True 로 설정시 로그 출력\n",
        ")\n",
        "\n",
        "user_message = \"내가 생각한 숫자가 무엇인지 맞춰봐\"\n",
        "while True:\n",
        "    ai_message = conversation.invoke(input=user_message)[\"response\"]\n",
        "    print(f\"AI: {ai_message}\")\n",
        "\n",
        "    user_message = input(\"You: \")\n",
        "    if user_message == \"끝\":\n",
        "        print(\"(대화 종료)\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **[LangChain]　4. Retrival**"
      ],
      "metadata": {
        "id": "TsPO2QWuOaSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1) Loader & Splitter**"
      ],
      "metadata": {
        "id": "mlgbllkYfZFY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CharacterTextSplitter**"
      ],
      "metadata": {
        "id": "MNjD-wh2KxKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TextLoader & RecursiveCharacterTextSplitter\n",
        "# Playground: https://chunkviz.up.railway.app/\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "splitter = CharacterTextSplitter(\n",
        "    separator = \"\",   # <= 실험\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=30,\n",
        "    length_function=len,\n",
        ")\n",
        "document = TextLoader(\"appendix-keywords.txt\").load()\n",
        "split_docs = splitter.split_documents(document)\n",
        "\n",
        "# 총 분할된 도큐먼트 수\n",
        "print(f'총 분할된 도큐먼트 수: {len(split_docs)}')\n",
        "print(split_docs[0].page_content)\n",
        "print('======')\n",
        "print(split_docs[1].page_content)\n",
        "print('======')\n",
        "print(split_docs[2].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnlr_Du1R2zQ",
        "outputId": "31257efd-0039-4ca3-f599-cfe42f982843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 분할된 도큐먼트 수: 22\n",
            "Semantic Search\n",
            "\n",
            "정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
            "예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n",
            "연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
            "\n",
            "Embedding\n",
            "\n",
            "정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\n",
            "예시: \"사과\"라는 단\n",
            "======\n",
            "해하고 처리할 수 있게 합니다.\n",
            "예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\n",
            "연관키워드: 자연어 처리, 벡터화, 딥러닝\n",
            "\n",
            "Token\n",
            "\n",
            "정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\n",
            "예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\n",
            "연관키워드: 토큰화, 자연어 처리, 구문 분석\n",
            "\n",
            "Tokenizer\n",
            "\n",
            "정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에\n",
            "======\n",
            "터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.\n",
            "예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\n",
            "연관키워드: 토큰화, 자연어 처리, 구문 분석\n",
            "\n",
            "VectorStore\n",
            "\n",
            "정의: 벡터스토어는 벡터 형식으로 변환된 데이터를 저장하는 시스템입니다. 이는 검색, 분류 및 기타 데이터 분석 작업에 사용됩니다.\n",
            "예시: 단어 임베딩 벡터들을 데이터베이스에 저장하여 빠르게 접근할 수 있습니다.\n",
            "연관키워드: 임베딩, 데\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RecursiveCharacterTextSplitter**"
      ],
      "metadata": {
        "id": "5fj9eNpVKzF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TextLoader & RecursiveCharacterTextSplitter\n",
        "# Playground: https://langchain-text-splitter.streamlit.app/\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, Language\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=30,\n",
        "    length_function=len,\n",
        ")\n",
        "document = TextLoader(\"appendix-keywords.txt\").load()\n",
        "split_docs = splitter.split_documents(document)\n",
        "\n",
        "# 총 분할된 도큐먼트 수\n",
        "print(f'총 분할된 도큐먼트 수: {len(split_docs)}')\n",
        "print(split_docs[0].page_content)\n",
        "print('======')\n",
        "print(split_docs[1].page_content)\n",
        "print('======')\n",
        "print(split_docs[2].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KBBK_zSOYwN",
        "outputId": "50a3e3da-55c6-41d7-eb2e-8ce916318ac8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 분할된 도큐먼트 수: 30\n",
            "Semantic Search\n",
            "\n",
            "정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
            "예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n",
            "연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
            "\n",
            "Embedding\n",
            "======\n",
            "Embedding\n",
            "\n",
            "정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\n",
            "예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\n",
            "연관키워드: 자연어 처리, 벡터화, 딥러닝\n",
            "\n",
            "Token\n",
            "======\n",
            "Token\n",
            "\n",
            "정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\n",
            "예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\n",
            "연관키워드: 토큰화, 자연어 처리, 구문 분석\n",
            "\n",
            "Tokenizer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PyPDFLoader**"
      ],
      "metadata": {
        "id": "dl8u9L6sLl7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PDFLoader\n",
        "#!pip install -q pypdf\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"소나기 - 황순원.pdf\")\n",
        "docs = loader.load()\n",
        "\n",
        "print(f'총 분할된 도큐먼트 수: {len(docs)}')\n",
        "docs[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "UY1q-74rRP6g",
        "outputId": "50733054-faeb-4c27-c99f-d2dfabafd7cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 분할된 도큐먼트 수: 7\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'- 1 -소나기\\n황순원\\n소년은 개울가에서 소녀를 보자 곧 윤 초시네 증손녀 (曾孫女 )딸이라는 걸 알 수 있었다 . \\n소녀는 개울에다 손을 잠그고 물장난을 하고 있는 것이다 . 서울서는 이런 개울물을 보지 \\n못하기나 한 듯이.\\n벌써 며칠째 소녀는 , 학교에서 돌아오는 길에 물장난이었다 . 그런데 , 어제까지 개울 기슭에\\n서 하더니 , 오늘은 징검다리 한가운데 앉아서 하고 있다.\\n소년은 개울둑에 앉아 버렸다 . 소녀가 비키기를 기다리자는 것이다 .\\n요행 지나가는 사람이 있어, 소녀가 길을 비켜 주었다 .\\n다음 날은 좀 늦게 개울가로 나왔다 .\\n이 날은 소녀가 징검다리 한가운데 앉아 세수를 하고 있었다 . 분홍 스웨터 소매를 걷어올\\n린 목덜미가 마냥 희었다 .\\n한참 세수를 하고 나더니 , 이번에는 물 속을 빤히 들여다 본다. 얼굴이라도 비추어 보는 \\n것이리라 . 갑자기 물을 움켜 낸다. 고기 새끼라도 지나가는 듯.\\n소녀는 소년이 개울둑에 앉아 있는 걸 아는지 모르는지 그냥 날쌔게 물만 움켜 낸다. 그러\\n나, 번번이 허탕이다 . 그대로 재미있는 양, 자꾸 물만 움킨다 . 어제처럼 개울을 건너는 사\\n람이 있어야 길을 비킬 모양이다 .\\n그러다가 소녀가 물 속에서 무엇을 하나 집어 낸다. 하얀 조약돌이었다 . 그리고는 벌떡 일\\n어나 팔짝팔짝 징검다리를 뛰어 건너간다 .\\n다 건너가더니만 홱 이리로 돌아서며 ,\\n“이 바보.”\\n조약돌이 날아왔다 .\\n소년은 저도 모르게 벌떡 일어섰다 .\\n단발 머리를 나풀거리며 소녀가 막 달린다 . 갈밭 사잇길로 들어섰다 . 뒤에는 청량한 가을 \\n햇살 아래 빛나는 갈꽃뿐 .\\n이제 저쯤 갈밭머리로 소녀가 나타나리라 . 꽤 오랜 시간이 지났다고 생각됐다 . 그런데도 \\n소녀는 나타나지 않는다 . 발돋움을 했다. 그러고도 상당한 시간이 지났다고 생각됐다 .\\n저 쪽 갈밭머리에 갈꽃이 한 옴큼 움직였다 . 소녀가 갈꽃을 안고 있었다 . 그리고 , 이제는 \\n천천한 걸음이었다 . 유난히 맑은 가을 햇살이 소녀의 갈꽃머리에서 반짝거렸다 . 소녀 아닌 \\n갈꽃이 들길을 걸어가는 것만 같았다 .\\n소년은 이 갈꽃이 아주 뵈지 않게 되기까지 그대로 서 있었다 . 문득, 소녀가 던지 조약돌\\n을 내려다보았다 . 물기가 걷혀 있었다 . 소년은 조약돌을 집어 주머니에 넣었다 .\\n다음 날부터 좀더 늦게 개울가로 나왔다 . 소녀의 그림자가 뵈지 않았다 . 다행이었다 .\\n그러나 , 이상한 일이었다 . 소녀의 그림자가 뵈지 않는 날이 계속될수록 소년의 가슴 한 구\\n석에는 어딘가 허전함이 자리 잡는 것이었다 . 주머니 속 조약돌을 주무르는 버릇이 생겼\\n다.\\n그러한 어떤 날, 소년은 전에 소녀가 앉아 물장난을 하던 징검다리 한가운데에 앉아 보았\\n다. 물 속에 손을 잠갔다 . 세수를 하였다 . 물 속을 들여다보았다 . 검게 탄 얼굴이 그대로 \\n비치었다 . 싫었다 .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PyMuPDFLoader**"
      ],
      "metadata": {
        "id": "kmkXJgsbMWUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyMuPDFLoader\n",
        "#!pip install -q pymypdf\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "loader = PyMuPDFLoader(\"소나기 - 황순원.pdf\")\n",
        "docs = loader.load()\n",
        "\n",
        "print(f'총 분할된 도큐먼트 수: {len(docs)}')\n",
        "docs[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "7lrXr-mBL6eL",
        "outputId": "cb08ea87-fd62-4fcf-81d1-adac7efdba76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 분할된 도큐먼트 수: 7\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'- 1 -\\n소나기\\n황순원\\n소년은 개울가에서 소녀를 보자 곧 윤 초시네 증손녀(曾孫女)딸이라는 걸 알 수 있었다. \\n소녀는 개울에다 손을 잠그고 물장난을 하고 있는 것이다. 서울서는 이런 개울물을 보지 \\n못하기나 한 듯이.\\n벌써 며칠째 소녀는, 학교에서 돌아오는 길에 물장난이었다. 그런데, 어제까지 개울 기슭에\\n서 하더니, 오늘은 징검다리 한가운데 앉아서 하고 있다.\\n소년은 개울둑에 앉아 버렸다. 소녀가 비키기를 기다리자는 것이다.\\n요행 지나가는 사람이 있어, 소녀가 길을 비켜 주었다.\\n다음 날은 좀 늦게 개울가로 나왔다.\\n이 날은 소녀가 징검다리 한가운데 앉아 세수를 하고 있었다. 분홍 스웨터 소매를 걷어올\\n린 목덜미가 마냥 희었다.\\n한참 세수를 하고 나더니, 이번에는 물 속을 빤히 들여다 본다. 얼굴이라도 비추어 보는 \\n것이리라. 갑자기 물을 움켜 낸다. 고기 새끼라도 지나가는 듯.\\n소녀는 소년이 개울둑에 앉아 있는 걸 아는지 모르는지 그냥 날쌔게 물만 움켜 낸다. 그러\\n나, 번번이 허탕이다. 그대로 재미있는 양, 자꾸 물만 움킨다. 어제처럼 개울을 건너는 사\\n람이 있어야 길을 비킬 모양이다.\\n그러다가 소녀가 물 속에서 무엇을 하나 집어 낸다. 하얀 조약돌이었다. 그리고는 벌떡 일\\n어나 팔짝팔짝 징검다리를 뛰어 건너간다.\\n다 건너가더니만 홱 이리로 돌아서며,\\n“이 바보.”\\n조약돌이 날아왔다.\\n소년은 저도 모르게 벌떡 일어섰다.\\n단발 머리를 나풀거리며 소녀가 막 달린다. 갈밭 사잇길로 들어섰다. 뒤에는 청량한 가을 \\n햇살 아래 빛나는 갈꽃뿐.\\n이제 저쯤 갈밭머리로 소녀가 나타나리라. 꽤 오랜 시간이 지났다고 생각됐다. 그런데도 \\n소녀는 나타나지 않는다. 발돋움을 했다. 그러고도 상당한 시간이 지났다고 생각됐다.\\n저 쪽 갈밭머리에 갈꽃이 한 옴큼 움직였다. 소녀가 갈꽃을 안고 있었다. 그리고, 이제는 \\n천천한 걸음이었다. 유난히 맑은 가을 햇살이 소녀의 갈꽃머리에서 반짝거렸다. 소녀 아닌 \\n갈꽃이 들길을 걸어가는 것만 같았다.\\n소년은 이 갈꽃이 아주 뵈지 않게 되기까지 그대로 서 있었다. 문득, 소녀가 던지 조약돌\\n을 내려다보았다. 물기가 걷혀 있었다. 소년은 조약돌을 집어 주머니에 넣었다.\\n다음 날부터 좀더 늦게 개울가로 나왔다. 소녀의 그림자가 뵈지 않았다. 다행이었다.\\n그러나, 이상한 일이었다. 소녀의 그림자가 뵈지 않는 날이 계속될수록 소년의 가슴 한 구\\n석에는 어딘가 허전함이 자리 잡는 것이었다. 주머니 속 조약돌을 주무르는 버릇이 생겼\\n다.\\n그러한 어떤 날, 소년은 전에 소녀가 앉아 물장난을 하던 징검다리 한가운데에 앉아 보았\\n다. 물 속에 손을 잠갔다. 세수를 하였다. 물 속을 들여다보았다. 검게 탄 얼굴이 그대로 \\n비치었다. 싫었다.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2) Embeddings**"
      ],
      "metadata": {
        "id": "Y2wcgZGCfffx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAI Embedding 모델\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "text=\"만나서 반가워요.\"\n",
        "embeded = embeddings.embed_query(text)\n",
        "print(str(len(embeded))+'차원')\n",
        "print(embeded[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHZm0AtmSvj0",
        "outputId": "247b35f7-f757-4dac-f65c-f775f9d3f840"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1536차원\n",
            "[-0.019351087510585785, -0.03914021700620651, 0.00637413514778018, -0.01435227133333683, -0.009520941413939]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 코사인 유사도 계산\n",
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "# 벡터 A와 벡터 B의 코사인 유사도 계산\n",
        "def cos_sim(A, B):\n",
        "  return dot(A, B)/(norm(A)*norm(B))"
      ],
      "metadata": {
        "id": "icALCRr5wLdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAI Embeddings 모델 테스트\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "embeddings_model = OpenAIEmbeddings()\n",
        "\n",
        "embeddings = embeddings_model.embed_documents(\n",
        "    [\n",
        "        '안녕하세요!',\n",
        "        '어! 오랜만이에요',\n",
        "        '이름이 어떻게 되세요?',\n",
        "        '날씨가 추워요',\n",
        "        'Hello LLM!'\n",
        "    ]\n",
        ")\n",
        "\n",
        "embedded_query = embeddings_model.embed_query('첫인사를 하고 이름을 물어봤나요?')\n",
        "print(str(len(embedded_query))+'차원')\n",
        "\n",
        "for embedding in embeddings:\n",
        "    print(cos_sim(embedding, embedded_query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogeSpZJxr5Kw",
        "outputId": "80c64099-5b74-4da5-b2ec-be3a9585621a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1536차원\n",
            "0.8348159356519259\n",
            "0.8153598883956\n",
            "0.8843727343154585\n",
            "0.7898927808309193\n",
            "0.7469070089071632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HuggingFace의 jhgan/ko-sroberta-nli 모델 테스트\n",
        "#!pip install -Uq sentence-transformers\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "embeddings_model = HuggingFaceEmbeddings(\n",
        "    model_name='jhgan/ko-sroberta-nli',\n",
        "    model_kwargs={'device':'cpu'},\n",
        "    encode_kwargs={'normalize_embeddings':True},\n",
        ")\n",
        "\n",
        "embeddings = embeddings_model.embed_documents(\n",
        "    [\n",
        "        '안녕하세요!',\n",
        "        '어! 오랜만이에요',\n",
        "        '이름이 어떻게 되세요?',\n",
        "        '날씨가 추워요',\n",
        "        'Hello LLM!'\n",
        "    ]\n",
        ")\n",
        "\n",
        "embedded_query = embeddings_model.embed_query('첫인사를 하고 이름을 물어봤나요?')\n",
        "print(str(len(embedded_query))+'차원')\n",
        "\n",
        "for embedding in embeddings:\n",
        "    print(cos_sim(embedding, embedded_query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yntw6sK_WdV1",
        "outputId": "084c52b1-9986-48d6-e2da-f0478aab720e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "768차원\n",
            "0.5899016189601531\n",
            "0.4182631225980652\n",
            "0.7240604521610333\n",
            "0.05702662997392148\n",
            "0.4316418328113528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GoogleGenerativeAIEmbeddings 모델 테스트\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "embeddings_model = GoogleGenerativeAIEmbeddings(model='models/embedding-001')\n",
        "\n",
        "embeddings = embeddings_model.embed_documents(\n",
        "    [\n",
        "        '안녕하세요!',\n",
        "        '어! 오랜만이에요',\n",
        "        '이름이 어떻게 되세요?',\n",
        "        '날씨가 추워요',\n",
        "        'Hello LLM!'\n",
        "    ]\n",
        ")\n",
        "\n",
        "embedded_query = embeddings_model.embed_query('첫인사를 하고 이름을 물어봤나요?')\n",
        "print(str(len(embedded_query))+'차원')\n",
        "\n",
        "for embedding in embeddings:\n",
        "    print(cos_sim(embedding, embedded_query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUgV7PY8vgde",
        "outputId": "865721ec-35c7-46a3-f102-c191835ef394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "768차원\n",
            "0.6051636939358793\n",
            "0.620231830582371\n",
            "0.7160855778483425\n",
            "0.6574387494383126\n",
            "0.55527388841408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google GenAI의 Embedding 모델\n",
        "# 텍스트를 특정 너비로 감싸는 데 사용되는 라이브러리를 가져옵니다.\n",
        "import textwrap\n",
        "# 과학 계산을 위한 라이브러리인 numpy를 가져옵니다.\n",
        "import numpy as np\n",
        "# 데이터 분석을 위한 라이브러리인 pandas를 가져옵니다.\n",
        "import pandas as pd\n",
        "# Google의 생성적 AI 모듈을 가져옵니다.\n",
        "import google.generativeai as genai\n",
        "# Google의 생성적 언어 모델을 가져옵니다.\n",
        "import google.ai.generativelanguage as glm\n",
        "# IPython 환경에서 Markdown 형식의 텍스트를 표시하기 위한 모듈을 가져옵니다.\n",
        "from IPython.display import Markdown\n",
        "# genai 라이브러리의 list_models 함수를 사용하여 사용 가능한 모델들의 목록을 가져옵니다.\n",
        "\n",
        "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "for m in genai.list_models():\n",
        "    # 각 모델의 supported_generation_methods 속성 중 'embedContent' 메소드를 지원하는지 확인합니다.\n",
        "    if \"embedContent\" in m.supported_generation_methods:\n",
        "        # 'embedContent' 메소드를 지원하는 모델의 이름을 출력합니다.\n",
        "        print(m.name)\n",
        "\n",
        "# 제목을 문자열로 선언합니다.\n",
        "title = \"The next generation of AI for developers and Google Workspace\"\n",
        "# 샘플 텍스트를 문자열로 선언합니다. 여기에는 제목과 본문이 포함되어 있습니다.\n",
        "sample_text = (\n",
        "    \"Title: The next generation of AI for developers and Google Workspace\"\n",
        "    \"\\n\"\n",
        "    \"Full article:\\n\"\n",
        "    \"\\n\"\n",
        "    \"Gemini API & Google AI Studio: An approachable way to explore and prototype with generative AI applications\"\n",
        ")\n",
        "\n",
        "# 사용할 모델의 이름을 문자열로 선언합니다.\n",
        "model = \"models/embedding-001\"\n",
        "# genai.embed_content 함수를 사용하여 콘텐츠의 임베딩을 생성합니다.\n",
        "# 이 함수는 모델, 콘텐츠, 작업 유형, 제목을 인자로 받습니다.\n",
        "embeded = genai.embed_content(\n",
        "    model=model, content=sample_text, task_type=\"retrieval_document\", title=title\n",
        ")\n",
        "\n",
        "# 생성된 임베딩을 출력합니다.\n",
        "print(str(len(embeded['embedding']))+'차원')\n",
        "print(embeded)\n",
        "\n",
        "\n",
        "text=\"진희는 강아지를 키우고 있습니다. 진희가 키우고 있는 동물은?\"\n",
        "# genai.embed_content 함수를 사용하여 콘텐츠의 임베딩을 생성합니다.\n",
        "# 이 함수는 모델, 콘텐츠, 작업 유형, 제목을 인자로 받습니다.\n",
        "embeded = genai.embed_content(\n",
        "    model=model, content=text\n",
        ")\n",
        "\n",
        "# 생성된 임베딩을 출력합니다.\n",
        "print(str(len(embeded['embedding']))+'차원')\n",
        "print(embeded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "Rg4njtr0VMcM",
        "outputId": "05738686-97a1-496c-8766-1352f0e5fc3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "768차원\n",
            "{'embedding': [0.03411343, -0.05517662, -0.020209055, -0.0041249567, 0.058917783, 0.014129515, 0.0045353593, 0.0014303668, 0.05976634, 0.08292115, 0.007162964, 0.0069041685, -0.053083427, -0.010905125, 0.0321402, -0.037163995, 0.050372455, 0.019348344, -0.037328612, 0.026647927, 0.030781753, -0.011288501, -0.031485256, -0.060248993, -0.026219442, -0.009794235, 0.006630139, -0.01846516, -0.026324715, 0.020442624, -0.06317684, 0.014559574, -0.052296035, 0.016451128, -9.720217e-05, -0.051706687, -0.0054406044, -0.056967627, 0.011144145, -0.009201792, -0.0021951047, -0.1099701, -0.011712193, 0.021221714, 0.009171804, -0.029621972, 0.034534883, 0.039578073, 0.019021519, -0.06269169, 0.039473332, 0.052403256, 0.061814185, -0.034507945, -0.009557816, -0.0049551064, 0.017839009, -0.021176832, 0.015043588, 0.015390569, -0.006334281, 0.043696404, -0.028341983, 0.028433999, 0.01472686, -0.06585564, -0.044533554, 0.0055523133, 0.035775978, 0.031099156, 0.027357662, 0.028062241, 0.056972917, -0.054656833, -0.027864764, -0.15486294, -0.027930057, 0.043678433, 0.008391214, 0.020209847, 0.002841071, -0.07201404, -0.05025868, -0.034896467, -0.030400582, 0.016623711, -0.050455835, -0.025557702, 0.0050540236, 0.032266915, -0.018223321, -0.04913693, 0.07667526, -0.03066128, -0.0127946865, 0.107169494, -0.0563475, -0.016773727, -0.010336115, -0.05220995, -0.022049127, 0.00478732, -0.039094422, 0.015671168, 0.041542538, 0.016112784, -0.022650082, 0.002988097, -0.061147556, 0.06630078, -0.057244215, -0.013767544, -0.003466806, -0.053994596, 0.04230463, -0.029314812, 0.021347178, 0.04522084, 0.0072983643, 0.0247336, 0.020755325, 0.025620919, 0.021721177, 0.008178421, -0.063603185, 0.025854606, -0.037521806, 0.020877894, 0.033131972, 0.030288944, 0.0033810628, -0.048698667, -0.027295412, 0.05622969, 0.029634966, 0.029705161, 0.010602056, -0.02217137, 0.03195607, 0.047208548, -0.013620148, 0.038463745, 0.0052672145, -0.024868716, -0.0071725682, 0.069668904, -0.092124775, 0.014151632, 0.0057337824, -0.006012909, -0.035946254, 0.0334855, -0.07426327, 0.033595767, 0.033740804, 0.0394573, -0.048899952, 0.06265119, 0.0028897377, 0.0039847936, 0.0329678, -0.012809373, 0.050108086, 0.009314281, -0.019499086, -0.048860364, -0.015204039, 0.008016007, 0.015667893, 0.03903864, 0.011732032, 0.034669068, -0.01226258, -0.052623957, 0.006695629, -0.05849198, 0.00101155, -0.009621011, -0.0052014636, -0.020959012, -0.02466722, -0.03861565, 0.049754824, 0.048655674, 0.0044479654, -0.020404046, 0.101043485, -0.022594253, -0.06822699, 0.044780556, -0.03859346, -0.015194885, -0.0059435116, -0.016267126, 0.0012126336, 0.054198146, 0.01978253, 0.02905382, 0.034172967, -0.0032252679, 0.020003818, 0.07212547, 0.035888623, -0.00029856138, 0.0044168616, 0.036989234, 0.100975856, 0.0048228516, -0.04405796, 0.00039434276, -0.044601627, -0.011658614, 0.03398768, 0.02250937, 0.034583274, -0.03440395, -0.003274625, -0.005927225, -0.007679341, -0.025777208, -0.02205426, 0.00823437, -0.027172998, -0.015607741, -0.022958823, 0.098416075, -0.045472592, 0.031623535, 0.030663209, -0.03987397, 0.0048750523, 0.057770126, 0.04547866, 0.009881574, 0.044948515, 0.012011639, 0.003141497, 0.0016209317, 0.07142094, 0.025111957, -0.049478546, 0.052195616, 0.041401174, 0.0380032, -0.05878786, -0.007194873, -0.015402912, 0.048243146, 0.025205499, 0.051020827, -0.030305905, -0.031656887, -0.008994425, 0.039839912, -0.043015696, 0.008373317, -0.089018084, -0.045301914, -0.0074205245, 0.0049243467, 0.060365975, -0.06462967, 0.00815101, -0.020417998, 0.00030822973, -0.039288856, 0.04017253, 0.03137731, -0.031728875, 0.03444872, -0.031234143, -0.048502136, 0.033941768, 0.034225147, -0.008299359, 0.033098515, -0.012317135, 0.014448822, 0.06187389, -0.059683096, 0.0012899865, 0.007460227, 0.02652167, -0.07248658, -0.05818953, 0.030052334, -0.015347992, -0.035913672, -0.034901086, -0.0661791, -0.055562418, 0.0130468095, -0.0035763406, -0.0086615095, -0.046888705, -0.005326655, -0.021710252, 0.072175056, 0.038597208, -0.038364347, -0.005039459, -0.07634857, -0.045539834, -0.07372115, 0.018378831, -0.032071035, -0.030269828, -0.044599615, 0.05132602, 0.04769642, 0.0014855171, -0.028435005, -0.0016777773, 0.0072506564, 0.08448479, 0.04224268, -0.029304115, 0.02165559, 0.0056837583, 0.06214723, 0.0028552667, 0.015904495, -0.016737062, -0.0040876116, -0.037475582, 0.04675168, -0.052556172, -0.016293239, -0.014435561, 0.022127734, -0.0052535324, 0.0190588, -0.011537659, 0.0484614, 0.028816467, 0.024607794, -0.043762755, 0.011608192, 0.0021703655, -0.045297306, -0.0048169023, -0.0071430723, 0.011705694, -0.05006429, 0.029933244, -0.020802287, -0.07580785, -0.012268235, 0.07616304, 0.006857885, 0.01853518, 0.043729052, -0.032221675, -0.010121849, -0.019831154, -0.032731093, 0.051531196, 0.0024111927, 0.090960525, -0.036896333, 0.035708647, 0.03678696, 0.00832481, 0.001757778, 0.04144341, 0.042203393, 0.0045936033, 0.021837635, 0.0066275136, 0.0069022025, -0.008452904, -0.03277543, 0.0061044246, -0.02500629, 0.012441071, 0.018081166, -0.06230864, -0.040046707, -0.019351328, 0.0007255696, 0.002202931, -0.041990966, 0.023313772, 0.039377946, -0.0012839311, 0.010378518, 0.0025737497, 0.043841247, -0.0067742136, 0.045794934, 0.01388272, 0.032243907, 0.0919292, 0.03760722, 0.0060486114, 0.010843367, 0.001991803, -0.04838942, -0.006412631, -0.030764624, -0.015602797, -0.048885867, -0.015245706, -0.0006477355, 0.013608845, 0.0040335134, -0.0015530499, -0.008402027, -0.05728556, -0.027370622, 0.019342335, -0.039145477, 0.049000833, -0.052876346, -0.060248777, 0.009484413, 0.011271402, -0.0019944878, -0.013369263, -0.0130786, 0.0050903647, -0.0003995775, 0.04580157, -0.030488051, -0.07777237, 0.022998745, -0.007693635, -0.013473893, 0.0071830116, 0.014312745, 0.019949466, 0.034036275, -0.0011623668, 0.022655929, -0.0049825236, -0.036455333, 0.0033899196, 0.020583669, -0.010457001, 0.027299065, 0.034606297, -0.0111719165, -0.013660416, -0.02705466, -0.05144293, -0.07396907, -0.022817062, -0.0064836126, 0.037774086, -0.06774259, 0.016620712, -0.046481006, -0.030288063, -0.055035893, -0.015402408, -0.014477583, 0.0024700973, 0.024081903, -0.008900536, -0.0032105052, 0.026591286, -0.027869076, -0.014552753, -0.026460772, 0.06831125, -0.019622969, -0.028588912, -0.02271201, 0.0019694276, 0.0079966, -0.013207389, -0.07246265, -0.005246626, -0.03556684, 0.014131167, 0.0018361827, -0.084728725, 0.010380415, -0.038140625, 0.0066234693, -0.023485202, 0.05133969, 0.018931301, -0.0077241925, -0.01968148, -0.0615474, 0.036711216, 0.028462604, -0.02205502, 0.02294784, 0.03529192, 0.044653304, -0.029656367, -0.04243813, -0.024271922, 0.008206945, -0.015324323, 0.028326686, 0.0708875, 0.03499979, -0.04111004, -0.02691298, -0.011054021, 0.035632536, 0.057256706, -0.058149684, 0.022313014, -0.03727344, 0.0095027555, -0.0325091, -0.007395906, 0.009455788, 0.0053972304, -0.028935568, 0.054196633, -0.051867362, -0.010642803, 0.034427024, 0.04308132, 0.020671992, 0.068610825, 0.018303277, -0.08433639, 0.0023544622, -0.009237108, -0.0410166, 0.012912618, -0.035220295, 0.032994937, -0.0063333404, -0.028377546, 0.05429965, -0.022590995, -0.033762764, -0.0061482205, 0.0014308131, 0.05402618, -0.030298075, -0.020893354, 0.04020406, -0.013849863, -0.047842298, 0.032006662, 0.037729368, -0.02878951, 0.002758488, -0.0023380243, -0.052403864, 0.021707276, -0.02718091, 0.0045513017, 0.02493268, -0.016037108, 0.009521465, 0.022595555, -0.03332406, -0.01791281, -0.026219219, 0.015336862, 0.018615942, 0.0014700901, 0.005194217, -0.0059983027, -0.002134208, 0.055935774, 0.0002028429, -0.01381741, 0.0005677742, 0.052481145, -0.0056857914, -0.024219796, -0.0074823913, 0.041230515, 0.005571935, 0.06841099, -0.025634678, -0.037456885, -0.0021465495, -0.05163424, 0.048833348, 0.057269894, -0.0017718605, -0.012836743, 0.054180846, -0.032427873, -0.003244846, 0.01254491, 0.0071952185, 0.02080726, 0.015043071, -0.08000574, 0.047099367, -0.009071923, 0.022494175, -0.007407801, -0.018199192, 0.01923855, -0.016820459, 0.026590073, 0.05919531, -0.015211094, -0.051043298, 0.05085604, -0.027980763, -0.01785205, 0.05260401, 0.0039136643, -0.010834236, 0.015846392, 0.011993318, 0.0085244095, -0.09705911, 0.004848937, -0.03151453, -0.049902532, -0.023312563, 0.0169847, 0.051852323, -0.018586924, -0.011750037, 0.020324359, 0.041236103, 0.046270456, 0.045885824, 0.035645086, 0.027820086, -0.054944187, -0.0018159872, 0.06008568, 0.056207847, 0.03509413, 0.07476336, 0.00042090056, -0.01791933, -0.049269866, 0.013118644, 0.03817175, 0.03985353, -0.023338122, -0.05917611, -0.040447813, -0.014515073, -0.01641867, -0.012444603, -0.015801677, 0.01694387, -0.012097041, -0.10444289, -0.044068433, 0.028175205, 0.0032158983, 0.017225135, 0.024197249, 0.0003871886, 0.008296747, 0.0020322825, -0.06488942, -0.028532177, 0.03631236, -0.021784041, -0.028676897, 0.020023972, -0.015093374, -0.0053404626, -0.035407133, -0.03022746, -0.045240995, -0.089037456, -0.05241791, 0.01601896, -0.058039088, 0.06633133, 0.01435994, 0.0024608225, 0.02044063, 0.049869247, 0.013966787, 0.011062478, 0.023516618, 0.010368709, 0.039040443, -0.03096598, -0.01665127, 0.010691767, -0.0089797005, 0.018564576, 0.03291386, 0.0032383145, -0.00884169, -0.008645399, 0.0001677955, -0.04452774, 0.007207213, -0.008696507, 0.0023566217, -0.025329702, -0.042708885, -0.03173582, 0.06427912, 0.030916397, -0.022305708, -0.018711232, -0.008136281, -0.01636213, 0.019092057, 0.010243902, -0.04405114, 0.018331835, -0.025844995, 0.035896596, 0.049257137, -0.053962618, -0.084952496, -0.009314442, -0.03644633, 0.0010881334, -0.042904764, 0.016017154, -0.011390375, 0.056498464, 0.007735383, 0.015750613, 0.023586866, -0.005065194, -0.05339934, 0.030084236, -0.021841932, -0.0035868485, -0.025362536, 0.0315042, 0.039552346, -0.032164883, -0.03519624, -0.013936666, 0.006526046, 0.02818671, -0.018081086, 0.04806136, -0.04418975, -0.064630605, -0.010125073, -0.02926605, 0.022641547, 0.040159058, 0.022463534, -0.04924557, -0.010198766, -0.019940902, -0.0033762371, -0.07010838, -0.031799905, -0.020567331, -0.015259151, 0.04870838, 0.030047685, -0.016861487, 0.020778332, -0.034649372, -0.0026895248, -0.0053685517, -0.03297844, -0.0048753927, -0.005587019, -0.041837722, 0.0161564, 0.072810896, -0.043315165, 0.03330332]}\n",
            "768차원\n",
            "{'embedding': [0.054843746, -0.058581058, -0.019897586, -0.0017663339, 0.029070921, -0.0057575023, 0.020625718, -0.012160993, 0.020421693, 0.031018129, 0.033817846, 0.014122755, 0.0006220173, -0.038810074, -0.02861183, -0.024272386, 0.00927779, -0.00792477, 0.042048242, -0.030893829, 0.008289451, 0.0044056294, -0.04625419, -0.008019856, -0.009024553, -0.046495218, -0.013070962, -0.033591338, -0.04385253, 0.06386754, -0.054670244, 0.03634559, -0.10055453, -0.01781741, 0.00076326204, -0.044195402, -0.005572735, 0.015877293, 0.023237122, 0.051023368, 0.01149229, -0.014820885, -0.06324471, -0.02994299, 0.0033564474, -0.011722816, 0.01878415, -0.0075198286, 0.041480687, -0.056625675, 0.005034629, 0.003286289, 0.06533547, -0.02565847, -0.020821031, -0.035840422, 0.006843424, 0.0048874076, 0.011744068, 0.01700335, 0.014097667, 0.015611321, -0.03628886, 0.093234316, -0.028957266, -0.013165717, -0.010430285, 0.024245162, 0.07572696, -0.015472902, 0.05038936, -0.017629892, 0.05219583, -0.024849666, -0.055331454, -0.08943086, -0.041345768, 0.08322464, 0.01410612, -0.03142438, -0.017147632, -0.06961238, -0.01804321, -0.017136022, -0.015665453, 0.035965886, -0.03760785, 0.01264925, 0.010263859, 0.05257626, 0.026929071, -0.0085201105, 0.017068064, -0.081945, -0.008287215, 0.07396927, -0.024371061, -0.008055808, -0.0064819492, -0.022743234, -0.009818665, -0.05790249, -0.033058643, -0.01108588, 0.031447474, 0.009978634, 0.013291388, 0.04415998, -0.01103935, 0.057981934, -0.003336669, -0.011449628, -0.007991294, 0.019066008, 0.027370706, -0.062328883, 0.014581486, 0.08178542, 0.07169404, 0.020532383, -0.01588534, -0.0015036996, 0.04278103, 0.04107482, 0.009246692, 0.013227745, -0.0027886406, 0.014654084, 0.08699878, 0.061784685, -0.023287332, -0.04361759, 0.02571579, 0.009389849, 0.02227584, 0.02254423, 0.018954637, 0.031318314, 0.05779377, 0.0060488745, -0.03245001, 0.020084143, -0.030583581, 0.02630803, 0.01814357, 0.04142794, -0.016086297, -0.051148538, 0.065773174, -0.033520635, -0.03281567, -0.05391822, -0.022390429, 0.043982178, 0.06655797, 0.029339425, -0.060350716, 0.013168367, -0.007944965, 0.036679883, 0.07085713, 0.051708855, 0.04115717, -0.0058953133, -0.009761633, -0.039321166, 0.015818315, -0.009388708, 0.011456819, 0.03669942, -0.0015929136, 0.013287417, -0.06657639, -0.057923857, -0.011865803, -0.050186973, 0.009886141, -0.03255958, -0.034901593, 0.00635014, -0.03204789, -0.06758266, 0.011529504, 0.024384163, 0.009605132, -0.06727176, 0.07353639, -0.009657852, -0.019698286, -0.032147717, 0.025427451, -0.044363678, -0.006670543, 0.0026900668, 0.0036994487, 0.03480386, 0.018354673, 0.021842925, 0.011899024, -0.025965858, -0.020353848, 0.064935625, 0.019070748, 0.006836591, 0.06306441, -0.038840923, 0.057934035, -0.026682096, -0.031146204, 0.032625243, -0.03658227, 0.042172987, -0.06840317, 0.007219157, 0.025500977, -0.011018242, 0.027530933, 0.04735681, 0.022236139, -0.025404694, 0.0073407483, 0.035207767, -0.054765496, 0.0011156462, 0.025672521, 0.028903987, -0.027505685, 0.034626916, -0.012150596, -0.027217075, 0.0034509206, 0.06100563, 0.07329388, -0.028288022, 0.05392365, -0.019842625, 0.03230911, 0.010195535, 0.018613921, -0.0006169085, -0.04536905, 0.038298663, 0.061112814, 0.013080217, -0.0323175, -0.049653135, 0.018387971, 0.0638665, -0.0012034451, 0.017347945, -0.02247559, -0.06539748, -0.0008005216, 0.04696262, -0.06507276, 0.038753994, -0.06751955, 0.015404021, -0.009964547, 0.04203699, 0.055961393, 0.012098297, 0.024049778, -0.019209025, -0.017788729, 0.032861896, 0.047629032, -0.030829066, -0.008399364, -0.02710352, 0.00934215, -0.07774335, 0.08244497, 0.016075889, -0.024942169, 0.030937038, -0.011808083, 0.041972537, 0.0082046855, -0.02948597, -0.024214333, -0.011672767, -0.00084790034, -0.03947782, -0.028370872, -0.027814202, -0.051112622, -0.014057901, 0.053115133, -0.03600577, -0.06102281, -0.014414677, -0.008738715, 0.00025424716, -0.033947486, 0.025960863, -0.025060631, 0.022042945, 0.002601195, 0.011643715, 0.022315713, 0.0236843, 0.00085941626, -0.0434076, 0.022862135, 0.014837881, -0.039124623, -0.042288292, -0.020157868, -0.0043806373, -0.030388238, -0.005659292, -0.07445525, -0.0031676055, 0.0034432034, 0.023028724, -0.046523787, 0.026618429, -0.02361191, 0.041228157, -0.01818947, 0.0457252, 0.0078070625, -0.009178675, 0.028150039, -0.0010648853, -0.037767455, 0.056801647, -0.0062064077, -0.025539527, -0.041121896, -0.007816442, -0.018811982, 0.017036961, 0.026536051, 0.05868703, -0.081727855, -0.017239546, -0.037374303, 0.00089340936, 0.04239679, -0.0024399078, -0.03908347, -0.07229061, -0.01338501, -0.03221466, -0.020304358, 0.0024362658, 0.052447025, 0.0003890146, -0.01325952, 0.09272853, -0.025139136, -0.026751243, -0.007671534, -0.073957495, 0.049638975, -0.018372424, 0.011350606, -0.05447495, -0.011510237, 0.039921016, -0.010379897, 0.03417562, -0.008454714, -0.005773268, 0.035054557, 0.0014120041, -0.017147508, 0.0044414387, 0.000766596, -0.034244817, 0.025782442, -0.026006699, -0.03361508, -0.06342385, -0.038717203, -0.014830335, 0.02118479, -0.019985871, -0.051455285, -0.006752686, 0.046952978, 0.05622775, 0.032193977, -0.017995397, 0.032316532, 0.050940495, 0.042857785, 0.036730144, 0.055387132, 0.011411945, 0.02100827, 0.029263336, 0.011029483, 0.015344243, -0.025290854, -0.053478245, 0.012123254, -0.025379963, -0.011276567, -0.03919355, -0.035247877, -0.04230424, -0.027609995, -0.050876234, -0.02382003, -0.0014566992, -0.031640112, -0.023603348, 0.001356336, 0.059967134, 0.021185845, -0.11405691, -0.061018355, -0.028512694, 0.052718893, -0.0037128702, 0.02418825, 0.027301522, 0.014848707, 0.03472745, -0.039180648, -0.03627376, -0.037601627, -0.051389918, -0.043601837, -0.028130878, -0.021606235, 0.02654582, 0.016010221, 0.0034465275, -0.01407335, -0.0328256, 0.0025416922, -0.046039954, 0.01275864, 0.03475831, 0.0120472815, -0.038339365, -0.021626959, -0.026938142, 0.03938696, 0.052277725, -0.08672662, -0.018662633, 0.026950093, -0.028684579, 0.05053692, -0.07660663, 0.012765714, -0.06743795, -0.038337693, -0.05454597, -0.06167282, -0.052753977, 0.035305154, 0.020245459, -0.030261692, 0.03253155, -0.022604577, 0.006195844, -0.02672642, -0.07267925, 0.047430128, -0.02836476, 0.046153966, 0.0020571118, 0.04503747, 0.045622528, 0.022686977, -0.020542791, -0.0040744315, 0.013289022, -0.0324465, 0.02103617, -0.075643264, 0.0043364125, -0.011499108, -0.046080936, -0.020617446, -0.011623073, 0.03946207, 0.026094362, -0.005153921, 0.001966455, -0.008146198, -0.017040273, 0.00939113, 0.04229409, -0.026300265, 0.0038289134, -0.020361189, -0.037334595, 0.024727842, 0.014013394, -0.040289138, -0.012913278, 0.020254241, 0.016379397, -0.018282939, -0.0028274069, 0.021102145, -0.010864298, 0.01954481, -0.08003087, 0.033322964, -0.012482792, -0.020868134, -0.02164382, 0.012325435, 0.0038214454, 0.047528315, -0.004349879, 0.049201574, 0.01866014, -0.038380537, 0.0428705, 0.02998638, -0.015444119, 0.03352443, -0.0042441348, -0.13327767, -0.014077764, 0.020418083, -0.064180404, 0.04301766, 0.021363406, -0.014964494, -0.031211779, -0.014935245, 0.08542472, -0.078642115, -0.024950009, 0.0004346852, -0.014739942, -0.026196532, 0.02065075, 0.024160303, -0.0004187664, -0.0003468962, 0.017365374, -0.0018945894, 0.01076294, 0.014879114, 0.024622219, -0.012754307, -0.10059341, 0.0015258787, -0.0058711637, -0.01140205, -0.03625902, -0.005960986, -0.039611455, 0.016198952, -0.026806543, -0.02252275, -0.03767314, 0.022954864, -0.0017818101, -0.033303853, -0.05199156, -0.0037084133, -0.036201257, 0.07600059, 0.032496523, 0.011749648, -0.019118728, 0.065794446, -0.02047061, 0.0184878, -0.0018934744, 0.03260105, 0.013659993, 0.040669717, -0.035137564, -0.010480408, -0.01747755, 0.027177457, 0.0058796643, 0.010870376, -0.0018999187, 0.02942216, 0.025846062, -0.0034579528, 0.021806464, 0.029851794, 0.0031602893, 0.04415413, 0.033605915, -0.06317112, 0.07339438, -0.048829574, 0.014847358, 0.023103649, -0.0074062003, -0.044894207, 0.007923719, 0.0038590017, -0.023280786, 0.03907225, -0.03960667, 0.04218756, -0.03084813, 0.027968567, 0.0041806204, -0.012489182, -0.020477414, -0.016682902, 0.0004245393, 0.002697497, -0.01680816, 0.036866836, -0.014289387, -0.060138945, 0.026303234, 0.049755115, -0.0038955058, -0.040593058, -0.069627635, 0.02333726, -0.05478558, -0.023412952, 0.023735851, 0.053576536, 0.0106350025, 0.033905163, -0.029309317, 0.039088476, -0.008383196, 0.019745093, 0.055139698, 0.0056781755, -0.0053684097, -0.027590374, 0.013225286, -0.009597591, 0.008952743, 0.017210273, -0.0040170136, -0.0995419, 0.04546855, 0.05175684, -0.033677466, -0.027249344, 0.1070668, 0.017747229, -0.06863393, -0.023744665, 0.0026338215, -0.031804945, 0.013801143, 0.019498313, 0.010673239, -0.00023158504, -0.023344152, -0.03242791, -0.025664026, -0.0012725461, -0.009544118, -0.03667804, -0.0037873308, -0.01693867, -0.016647767, -0.017232794, -0.028198365, -0.08189828, -0.007037337, -0.04368579, 0.020485258, -0.053272143, 0.039982934, 0.059570342, -0.011532538, -0.004242546, 0.051791556, -0.026911726, 0.026864342, 0.004838321, 0.012159357, -0.025033692, -0.04460155, -0.012253947, -0.032121193, 0.021178644, 0.04232097, 0.020042133, -0.0069203926, 0.013090432, -0.04094695, 0.015201011, -0.011625365, -0.057706613, 0.022126729, 0.051221445, -0.016049871, -0.02021609, 0.018197503, -0.017609337, 0.038752865, -0.0050260983, -0.053044062, -0.00881059, 0.02861837, -0.021129845, 0.042592272, -0.0030798933, 0.018807517, 0.021740492, 0.012004232, 0.04267284, -0.022435535, -0.09231897, 0.02138924, -0.013570264, -0.05906507, 0.035449, 0.0136593925, -0.023852304, 0.05848755, 0.065136045, 0.03160983, 0.035098083, -0.01927673, -0.04950591, 0.020443913, -0.03890607, 0.06505175, -0.0013526937, -0.0020388244, 0.10846535, 0.010428647, -0.047407124, 0.032529, -0.052487962, 0.053684223, -0.008273884, 0.04926278, -0.03734766, -0.03682752, -0.05113083, -0.019343834, 0.017845944, 0.054409586, -0.014005119, -0.031780615, 0.044583537, -0.035778146, -8.184577e-05, -0.04296958, -0.06615992, 0.017480198, -0.023362344, 0.0030373977, 0.050115786, 0.0024762312, -0.017006833, 0.01595305, 0.005094877, 0.012200623, -0.049848747, 0.05626995, 0.044056058, -0.021174276, 0.0014173074, 0.013604944, 0.0050727967, 0.0234695]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3) Vector Store**"
      ],
      "metadata": {
        "id": "euIwIhCSOTLp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[벡터저장소]** FAISS(Facebook AI Similarity Search)"
      ],
      "metadata": {
        "id": "q8f36ZlyfK8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FAISS 유사도 기반 검색\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, Language\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_community.vectorstores.utils import DistanceStrategy\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=400,\n",
        "    chunk_overlap=40,\n",
        "    length_function=len,\n",
        ")\n",
        "\n",
        "embeddings_model = OpenAIEmbeddings()\n",
        "\n",
        "document = TextLoader(\"appendix-keywords.txt\").load()\n",
        "split_docs = splitter.split_documents(document)\n",
        "print(f'총 분할된 도큐먼트 수: {len(split_docs)}')\n",
        "\n",
        "#vector store\n",
        "vs = FAISS.from_documents(\n",
        "    split_docs,\n",
        "    embedding = embeddings_model,\n",
        "    #유사도 검색방식 지정\n",
        "    #distance_strategy = DistanceStrategy.EUCLIDEAN_DISTANCE\n",
        "    #distance_strategy = DistanceStrategy.COSINE\n",
        ")\n",
        "print(f\"{vs.distance_strategy}\\n\")\n",
        "\n",
        "query = \"FAISS가 뭐야?\"\n",
        "docs = vs.similarity_search(query, k=2)\n",
        "for index, doc in enumerate(docs, start=1):\n",
        "    print(f'[{index}]\\n' + doc.page_content+ \"\\n========\\n\")\n",
        "\n",
        "query = \"GPT란?\"\n",
        "docs = vs.similarity_search(query, k=2)\n",
        "for index, doc in enumerate(docs, start=1):\n",
        "    print(f'[{index}]\\n' + doc.page_content+ \"\\n========\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0FZ0gsla_9b",
        "outputId": "6efdb515-d1ae-480f-96ed-cb5a5de796b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 분할된 도큐먼트 수: 19\n",
            "EUCLIDEAN_DISTANCE\n",
            "\n",
            "[1]\n",
            "FAISS (Facebook AI Similarity Search)\n",
            "\n",
            "정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\n",
            "예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\n",
            "연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\n",
            "\n",
            "Open Source\n",
            "\n",
            "정의: 오픈 소스는 소스 코드가 공개되어 누구나 자유롭게 사용, 수정, 배포할 수 있는 소프트웨어를 의미합니다. 이는 협업과 혁신을 촉진하는 데 중요한 역할을 합니다.\n",
            "예시: 리눅스 운영 체제는 대표적인 오픈 소스 프로젝트입니다.\n",
            "연관키워드: 소프트웨어 개발, 커뮤니티, 기술 협업\n",
            "========\n",
            "\n",
            "[2]\n",
            "HuggingFace\n",
            "\n",
            "정의: HuggingFace는 자연어 처리를 위한 다양한 사전 훈련된 모델과 도구를 제공하는 라이브러리입니다. 이는 연구자와 개발자들이 쉽게 NLP 작업을 수행할 수 있도록 돕습니다.\n",
            "예시: HuggingFace의 Transformers 라이브러리를 사용하여 감정 분석, 텍스트 생성 등의 작업을 수행할 수 있습니다.\n",
            "연관키워드: 자연어 처리, 딥러닝, 라이브러리\n",
            "\n",
            "Digital Transformation\n",
            "========\n",
            "\n",
            "[1]\n",
            "정의: GPT는 대규모의 데이터셋으로 사전 훈련된 생성적 언어 모델로, 다양한 텍스트 기반 작업에 활용됩니다. 이는 입력된 텍스트에 기반하여 자연스러운 언어를 생성할 수 있습니다.\n",
            "예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇은 GPT 모델을 사용할 수 있습니다.\n",
            "연관키워드: 자연어 처리, 텍스트 생성, 딥러닝\n",
            "\n",
            "InstructGPT\n",
            "========\n",
            "\n",
            "[2]\n",
            "InstructGPT\n",
            "\n",
            "정의: InstructGPT는 사용자의 지시에 따라 특정한 작업을 수행하기 위해 최적화된 GPT 모델입니다. 이 모델은 보다 정확하고 관련성 높은 결과를 생성하도록 설계되었습니다.\n",
            "예시: 사용자가 \"이메일 초안 작성\"과 같은 특정 지시를 제공하면, InstructGPT는 관련 내용을 기반으로 이메일을 작성합니다.\n",
            "연관키워드: 인공지능, 자연어 이해, 명령 기반 처리\n",
            "\n",
            "Keyword Search\n",
            "========\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FAISS MMR(Maximum marginal relevances search) 검색\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, Language\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_community.vectorstores.utils import DistanceStrategy\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=400,\n",
        "    chunk_overlap=40,\n",
        "    length_function=len,\n",
        ")\n",
        "\n",
        "embeddings_model = OpenAIEmbeddings()\n",
        "\n",
        "document = TextLoader(\"appendix-keywords.txt\").load()\n",
        "split_docs = splitter.split_documents(document)\n",
        "print(f'총 분할된 도큐먼트 수: {len(split_docs)}')\n",
        "\n",
        "#vector store\n",
        "vs = FAISS.from_documents(\n",
        "    split_docs,\n",
        "    embedding = embeddings_model,\n",
        "    #distance_strategy = DistanceStrategy.EUCLIDEAN_DISTANCE\n",
        "    distance_strategy = DistanceStrategy.COSINE\n",
        ")\n",
        "print(f\"{vs.distance_strategy}\\n\")\n",
        "\n",
        "query = \"FAISS가 뭐야?\"\n",
        "mmr_docs = vs.max_marginal_relevance_search(query, k=2, fetch_k=5)\n",
        "for index, doc in enumerate(mmr_docs, start=1):\n",
        "    print(f'[{index}]\\n' + doc.page_content+ \"\\n========\\n\")\n",
        "\n",
        "query = \"GPT란?\"\n",
        "mmr_docs = vs.max_marginal_relevance_search(query, k=2, fetch_k=5)\n",
        "for index, doc in enumerate(mmr_docs, start=1):\n",
        "    print(f'[{index}]\\n' + doc.page_content+ \"\\n========\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFxGbGv61o6c",
        "outputId": "d9c07c8c-3061-4b31-9b82-5fd9c4dd15b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 분할된 도큐먼트 수: 19\n",
            "COSINE\n",
            "\n",
            "[1]\n",
            "FAISS (Facebook AI Similarity Search)\n",
            "\n",
            "정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\n",
            "예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\n",
            "연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\n",
            "\n",
            "Open Source\n",
            "\n",
            "정의: 오픈 소스는 소스 코드가 공개되어 누구나 자유롭게 사용, 수정, 배포할 수 있는 소프트웨어를 의미합니다. 이는 협업과 혁신을 촉진하는 데 중요한 역할을 합니다.\n",
            "예시: 리눅스 운영 체제는 대표적인 오픈 소스 프로젝트입니다.\n",
            "연관키워드: 소프트웨어 개발, 커뮤니티, 기술 협업\n",
            "========\n",
            "\n",
            "[2]\n",
            "Schema\n",
            "\n",
            "정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\n",
            "예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\n",
            "연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\n",
            "\n",
            "DataFrame\n",
            "\n",
            "정의: DataFrame은 행과 열로 이루어진 테이블 형태의 데이터 구조로, 주로 데이터 분석 및 처리에 사용됩니다.\n",
            "예시: 판다스 라이브러리에서 DataFrame은 다양한 데이터 타입의 열을 가질 수 있으며, 데이터 조작과 분석을 용이하게 합니다.\n",
            "연관키워드: 데이터 분석, 판다스, 데이터 처리\n",
            "\n",
            "Attention 메커니즘\n",
            "========\n",
            "\n",
            "[1]\n",
            "정의: GPT는 대규모의 데이터셋으로 사전 훈련된 생성적 언어 모델로, 다양한 텍스트 기반 작업에 활용됩니다. 이는 입력된 텍스트에 기반하여 자연스러운 언어를 생성할 수 있습니다.\n",
            "예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇은 GPT 모델을 사용할 수 있습니다.\n",
            "연관키워드: 자연어 처리, 텍스트 생성, 딥러닝\n",
            "\n",
            "InstructGPT\n",
            "========\n",
            "\n",
            "[2]\n",
            "Token\n",
            "\n",
            "정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\n",
            "예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\n",
            "연관키워드: 토큰화, 자연어 처리, 구문 분석\n",
            "\n",
            "Tokenizer\n",
            "\n",
            "정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.\n",
            "예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\n",
            "연관키워드: 토큰화, 자연어 처리, 구문 분석\n",
            "\n",
            "VectorStore\n",
            "========\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[벡터저장소]** FAISS 로컬 DB Save & Load"
      ],
      "metadata": {
        "id": "hmOsrpgugFss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 벡터저장소(FAISS)\n",
        "# 임베딩 결과를 파일로 저장해 놓으면 다시 임베딩 할 필요 없이 기존 결과를 불러오면 된다.\n",
        "#!pip install -q faiss-cpu\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, Language\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embedding_model = OpenAIEmbeddings()\n",
        "faiss_dir = \"faiss\"\n",
        "doc_file_path = \"appendix-keywords.txt\"\n",
        "\n",
        "if(os.path.isdir(faiss_dir) == False):\n",
        "    document = TextLoader(doc_file_path).load()\n",
        "\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        "        chunk_size=400,\n",
        "        chunk_overlap=40,\n",
        "        length_function=len,\n",
        "    )\n",
        "    split_docs = splitter.split_documents(document)\n",
        "    print(f'총 분할된 도큐먼트 수: {len(split_docs)}')\n",
        "\n",
        "    vs = FAISS.from_documents(split_docs, embedding_model)\n",
        "    vs.save_local(faiss_dir)\n",
        "    print(\"saved\")\n",
        "else:\n",
        "    vs = FAISS.load_local(faiss_dir, embedding_model, allow_dangerous_deserialization=True)\n",
        "    print('loaded')\n",
        "\n",
        "query = \"FAISS가 뭐야?\"\n",
        "#query = \"Pandas란?\"\n",
        "docs = vs.similarity_search(query)\n",
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGXf4e7tftOQ",
        "outputId": "259880ab-1711-4942-ad15-93074ab1c010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded\n",
            "FAISS (Facebook AI Similarity Search)\n",
            "\n",
            "정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\n",
            "예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\n",
            "연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\n",
            "\n",
            "Open Source\n",
            "\n",
            "정의: 오픈 소스는 소스 코드가 공개되어 누구나 자유롭게 사용, 수정, 배포할 수 있는 소프트웨어를 의미합니다. 이는 협업과 혁신을 촉진하는 데 중요한 역할을 합니다.\n",
            "예시: 리눅스 운영 체제는 대표적인 오픈 소스 프로젝트입니다.\n",
            "연관키워드: 소프트웨어 개발, 커뮤니티, 기술 협업\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 벡터저장소(FAISS)\n",
        "# 임베딩 결과를 파일로 저장해 놓으면 다시 임베딩 할 필요 없이 기존 결과를 불러오면 된다.\n",
        "#!pip install -q faiss-cpu\n",
        "from langchain.document_loaders import TextLoader, PyMuPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embedding_model = OpenAIEmbeddings()\n",
        "faiss_dir = \"faiss\"\n",
        "doc_file_path = \"소나기 - 황순원.pdf\"\n",
        "\n",
        "if(os.path.isdir(faiss_dir) == False):\n",
        "    document = PyMuPDFLoader(doc_file_path).load()\n",
        "\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200,\n",
        "        length_function=len,\n",
        "    )\n",
        "    split_docs = splitter.split_documents(document)\n",
        "    print(f'총 분할된 도큐먼트 수: {len(split_docs)}')\n",
        "\n",
        "    vs = FAISS.from_documents(split_docs, embedding_model)\n",
        "    vs.save_local(faiss_dir)\n",
        "    print(\"saved\")\n",
        "else:\n",
        "    vs = FAISS.load_local(faiss_dir, embedding_model, allow_dangerous_deserialization=True)\n",
        "    print('loaded')\n",
        "\n",
        "print(f\"{vs.distance_strategy}\\n\")\n",
        "\n",
        "query = \"소녀는 왜 이사를 오게 되었는가?\"\n",
        "docs = vs.max_marginal_relevance_search(query, k=2)\n",
        "for index, doc in enumerate(docs, start=1):\n",
        "    print(f'[{index}]' + doc.page_content+ \"\\n========\\n\")\n",
        "\n",
        "query = \"소녀가 대추를 딴 이유는?\"\n",
        "docs = vs.max_marginal_relevance_search(query, k=3)\n",
        "for index, doc in enumerate(docs, start=1):\n",
        "    print(f'[{index}]' + doc.page_content+ \"\\n========\\n\")\n",
        "\n",
        "# 고찰1\n",
        "query = \"소설 끝에서 소녀는 어떠한 결말을 맞이한거야?\"\n",
        "docs = vs.max_marginal_relevance_search(query, k=6)\n",
        "for index, doc in enumerate(docs, start=1):\n",
        "    print(f'[{index}]' + doc.page_content+ \"\\n========\\n\")\n",
        "\n",
        "# 고찰2\n",
        "query = \"소설의 주인공은?\"\n",
        "docs = vs.max_marginal_relevance_search(query, k=3)\n",
        "for index, doc in enumerate(docs, start=1):\n",
        "    print(f'[{index}]' + doc.page_content+ \"\\n========\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zkc9LwSscSvt",
        "outputId": "3eb6d3c2-eaa2-4c90-89b5-ead1fc764547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded\n",
            "EUCLIDEAN_DISTANCE\n",
            "\n",
            "[1]- 6 -\n",
            "소년은 소녀네가 이사해 오기 전에 벌써 어른들의 이야기를 들어서, 윤 초시 손자(孫子)가 \n",
            "서울서 사업에 실패해 가지고 고향에 돌아오지 않을 수 없게 되었다는 걸 알고 있었다. 그\n",
            "것이 이번에는 고향 집마저 남의 손에 넘기게 된 모양이었다.\n",
            "“왜 그런지 난 이사 가는 게 싫어졌다. 어른들이 하는 일이니 어쩔 수 없지만…….”\n",
            "전에 없이, 소녀의 까만 눈에 쓸쓸한 빛이 떠돌았다.\n",
            "소녀와 헤어져 돌아오는 길에, 소년은 혼잣속으로, 소녀가 이사를 간다는 말을 수없이 되\n",
            "뇌어 보았다. 무어 그리 안타까울 것도 서러울 것도 없었다. 그렇건만, 소년은 지금 자기가 \n",
            "씹고 있는 대추알의 단맛을 모르고 있었다.\n",
            "이 날 밤, 소년은 몰래 덕쇠 할아버지네 호두밭으로 갔다.\n",
            "낯에 봐 두었던 나무로 올라갔다. 그리고, 봐 두었던 가지를 향해 작대기를 내리쳤다. 호두\n",
            "송이 떨어지는 소리가 별나게 크게 들렸다. 가슴이 선뜩했다. 그러나 다음 순간, 굵은 호두\n",
            "야 많이 떨어져라, 많이 떨어져라, 저도 모를 힘에 이끌려 마구 작대기를 내리 치는 것이\n",
            "었다.\n",
            "돌아오는 길에는 열 이틀 달이 지우는 그늘만 골라 디뎠다. 그늘의 고마움을 처음 느꼈다.\n",
            "불룩한 주머니를 어루만졌다. 호두송이를 맨손으로 깠다가는 옴이 오르기 쉽다는 말 같은 건 아\n",
            "무렇지도 않았다. 그저 근동에서 제일 가는 이 덕쇠 할아버지네 호두를 어서 소녀에게 맛보여야 \n",
            "한다는 생각만이 앞섰다.\n",
            "그러다, 아차 하는 생각이 들었다. 소녀더러 병이 좀 낫거들랑 이사 가기 전에 한 번 개울\n",
            "가로 나와 달라는 말을 못해 둔 것이었다. 바보 같은것, 바보 같은것.\n",
            "이튿날, 소년이 학교에서 돌아오니, 아버지가 나들이옷으로 갈아입고 닭 한 마리를 안고 \n",
            "있었다.\n",
            "어디 가시느냐고 물었다.\n",
            "그 말에도 대꾸도 없이, 아버지는 안고 있는 닭의 무게를 겨냥해 보면서,\n",
            "“이만하면 될까?”\n",
            "어머니가 망태기를 내주며,\n",
            "“벌써 며칠째 ‘걀걀’하고 알 날 자리를 보던데요. 크진 않아도살은 쪘을 거여요.”\n",
            "========\n",
            "\n",
            "[2]누가 말할 것도 아닌데, 바위에 나란히 걸터앉았다. 유달리 주위가 조용해진 것 같았다. 따\n",
            "가운 가을 햇살만이 말라가는 풀 냄새를 퍼뜨리고 있었다.\n",
            "“저건 또 무슨 꽃이지?”\n",
            "적잖이 비탈진 곳에 칡덩굴이 엉키어 꽃을 달고 있었다.\n",
            "“꼭 등꽃 같네. 서울 우리 학교에 큰 등나무가 있었단다. 저 꽃을 보니까 등나무 밑에서 \n",
            "놀던 동무들 생각이 난다.”\n",
            "소녀가 조용히 일어나 비탈진 곳으로 간다. 꽃송이가 많이 달린 줄기를 잡고 끊기 시작한\n",
            "========\n",
            "\n",
            "[1]소녀는 나타나지 않는다. 발돋움을 했다. 그러고도 상당한 시간이 지났다고 생각됐다.\n",
            "저 쪽 갈밭머리에 갈꽃이 한 옴큼 움직였다. 소녀가 갈꽃을 안고 있었다. 그리고, 이제는 \n",
            "천천한 걸음이었다. 유난히 맑은 가을 햇살이 소녀의 갈꽃머리에서 반짝거렸다. 소녀 아닌 \n",
            "갈꽃이 들길을 걸어가는 것만 같았다.\n",
            "소년은 이 갈꽃이 아주 뵈지 않게 되기까지 그대로 서 있었다. 문득, 소녀가 던지 조약돌\n",
            "을 내려다보았다. 물기가 걷혀 있었다. 소년은 조약돌을 집어 주머니에 넣었다.\n",
            "다음 날부터 좀더 늦게 개울가로 나왔다. 소녀의 그림자가 뵈지 않았다. 다행이었다.\n",
            "그러나, 이상한 일이었다. 소녀의 그림자가 뵈지 않는 날이 계속될수록 소년의 가슴 한 구\n",
            "석에는 어딘가 허전함이 자리 잡는 것이었다. 주머니 속 조약돌을 주무르는 버릇이 생겼\n",
            "다.\n",
            "그러한 어떤 날, 소년은 전에 소녀가 앉아 물장난을 하던 징검다리 한가운데에 앉아 보았\n",
            "다. 물 속에 손을 잠갔다. 세수를 하였다. 물 속을 들여다보았다. 검게 탄 얼굴이 그대로 \n",
            "비치었다. 싫었다.\n",
            "========\n",
            "\n",
            "[2]는지 잘 지지 않는다.”\n",
            "소녀가 분홍 스웨터 앞자락을 내려다본다. 거기에 검붉은 진흙물 같은 게 들어 있었다.\n",
            "소녀가 가만히 보조개를 떠올리며,\n",
            "“그래 이게 무슨 물 같니?”\n",
            "소년은 스웨터 앞자락만 바라보고 있었다.\n",
            "“내, 생각해 냈다. 그 날, 도랑을 건너면서 내가 업힌 일이 있지? 그 때, 네 등에서 옮은 \n",
            "물이다.”\n",
            "소년은 얼굴이 확 달아오름을 느꼈다.\n",
            "갈림길에서 소녀는\n",
            "“저, 오늘 아침에 우리 집에서 대추를 땄다. 낼 제사 지내려고…….”\n",
            "대추 한 줌을 내준다. 소년은 주춤한다.\n",
            "“맛봐라. 우리 증조(曾祖)할아버지가 심었다는데, 아주 달다.”\n",
            "소년은 두 손을 오그려 내밀며,\n",
            "“참, 알도 굵다!”\n",
            "“그리고 저, 우리 이번에 제사 지내고 나서 좀 있다. 집을 내주게 됐다.”\n",
            "========\n",
            "\n",
            "[3]누가 말할 것도 아닌데, 바위에 나란히 걸터앉았다. 유달리 주위가 조용해진 것 같았다. 따\n",
            "가운 가을 햇살만이 말라가는 풀 냄새를 퍼뜨리고 있었다.\n",
            "“저건 또 무슨 꽃이지?”\n",
            "적잖이 비탈진 곳에 칡덩굴이 엉키어 꽃을 달고 있었다.\n",
            "“꼭 등꽃 같네. 서울 우리 학교에 큰 등나무가 있었단다. 저 꽃을 보니까 등나무 밑에서 \n",
            "놀던 동무들 생각이 난다.”\n",
            "소녀가 조용히 일어나 비탈진 곳으로 간다. 꽃송이가 많이 달린 줄기를 잡고 끊기 시작한\n",
            "========\n",
            "\n",
            "[1]- 1 -\n",
            "소나기\n",
            "황순원\n",
            "소년은 개울가에서 소녀를 보자 곧 윤 초시네 증손녀(曾孫女)딸이라는 걸 알 수 있었다. \n",
            "소녀는 개울에다 손을 잠그고 물장난을 하고 있는 것이다. 서울서는 이런 개울물을 보지 \n",
            "못하기나 한 듯이.\n",
            "벌써 며칠째 소녀는, 학교에서 돌아오는 길에 물장난이었다. 그런데, 어제까지 개울 기슭에\n",
            "서 하더니, 오늘은 징검다리 한가운데 앉아서 하고 있다.\n",
            "소년은 개울둑에 앉아 버렸다. 소녀가 비키기를 기다리자는 것이다.\n",
            "요행 지나가는 사람이 있어, 소녀가 길을 비켜 주었다.\n",
            "다음 날은 좀 늦게 개울가로 나왔다.\n",
            "이 날은 소녀가 징검다리 한가운데 앉아 세수를 하고 있었다. 분홍 스웨터 소매를 걷어올\n",
            "린 목덜미가 마냥 희었다.\n",
            "한참 세수를 하고 나더니, 이번에는 물 속을 빤히 들여다 본다. 얼굴이라도 비추어 보는 \n",
            "것이리라. 갑자기 물을 움켜 낸다. 고기 새끼라도 지나가는 듯.\n",
            "소녀는 소년이 개울둑에 앉아 있는 걸 아는지 모르는지 그냥 날쌔게 물만 움켜 낸다. 그러\n",
            "나, 번번이 허탕이다. 그대로 재미있는 양, 자꾸 물만 움킨다. 어제처럼 개울을 건너는 사\n",
            "람이 있어야 길을 비킬 모양이다.\n",
            "그러다가 소녀가 물 속에서 무엇을 하나 집어 낸다. 하얀 조약돌이었다. 그리고는 벌떡 일\n",
            "어나 팔짝팔짝 징검다리를 뛰어 건너간다.\n",
            "다 건너가더니만 홱 이리로 돌아서며,\n",
            "“이 바보.”\n",
            "조약돌이 날아왔다.\n",
            "소년은 저도 모르게 벌떡 일어섰다.\n",
            "단발 머리를 나풀거리며 소녀가 막 달린다. 갈밭 사잇길로 들어섰다. 뒤에는 청량한 가을 \n",
            "햇살 아래 빛나는 갈꽃뿐.\n",
            "이제 저쯤 갈밭머리로 소녀가 나타나리라. 꽤 오랜 시간이 지났다고 생각됐다. 그런데도 \n",
            "소녀는 나타나지 않는다. 발돋움을 했다. 그러고도 상당한 시간이 지났다고 생각됐다.\n",
            "저 쪽 갈밭머리에 갈꽃이 한 옴큼 움직였다. 소녀가 갈꽃을 안고 있었다. 그리고, 이제는 \n",
            "천천한 걸음이었다. 유난히 맑은 가을 햇살이 소녀의 갈꽃머리에서 반짝거렸다. 소녀 아닌 \n",
            "갈꽃이 들길을 걸어가는 것만 같았다.\n",
            "========\n",
            "\n",
            "[2]누가 말할 것도 아닌데, 바위에 나란히 걸터앉았다. 유달리 주위가 조용해진 것 같았다. 따\n",
            "가운 가을 햇살만이 말라가는 풀 냄새를 퍼뜨리고 있었다.\n",
            "“저건 또 무슨 꽃이지?”\n",
            "적잖이 비탈진 곳에 칡덩굴이 엉키어 꽃을 달고 있었다.\n",
            "“꼭 등꽃 같네. 서울 우리 학교에 큰 등나무가 있었단다. 저 꽃을 보니까 등나무 밑에서 \n",
            "놀던 동무들 생각이 난다.”\n",
            "소녀가 조용히 일어나 비탈진 곳으로 간다. 꽃송이가 많이 달린 줄기를 잡고 끊기 시작한\n",
            "========\n",
            "\n",
            "[3]“멀면 얼마나 멀기에? 서울 있을 땐 사뭇 먼 데까지 소풍 갔었다.”\n",
            "소녀의 눈이 금새 ‘바보,바보,’할 것만 같았다.\n",
            "논 사잇길로 들어섰다. 벼 가을걷이하는 곁을 지났다.\n",
            "허수아비가 서 있었다. 소년이 새끼줄을 흔들었다. 참새가 몇 마리 날아간다. ‘참, 오늘은 \n",
            "일찍 집으로 돌아가 텃논의 참새를 봐야 할걸.’ 하는 생각이 든다.\n",
            "“야, 재밌다!”\n",
            "소녀가 허수아비 줄을 잡더니 흔들어 댄다. 허수아비가 자꾸 우쭐거리며 춤을 춘다. 소녀\n",
            "의 왼쪽 볼에 살포시 보조개가 패었다.\n",
            "저만큼 허수아비가 또 서 있다. 소녀가 그리로 달려간다. 그 뒤를 소년도 달렸다. 오늘 같\n",
            "은 날은 일찍 집으로 돌아가 집안일을 도와야 한다는 생각을 잊어버리기라도 하려는 듯이.\n",
            "소녀의 곁을 스쳐 그냥 달린다. 메뚜기가 따끔따끔 얼굴에 와 부딪친다. 쪽빛으로 한껏 갠 가을 \n",
            "하늘이 소년의 눈앞에서 맴을 돈다. 어지럽다. 저놈의 독수리, 저놈의 독수리, 저놈의 독수리가 \n",
            "맴을 돌고 있기 때문이다.\n",
            "========\n",
            "\n",
            "[4]- 3 -\n",
            "돌아다보니, 소녀는 지금 자기가 지나쳐 온 허수아비를 흔들고 있다. 좀 전 허수아비보다 \n",
            "더 우쭐거린다.\n",
            "논이 끝난 곳에 도랑이 하나 있었다. 소녀가 먼저 뛰어 건넜다.\n",
            "거기서부터 산 밑까지는 밭이었다.\n",
            "수숫단을 세워 놓은 밭머리를 지났다.\n",
            "“저게 뭐니?”\n",
            "“원두막.”\n",
            "“여기 참외, 맛있니?”\n",
            "“그럼, 참외 맛도 좋지만 수박 맛은 더 좋다.”\n",
            "“하나 먹어 봤으면.”\n",
            "소년이 참외 그루에 심은 무우밭으로 들어가, 무우 두 밑을 뽑아 왔다. 아직 밑이 덜 들어 \n",
            "있었다. 잎을 비틀어 팽개친 후, 소녀에게 한개 건넨다. 그리고는 이렇게 먹어야 한다는 듯\n",
            "이, 먼저 대강이를 한 입 베물어 낸 다음, 손톱으로 한 돌이 껍질을 벗겨 우쩍 깨문다.\n",
            "소녀도 따라 했다. 그러나, 세 입도 못 먹고,\n",
            "“아, 맵고 지려.”\n",
            "하며 집어던지고 만다.\n",
            "“참, 맛 없어 못 먹겠다.”\n",
            "소년이 더 멀리 팽개쳐 버렸다.\n",
            "산이 가까워졌다.\n",
            "단풍이 눈에 따가웠다.\n",
            "“야아!”\n",
            "소녀가 산을 향해 달려갔다. 이번은 소년이 뒤따라 달리지 않았다. 그러고도 곧 소녀보다 \n",
            "더 많은 꽃을 꺾었다.\n",
            "“이게 들국화, 이게 싸리꽃, 이게 도라지꽃,…….”\n",
            "“도라지꽃이 이렇게 예쁜 줄은 몰랐네. 난 보랏빛이 좋아!…… 그런데, 이 양산 같이 생긴 \n",
            "노란 꽃이 뭐지?”\n",
            "“마타리꽃.”\n",
            "소녀는 마타리꽃을 양산 받듯이 해 보인다. 약간 상기된 얼굴에 살포시 보조개를 떠올리\n",
            "며.\n",
            "다시 소년은 꽃 한 옴큼을 꺾어 왔다. 싱싱한 꽃가지만 골라 소녀에게 건넨다.\n",
            "그러나 소녀는\n",
            "“하나도 버리지 마라.”\n",
            "산마루께로 올라갔다.\n",
            "맞은편 골짜기에 오순도순 초가집이 몇 모여 있었다.\n",
            "누가 말할 것도 아닌데, 바위에 나란히 걸터앉았다. 유달리 주위가 조용해진 것 같았다. 따\n",
            "가운 가을 햇살만이 말라가는 풀 냄새를 퍼뜨리고 있었다.\n",
            "“저건 또 무슨 꽃이지?”\n",
            "적잖이 비탈진 곳에 칡덩굴이 엉키어 꽃을 달고 있었다.\n",
            "“꼭 등꽃 같네. 서울 우리 학교에 큰 등나무가 있었단다. 저 꽃을 보니까 등나무 밑에서 \n",
            "놀던 동무들 생각이 난다.”\n",
            "========\n",
            "\n",
            "[5]- 7 -\n",
            "나 어쩌나. 가면 소녀를 보게 될까 어떨까.\n",
            "그러다가 까무룩 잠이 들었는가 하는데,\n",
            "“허, 참 세상일도…….”\n",
            "마을 갔던 아버지가 언제 돌아왔는지,\n",
            "“윤 초시 댁도 말이 아니야, 그 많던 전답을 다 팔아 버리고, 대대로 살아오던 집마저 남\n",
            "의 손에 넘기더니, 또 악상까지 당하는걸 보면…….”\n",
            "남폿불 밑에서 바느질감을 안고 있던 어머니가,\n",
            "“증손(曾孫)이라곤 계집애 그 애 하나뿐이었지요?”\n",
            "“그렇지, 사내 애 둘 있던 건 어려서 잃어버리고…….”\n",
            "“어쩌면 그렇게 자식복이 없을까.”\n",
            "“글쎄 말이지. 이번 앤 꽤 여러 날 앓는 걸 약도 변변히 못써 봤다더군. 지금 같아서 윤 \n",
            "초시네도 대가 끊긴 셈이지.……그런데참, 이번 계집앤 어린 것이 여간 잔망스럽지가 않아. \n",
            "글쎄, 죽기전에 이런 말을 했다지 않아? 자기가 죽거든 자기 입던 옷을 꼭그대로 입혀서 \n",
            "묻어 달라고…….”\n",
            "========\n",
            "\n",
            "[1]는지 잘 지지 않는다.”\n",
            "소녀가 분홍 스웨터 앞자락을 내려다본다. 거기에 검붉은 진흙물 같은 게 들어 있었다.\n",
            "소녀가 가만히 보조개를 떠올리며,\n",
            "“그래 이게 무슨 물 같니?”\n",
            "소년은 스웨터 앞자락만 바라보고 있었다.\n",
            "“내, 생각해 냈다. 그 날, 도랑을 건너면서 내가 업힌 일이 있지? 그 때, 네 등에서 옮은 \n",
            "물이다.”\n",
            "소년은 얼굴이 확 달아오름을 느꼈다.\n",
            "갈림길에서 소녀는\n",
            "“저, 오늘 아침에 우리 집에서 대추를 땄다. 낼 제사 지내려고…….”\n",
            "대추 한 줌을 내준다. 소년은 주춤한다.\n",
            "“맛봐라. 우리 증조(曾祖)할아버지가 심었다는데, 아주 달다.”\n",
            "소년은 두 손을 오그려 내밀며,\n",
            "“참, 알도 굵다!”\n",
            "“그리고 저, 우리 이번에 제사 지내고 나서 좀 있다. 집을 내주게 됐다.”\n",
            "========\n",
            "\n",
            "[2]누가 말할 것도 아닌데, 바위에 나란히 걸터앉았다. 유달리 주위가 조용해진 것 같았다. 따\n",
            "가운 가을 햇살만이 말라가는 풀 냄새를 퍼뜨리고 있었다.\n",
            "“저건 또 무슨 꽃이지?”\n",
            "적잖이 비탈진 곳에 칡덩굴이 엉키어 꽃을 달고 있었다.\n",
            "“꼭 등꽃 같네. 서울 우리 학교에 큰 등나무가 있었단다. 저 꽃을 보니까 등나무 밑에서 \n",
            "놀던 동무들 생각이 난다.”\n",
            "소녀가 조용히 일어나 비탈진 곳으로 간다. 꽃송이가 많이 달린 줄기를 잡고 끊기 시작한\n",
            "========\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[벡터저장소]** Chroma DB"
      ],
      "metadata": {
        "id": "7UPZOY7fg9l3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 벡터저장소(Chroma)\n",
        "#!pip install -q chromadb\n",
        "from langchain.document_loaders import PyMuPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, model_name='gpt-4o-mini')\n",
        "embedding_model = OpenAIEmbeddings()\n",
        "db_dir = \"chroma/\"\n",
        "doc_file_path = \"소나기 - 황순원.pdf\"\n",
        "\n",
        "if(os.path.isdir(db_dir) == False):\n",
        "    document = PyMuPDFLoader(doc_file_path).load()\n",
        "\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200,\n",
        "        length_function=len,\n",
        "    )\n",
        "    split_docs = splitter.split_documents(document)\n",
        "    print(f'총 분할된 도큐먼트 수: {len(split_docs)}')\n",
        "\n",
        "    vs = Chroma.from_documents(\n",
        "        split_docs,\n",
        "        embedding_model,\n",
        "        persist_directory = db_dir,\n",
        "        #collection_metadata = {'hnsw:space': 'cosine'}, # 유사도 계산에 코사인 유사도를 사용\n",
        "    )\n",
        "    print(\"saved\")\n",
        "else:\n",
        "    vs = Chroma(persist_directory=db_dir, embedding_function=embedding_model)\n",
        "    print('loaded')\n",
        "\n",
        "query = \"소녀는 왜 이사를 오게 되었는가?\"\n",
        "docs = vs.similarity_search(query, k=2)\n",
        "for index, doc in enumerate(docs, start=1):\n",
        "    print(f'[{index}]\\n' + doc.page_content+ \"\\n========\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qzG6sjsgaAM",
        "outputId": "22d35031-58b6-43b3-dd2b-4936537146c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 분할된 도큐먼트 수: 13\n",
            "saved\n",
            "[1]\n",
            "- 6 -\n",
            "소년은 소녀네가 이사해 오기 전에 벌써 어른들의 이야기를 들어서, 윤 초시 손자(孫子)가 \n",
            "서울서 사업에 실패해 가지고 고향에 돌아오지 않을 수 없게 되었다는 걸 알고 있었다. 그\n",
            "것이 이번에는 고향 집마저 남의 손에 넘기게 된 모양이었다.\n",
            "“왜 그런지 난 이사 가는 게 싫어졌다. 어른들이 하는 일이니 어쩔 수 없지만…….”\n",
            "전에 없이, 소녀의 까만 눈에 쓸쓸한 빛이 떠돌았다.\n",
            "소녀와 헤어져 돌아오는 길에, 소년은 혼잣속으로, 소녀가 이사를 간다는 말을 수없이 되\n",
            "뇌어 보았다. 무어 그리 안타까울 것도 서러울 것도 없었다. 그렇건만, 소년은 지금 자기가 \n",
            "씹고 있는 대추알의 단맛을 모르고 있었다.\n",
            "이 날 밤, 소년은 몰래 덕쇠 할아버지네 호두밭으로 갔다.\n",
            "낯에 봐 두었던 나무로 올라갔다. 그리고, 봐 두었던 가지를 향해 작대기를 내리쳤다. 호두\n",
            "송이 떨어지는 소리가 별나게 크게 들렸다. 가슴이 선뜩했다. 그러나 다음 순간, 굵은 호두\n",
            "야 많이 떨어져라, 많이 떨어져라, 저도 모를 힘에 이끌려 마구 작대기를 내리 치는 것이\n",
            "었다.\n",
            "돌아오는 길에는 열 이틀 달이 지우는 그늘만 골라 디뎠다. 그늘의 고마움을 처음 느꼈다.\n",
            "불룩한 주머니를 어루만졌다. 호두송이를 맨손으로 깠다가는 옴이 오르기 쉽다는 말 같은 건 아\n",
            "무렇지도 않았다. 그저 근동에서 제일 가는 이 덕쇠 할아버지네 호두를 어서 소녀에게 맛보여야 \n",
            "한다는 생각만이 앞섰다.\n",
            "그러다, 아차 하는 생각이 들었다. 소녀더러 병이 좀 낫거들랑 이사 가기 전에 한 번 개울\n",
            "가로 나와 달라는 말을 못해 둔 것이었다. 바보 같은것, 바보 같은것.\n",
            "이튿날, 소년이 학교에서 돌아오니, 아버지가 나들이옷으로 갈아입고 닭 한 마리를 안고 \n",
            "있었다.\n",
            "어디 가시느냐고 물었다.\n",
            "그 말에도 대꾸도 없이, 아버지는 안고 있는 닭의 무게를 겨냥해 보면서,\n",
            "“이만하면 될까?”\n",
            "어머니가 망태기를 내주며,\n",
            "“벌써 며칠째 ‘걀걀’하고 알 날 자리를 보던데요. 크진 않아도살은 쪘을 거여요.”\n",
            "========\n",
            "\n",
            "[2]\n",
            "이튿날, 소년이 학교에서 돌아오니, 아버지가 나들이옷으로 갈아입고 닭 한 마리를 안고 \n",
            "있었다.\n",
            "어디 가시느냐고 물었다.\n",
            "그 말에도 대꾸도 없이, 아버지는 안고 있는 닭의 무게를 겨냥해 보면서,\n",
            "“이만하면 될까?”\n",
            "어머니가 망태기를 내주며,\n",
            "“벌써 며칠째 ‘걀걀’하고 알 날 자리를 보던데요. 크진 않아도살은 쪘을 거여요.”\n",
            "소년이 이번에는 어머니한테 아버지가 어디 가시느냐고 물어 보았다.\n",
            "“저, 서당골 윤 초시 댁에 가신다. 제삿상에라도 놓으시라고…….”\n",
            "“그럼, 큰 놈으로 하나 가져가지. 저 얼룩수탉으로…….”\n",
            "이 말에, 아버지는 허허 웃고 나서,\n",
            "“임마, 그래도 이게 실속이 있다.”\n",
            "소년은 공연히 열적어, 책보를 집어던지고는 외양간으로가, 쇠잔등을 한 번 철썩 갈겼다. \n",
            "쇠파리라도 잡는 체.\n",
            "개울물은 날로 여물어 갔다.\n",
            "소년은 갈림길에서 아래쪽으로 가 보았다. 갈밭머리에서 바라보는 서당골 마을은 쪽빛 하\n",
            "늘 아래 한결 가까워 보였다.\n",
            "어른들의 말이, 내일 소녀네가 양평읍으로 이사 간다는 것이었다. 거기 가서는 조그마한 \n",
            "가겟방을 보게 되리라는 것이었다.\n",
            "소년은 저도 모르게 주머니 속 호두알을 만지작거리며, 한 손으로는 수없이 갈꽃을 휘어 \n",
            "꺾고 있었다.\n",
            "그 날 밤, 소년은 자리에 누워서도 같은 생각뿐이었다. 내일 소녀네가 이사하는 걸 가 보\n",
            "========\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4) Retrieval Chain**"
      ],
      "metadata": {
        "id": "2R7YnSjiOpQa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RetrievalQA** (chain_type=\"stuff\")"
      ],
      "metadata": {
        "id": "KUCHhRx7h9EN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RetrievalQA (chain_type=\"stuff\")\n",
        "# FAISS를 사용했으며 임베딩 결과 저장하지 않음.\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.document_loaders import PyMuPDFLoader\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, model_name='gpt-4o-mini')\n",
        "embeddings = OpenAIEmbeddings()\n",
        "doc_file_path = \"소나기 - 황순원.pdf\"\n",
        "\n",
        "loader = PyMuPDFLoader(doc_file_path)\n",
        "raw_doc = loader.load()\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        "    length_function=len,\n",
        ")\n",
        "\n",
        "split_docs = splitter.split_documents(raw_doc)\n",
        "print(f'총 분할된 도큐먼트 수: {len(split_docs)}')\n",
        "db = FAISS.from_documents(split_docs, embeddings)\n",
        "\n",
        "retriever = db.as_retriever()\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "retriever = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever)\n",
        "\n",
        "query = \"소녀는 왜 이사를 오게 되었는가?\"\n",
        "response = retriever.invoke({\"query\": query})\n",
        "print(response['result'])\n",
        "\n",
        "# RetrievalQA 체인의 실행과정을 모니터링하려면?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbVWDbdHh8Jr",
        "outputId": "a2de047d-a54c-4730-c194-670dfeae7cd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 분할된 도큐먼트 수: 13\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
            "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "----------------\n",
            "- 6 -\n",
            "소년은 소녀네가 이사해 오기 전에 벌써 어른들의 이야기를 들어서, 윤 초시 손자(孫子)가 \n",
            "서울서 사업에 실패해 가지고 고향에 돌아오지 않을 수 없게 되었다는 걸 알고 있었다. 그\n",
            "것이 이번에는 고향 집마저 남의 손에 넘기게 된 모양이었다.\n",
            "“왜 그런지 난 이사 가는 게 싫어졌다. 어른들이 하는 일이니 어쩔 수 없지만…….”\n",
            "전에 없이, 소녀의 까만 눈에 쓸쓸한 빛이 떠돌았다.\n",
            "소녀와 헤어져 돌아오는 길에, 소년은 혼잣속으로, 소녀가 이사를 간다는 말을 수없이 되\n",
            "뇌어 보았다. 무어 그리 안타까울 것도 서러울 것도 없었다. 그렇건만, 소년은 지금 자기가 \n",
            "씹고 있는 대추알의 단맛을 모르고 있었다.\n",
            "이 날 밤, 소년은 몰래 덕쇠 할아버지네 호두밭으로 갔다.\n",
            "낯에 봐 두었던 나무로 올라갔다. 그리고, 봐 두었던 가지를 향해 작대기를 내리쳤다. 호두\n",
            "송이 떨어지는 소리가 별나게 크게 들렸다. 가슴이 선뜩했다. 그러나 다음 순간, 굵은 호두\n",
            "야 많이 떨어져라, 많이 떨어져라, 저도 모를 힘에 이끌려 마구 작대기를 내리 치는 것이\n",
            "었다.\n",
            "돌아오는 길에는 열 이틀 달이 지우는 그늘만 골라 디뎠다. 그늘의 고마움을 처음 느꼈다.\n",
            "불룩한 주머니를 어루만졌다. 호두송이를 맨손으로 깠다가는 옴이 오르기 쉽다는 말 같은 건 아\n",
            "무렇지도 않았다. 그저 근동에서 제일 가는 이 덕쇠 할아버지네 호두를 어서 소녀에게 맛보여야 \n",
            "한다는 생각만이 앞섰다.\n",
            "그러다, 아차 하는 생각이 들었다. 소녀더러 병이 좀 낫거들랑 이사 가기 전에 한 번 개울\n",
            "가로 나와 달라는 말을 못해 둔 것이었다. 바보 같은것, 바보 같은것.\n",
            "이튿날, 소년이 학교에서 돌아오니, 아버지가 나들이옷으로 갈아입고 닭 한 마리를 안고 \n",
            "있었다.\n",
            "어디 가시느냐고 물었다.\n",
            "그 말에도 대꾸도 없이, 아버지는 안고 있는 닭의 무게를 겨냥해 보면서,\n",
            "“이만하면 될까?”\n",
            "어머니가 망태기를 내주며,\n",
            "“벌써 며칠째 ‘걀걀’하고 알 날 자리를 보던데요. 크진 않아도살은 쪘을 거여요.”\n",
            "\n",
            "이튿날, 소년이 학교에서 돌아오니, 아버지가 나들이옷으로 갈아입고 닭 한 마리를 안고 \n",
            "있었다.\n",
            "어디 가시느냐고 물었다.\n",
            "그 말에도 대꾸도 없이, 아버지는 안고 있는 닭의 무게를 겨냥해 보면서,\n",
            "“이만하면 될까?”\n",
            "어머니가 망태기를 내주며,\n",
            "“벌써 며칠째 ‘걀걀’하고 알 날 자리를 보던데요. 크진 않아도살은 쪘을 거여요.”\n",
            "소년이 이번에는 어머니한테 아버지가 어디 가시느냐고 물어 보았다.\n",
            "“저, 서당골 윤 초시 댁에 가신다. 제삿상에라도 놓으시라고…….”\n",
            "“그럼, 큰 놈으로 하나 가져가지. 저 얼룩수탉으로…….”\n",
            "이 말에, 아버지는 허허 웃고 나서,\n",
            "“임마, 그래도 이게 실속이 있다.”\n",
            "소년은 공연히 열적어, 책보를 집어던지고는 외양간으로가, 쇠잔등을 한 번 철썩 갈겼다. \n",
            "쇠파리라도 잡는 체.\n",
            "개울물은 날로 여물어 갔다.\n",
            "소년은 갈림길에서 아래쪽으로 가 보았다. 갈밭머리에서 바라보는 서당골 마을은 쪽빛 하\n",
            "늘 아래 한결 가까워 보였다.\n",
            "어른들의 말이, 내일 소녀네가 양평읍으로 이사 간다는 것이었다. 거기 가서는 조그마한 \n",
            "가겟방을 보게 되리라는 것이었다.\n",
            "소년은 저도 모르게 주머니 속 호두알을 만지작거리며, 한 손으로는 수없이 갈꽃을 휘어 \n",
            "꺾고 있었다.\n",
            "그 날 밤, 소년은 자리에 누워서도 같은 생각뿐이었다. 내일 소녀네가 이사하는 걸 가 보\n",
            "\n",
            "- 1 -\n",
            "소나기\n",
            "황순원\n",
            "소년은 개울가에서 소녀를 보자 곧 윤 초시네 증손녀(曾孫女)딸이라는 걸 알 수 있었다. \n",
            "소녀는 개울에다 손을 잠그고 물장난을 하고 있는 것이다. 서울서는 이런 개울물을 보지 \n",
            "못하기나 한 듯이.\n",
            "벌써 며칠째 소녀는, 학교에서 돌아오는 길에 물장난이었다. 그런데, 어제까지 개울 기슭에\n",
            "서 하더니, 오늘은 징검다리 한가운데 앉아서 하고 있다.\n",
            "소년은 개울둑에 앉아 버렸다. 소녀가 비키기를 기다리자는 것이다.\n",
            "요행 지나가는 사람이 있어, 소녀가 길을 비켜 주었다.\n",
            "다음 날은 좀 늦게 개울가로 나왔다.\n",
            "이 날은 소녀가 징검다리 한가운데 앉아 세수를 하고 있었다. 분홍 스웨터 소매를 걷어올\n",
            "린 목덜미가 마냥 희었다.\n",
            "한참 세수를 하고 나더니, 이번에는 물 속을 빤히 들여다 본다. 얼굴이라도 비추어 보는 \n",
            "것이리라. 갑자기 물을 움켜 낸다. 고기 새끼라도 지나가는 듯.\n",
            "소녀는 소년이 개울둑에 앉아 있는 걸 아는지 모르는지 그냥 날쌔게 물만 움켜 낸다. 그러\n",
            "나, 번번이 허탕이다. 그대로 재미있는 양, 자꾸 물만 움킨다. 어제처럼 개울을 건너는 사\n",
            "람이 있어야 길을 비킬 모양이다.\n",
            "그러다가 소녀가 물 속에서 무엇을 하나 집어 낸다. 하얀 조약돌이었다. 그리고는 벌떡 일\n",
            "어나 팔짝팔짝 징검다리를 뛰어 건너간다.\n",
            "다 건너가더니만 홱 이리로 돌아서며,\n",
            "“이 바보.”\n",
            "조약돌이 날아왔다.\n",
            "소년은 저도 모르게 벌떡 일어섰다.\n",
            "단발 머리를 나풀거리며 소녀가 막 달린다. 갈밭 사잇길로 들어섰다. 뒤에는 청량한 가을 \n",
            "햇살 아래 빛나는 갈꽃뿐.\n",
            "이제 저쯤 갈밭머리로 소녀가 나타나리라. 꽤 오랜 시간이 지났다고 생각됐다. 그런데도 \n",
            "소녀는 나타나지 않는다. 발돋움을 했다. 그러고도 상당한 시간이 지났다고 생각됐다.\n",
            "저 쪽 갈밭머리에 갈꽃이 한 옴큼 움직였다. 소녀가 갈꽃을 안고 있었다. 그리고, 이제는 \n",
            "천천한 걸음이었다. 유난히 맑은 가을 햇살이 소녀의 갈꽃머리에서 반짝거렸다. 소녀 아닌 \n",
            "갈꽃이 들길을 걸어가는 것만 같았다.\n",
            "\n",
            "“멀면 얼마나 멀기에? 서울 있을 땐 사뭇 먼 데까지 소풍 갔었다.”\n",
            "소녀의 눈이 금새 ‘바보,바보,’할 것만 같았다.\n",
            "논 사잇길로 들어섰다. 벼 가을걷이하는 곁을 지났다.\n",
            "허수아비가 서 있었다. 소년이 새끼줄을 흔들었다. 참새가 몇 마리 날아간다. ‘참, 오늘은 \n",
            "일찍 집으로 돌아가 텃논의 참새를 봐야 할걸.’ 하는 생각이 든다.\n",
            "“야, 재밌다!”\n",
            "소녀가 허수아비 줄을 잡더니 흔들어 댄다. 허수아비가 자꾸 우쭐거리며 춤을 춘다. 소녀\n",
            "의 왼쪽 볼에 살포시 보조개가 패었다.\n",
            "저만큼 허수아비가 또 서 있다. 소녀가 그리로 달려간다. 그 뒤를 소년도 달렸다. 오늘 같\n",
            "은 날은 일찍 집으로 돌아가 집안일을 도와야 한다는 생각을 잊어버리기라도 하려는 듯이.\n",
            "소녀의 곁을 스쳐 그냥 달린다. 메뚜기가 따끔따끔 얼굴에 와 부딪친다. 쪽빛으로 한껏 갠 가을 \n",
            "하늘이 소년의 눈앞에서 맴을 돈다. 어지럽다. 저놈의 독수리, 저놈의 독수리, 저놈의 독수리가 \n",
            "맴을 돌고 있기 때문이다.\n",
            "Human: 소녀는 왜 이사를 오게 되었는가?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "소녀는 윤 초시 손자의 사업 실패로 인해 이사를 오게 되었다. 소년은 소녀가 이사 간다는 사실을 알고 있었고, 소녀의 가족이 고향 집마저 남의 손에 넘기게 된 상황을 이해하고 있었다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**로그 활성화**"
      ],
      "metadata": {
        "id": "H4doD_3mOPgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "langchain.debug = False\n",
        "langchain.verbose = False\n",
        "\n",
        "# langchain.verbose 를 True로 설정하여 프롬프트와 retrieval이 반환한 문서 확인 가능"
      ],
      "metadata": {
        "id": "rycJljfROMs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RetrievalQA** (chain_type=\"map_rerank\")"
      ],
      "metadata": {
        "id": "UVsxwc_l6EC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RetrievalQA (chain_type=\"map_rerank\")\n",
        "# FAISS를 사용했으며 임베딩 결과 저장하지 않음\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.document_loaders import PyMuPDFLoader\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, model_name='gpt-4o')\n",
        "embeddings = OpenAIEmbeddings()\n",
        "doc_file_path = \"소나기 - 황순원.pdf\"\n",
        "\n",
        "loader = PyMuPDFLoader(doc_file_path)\n",
        "raw_doc = loader.load()\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        "    length_function=len,\n",
        ")\n",
        "\n",
        "split_docs = splitter.split_documents(raw_doc)\n",
        "print(f'총 분할된 도큐먼트 수: {len(split_docs)}')\n",
        "db = FAISS.from_documents(split_docs, embeddings)\n",
        "\n",
        "retriever = db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 5})\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "retriever = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"map_rerank\",\n",
        "    retriever=retriever)\n",
        "\n",
        "query = \"소녀가 대추를 딴 이유는?\"\n",
        "response = retriever.invoke({\"query\": query})\n",
        "print(response['result'])\n",
        "\n",
        "# 정신없는 로그, 도저히 정리가 안된다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Rcp52na18Te3",
        "outputId": "a227a27e-8ebf-44ac-8177-d830f99d64c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 분할된 도큐먼트 수: 13\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new MapRerankDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
            "\n",
            "Question: [question here]\n",
            "Helpful Answer: [answer here]\n",
            "Score: [score between 0 and 100]\n",
            "\n",
            "How to determine the score:\n",
            "- Higher is a better answer\n",
            "- Better responds fully to the asked question, with sufficient level of detail\n",
            "- If you do not know the answer based on the context, that should be a score of 0\n",
            "- Don't be overconfident!\n",
            "\n",
            "Example #1\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Apples are red\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: red\n",
            "Score: 100\n",
            "\n",
            "Example #2\n",
            "\n",
            "Context:\n",
            "---------\n",
            "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
            "---------\n",
            "Question: what type was the car?\n",
            "Helpful Answer: a sports car or an suv\n",
            "Score: 60\n",
            "\n",
            "Example #3\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Pears are either red or orange\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: This document does not answer the question\n",
            "Score: 0\n",
            "\n",
            "Begin!\n",
            "\n",
            "Context:\n",
            "---------\n",
            "- 6 -\n",
            "소년은 소녀네가 이사해 오기 전에 벌써 어른들의 이야기를 들어서, 윤 초시 손자(孫子)가 \n",
            "서울서 사업에 실패해 가지고 고향에 돌아오지 않을 수 없게 되었다는 걸 알고 있었다. 그\n",
            "것이 이번에는 고향 집마저 남의 손에 넘기게 된 모양이었다.\n",
            "“왜 그런지 난 이사 가는 게 싫어졌다. 어른들이 하는 일이니 어쩔 수 없지만…….”\n",
            "전에 없이, 소녀의 까만 눈에 쓸쓸한 빛이 떠돌았다.\n",
            "소녀와 헤어져 돌아오는 길에, 소년은 혼잣속으로, 소녀가 이사를 간다는 말을 수없이 되\n",
            "뇌어 보았다. 무어 그리 안타까울 것도 서러울 것도 없었다. 그렇건만, 소년은 지금 자기가 \n",
            "씹고 있는 대추알의 단맛을 모르고 있었다.\n",
            "이 날 밤, 소년은 몰래 덕쇠 할아버지네 호두밭으로 갔다.\n",
            "낯에 봐 두었던 나무로 올라갔다. 그리고, 봐 두었던 가지를 향해 작대기를 내리쳤다. 호두\n",
            "송이 떨어지는 소리가 별나게 크게 들렸다. 가슴이 선뜩했다. 그러나 다음 순간, 굵은 호두\n",
            "야 많이 떨어져라, 많이 떨어져라, 저도 모를 힘에 이끌려 마구 작대기를 내리 치는 것이\n",
            "었다.\n",
            "돌아오는 길에는 열 이틀 달이 지우는 그늘만 골라 디뎠다. 그늘의 고마움을 처음 느꼈다.\n",
            "불룩한 주머니를 어루만졌다. 호두송이를 맨손으로 깠다가는 옴이 오르기 쉽다는 말 같은 건 아\n",
            "무렇지도 않았다. 그저 근동에서 제일 가는 이 덕쇠 할아버지네 호두를 어서 소녀에게 맛보여야 \n",
            "한다는 생각만이 앞섰다.\n",
            "그러다, 아차 하는 생각이 들었다. 소녀더러 병이 좀 낫거들랑 이사 가기 전에 한 번 개울\n",
            "가로 나와 달라는 말을 못해 둔 것이었다. 바보 같은것, 바보 같은것.\n",
            "이튿날, 소년이 학교에서 돌아오니, 아버지가 나들이옷으로 갈아입고 닭 한 마리를 안고 \n",
            "있었다.\n",
            "어디 가시느냐고 물었다.\n",
            "그 말에도 대꾸도 없이, 아버지는 안고 있는 닭의 무게를 겨냥해 보면서,\n",
            "“이만하면 될까?”\n",
            "어머니가 망태기를 내주며,\n",
            "“벌써 며칠째 ‘걀걀’하고 알 날 자리를 보던데요. 크진 않아도살은 쪘을 거여요.”\n",
            "---------\n",
            "Question: 소녀는 왜 이사를 오게 되었는가?\n",
            "Helpful Answer:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
            "\n",
            "Question: [question here]\n",
            "Helpful Answer: [answer here]\n",
            "Score: [score between 0 and 100]\n",
            "\n",
            "How to determine the score:\n",
            "- Higher is a better answer\n",
            "- Better responds fully to the asked question, with sufficient level of detail\n",
            "- If you do not know the answer based on the context, that should be a score of 0\n",
            "- Don't be overconfident!\n",
            "\n",
            "Example #1\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Apples are red\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: red\n",
            "Score: 100\n",
            "\n",
            "Example #2\n",
            "\n",
            "Context:\n",
            "---------\n",
            "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
            "---------\n",
            "Question: what type was the car?\n",
            "Helpful Answer: a sports car or an suv\n",
            "Score: 60\n",
            "\n",
            "Example #3\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Pears are either red or orange\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: This document does not answer the question\n",
            "Score: 0\n",
            "\n",
            "Begin!\n",
            "\n",
            "Context:\n",
            "---------\n",
            "누가 말할 것도 아닌데, 바위에 나란히 걸터앉았다. 유달리 주위가 조용해진 것 같았다. 따\n",
            "가운 가을 햇살만이 말라가는 풀 냄새를 퍼뜨리고 있었다.\n",
            "“저건 또 무슨 꽃이지?”\n",
            "적잖이 비탈진 곳에 칡덩굴이 엉키어 꽃을 달고 있었다.\n",
            "“꼭 등꽃 같네. 서울 우리 학교에 큰 등나무가 있었단다. 저 꽃을 보니까 등나무 밑에서 \n",
            "놀던 동무들 생각이 난다.”\n",
            "소녀가 조용히 일어나 비탈진 곳으로 간다. 꽃송이가 많이 달린 줄기를 잡고 끊기 시작한\n",
            "---------\n",
            "Question: 소녀는 왜 이사를 오게 되었는가?\n",
            "Helpful Answer:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
            "\n",
            "Question: [question here]\n",
            "Helpful Answer: [answer here]\n",
            "Score: [score between 0 and 100]\n",
            "\n",
            "How to determine the score:\n",
            "- Higher is a better answer\n",
            "- Better responds fully to the asked question, with sufficient level of detail\n",
            "- If you do not know the answer based on the context, that should be a score of 0\n",
            "- Don't be overconfident!\n",
            "\n",
            "Example #1\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Apples are red\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: red\n",
            "Score: 100\n",
            "\n",
            "Example #2\n",
            "\n",
            "Context:\n",
            "---------\n",
            "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
            "---------\n",
            "Question: what type was the car?\n",
            "Helpful Answer: a sports car or an suv\n",
            "Score: 60\n",
            "\n",
            "Example #3\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Pears are either red or orange\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: This document does not answer the question\n",
            "Score: 0\n",
            "\n",
            "Begin!\n",
            "\n",
            "Context:\n",
            "---------\n",
            "“멀면 얼마나 멀기에? 서울 있을 땐 사뭇 먼 데까지 소풍 갔었다.”\n",
            "소녀의 눈이 금새 ‘바보,바보,’할 것만 같았다.\n",
            "논 사잇길로 들어섰다. 벼 가을걷이하는 곁을 지났다.\n",
            "허수아비가 서 있었다. 소년이 새끼줄을 흔들었다. 참새가 몇 마리 날아간다. ‘참, 오늘은 \n",
            "일찍 집으로 돌아가 텃논의 참새를 봐야 할걸.’ 하는 생각이 든다.\n",
            "“야, 재밌다!”\n",
            "소녀가 허수아비 줄을 잡더니 흔들어 댄다. 허수아비가 자꾸 우쭐거리며 춤을 춘다. 소녀\n",
            "의 왼쪽 볼에 살포시 보조개가 패었다.\n",
            "저만큼 허수아비가 또 서 있다. 소녀가 그리로 달려간다. 그 뒤를 소년도 달렸다. 오늘 같\n",
            "은 날은 일찍 집으로 돌아가 집안일을 도와야 한다는 생각을 잊어버리기라도 하려는 듯이.\n",
            "소녀의 곁을 스쳐 그냥 달린다. 메뚜기가 따끔따끔 얼굴에 와 부딪친다. 쪽빛으로 한껏 갠 가을 \n",
            "하늘이 소년의 눈앞에서 맴을 돈다. 어지럽다. 저놈의 독수리, 저놈의 독수리, 저놈의 독수리가 \n",
            "맴을 돌고 있기 때문이다.\n",
            "---------\n",
            "Question: 소녀는 왜 이사를 오게 되었는가?\n",
            "Helpful Answer:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
            "\n",
            "Question: [question here]\n",
            "Helpful Answer: [answer here]\n",
            "Score: [score between 0 and 100]\n",
            "\n",
            "How to determine the score:\n",
            "- Higher is a better answer\n",
            "- Better responds fully to the asked question, with sufficient level of detail\n",
            "- If you do not know the answer based on the context, that should be a score of 0\n",
            "- Don't be overconfident!\n",
            "\n",
            "Example #1\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Apples are red\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: red\n",
            "Score: 100\n",
            "\n",
            "Example #2\n",
            "\n",
            "Context:\n",
            "---------\n",
            "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
            "---------\n",
            "Question: what type was the car?\n",
            "Helpful Answer: a sports car or an suv\n",
            "Score: 60\n",
            "\n",
            "Example #3\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Pears are either red or orange\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: This document does not answer the question\n",
            "Score: 0\n",
            "\n",
            "Begin!\n",
            "\n",
            "Context:\n",
            "---------\n",
            "소녀는 나타나지 않는다. 발돋움을 했다. 그러고도 상당한 시간이 지났다고 생각됐다.\n",
            "저 쪽 갈밭머리에 갈꽃이 한 옴큼 움직였다. 소녀가 갈꽃을 안고 있었다. 그리고, 이제는 \n",
            "천천한 걸음이었다. 유난히 맑은 가을 햇살이 소녀의 갈꽃머리에서 반짝거렸다. 소녀 아닌 \n",
            "갈꽃이 들길을 걸어가는 것만 같았다.\n",
            "소년은 이 갈꽃이 아주 뵈지 않게 되기까지 그대로 서 있었다. 문득, 소녀가 던지 조약돌\n",
            "을 내려다보았다. 물기가 걷혀 있었다. 소년은 조약돌을 집어 주머니에 넣었다.\n",
            "다음 날부터 좀더 늦게 개울가로 나왔다. 소녀의 그림자가 뵈지 않았다. 다행이었다.\n",
            "그러나, 이상한 일이었다. 소녀의 그림자가 뵈지 않는 날이 계속될수록 소년의 가슴 한 구\n",
            "석에는 어딘가 허전함이 자리 잡는 것이었다. 주머니 속 조약돌을 주무르는 버릇이 생겼\n",
            "다.\n",
            "그러한 어떤 날, 소년은 전에 소녀가 앉아 물장난을 하던 징검다리 한가운데에 앉아 보았\n",
            "다. 물 속에 손을 잠갔다. 세수를 하였다. 물 속을 들여다보았다. 검게 탄 얼굴이 그대로 \n",
            "비치었다. 싫었다.\n",
            "---------\n",
            "Question: 소녀는 왜 이사를 오게 되었는가?\n",
            "Helpful Answer:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
            "\n",
            "Question: [question here]\n",
            "Helpful Answer: [answer here]\n",
            "Score: [score between 0 and 100]\n",
            "\n",
            "How to determine the score:\n",
            "- Higher is a better answer\n",
            "- Better responds fully to the asked question, with sufficient level of detail\n",
            "- If you do not know the answer based on the context, that should be a score of 0\n",
            "- Don't be overconfident!\n",
            "\n",
            "Example #1\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Apples are red\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: red\n",
            "Score: 100\n",
            "\n",
            "Example #2\n",
            "\n",
            "Context:\n",
            "---------\n",
            "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
            "---------\n",
            "Question: what type was the car?\n",
            "Helpful Answer: a sports car or an suv\n",
            "Score: 60\n",
            "\n",
            "Example #3\n",
            "\n",
            "Context:\n",
            "---------\n",
            "Pears are either red or orange\n",
            "---------\n",
            "Question: what color are apples?\n",
            "Helpful Answer: This document does not answer the question\n",
            "Score: 0\n",
            "\n",
            "Begin!\n",
            "\n",
            "Context:\n",
            "---------\n",
            "는지 잘 지지 않는다.”\n",
            "소녀가 분홍 스웨터 앞자락을 내려다본다. 거기에 검붉은 진흙물 같은 게 들어 있었다.\n",
            "소녀가 가만히 보조개를 떠올리며,\n",
            "“그래 이게 무슨 물 같니?”\n",
            "소년은 스웨터 앞자락만 바라보고 있었다.\n",
            "“내, 생각해 냈다. 그 날, 도랑을 건너면서 내가 업힌 일이 있지? 그 때, 네 등에서 옮은 \n",
            "물이다.”\n",
            "소년은 얼굴이 확 달아오름을 느꼈다.\n",
            "갈림길에서 소녀는\n",
            "“저, 오늘 아침에 우리 집에서 대추를 땄다. 낼 제사 지내려고…….”\n",
            "대추 한 줌을 내준다. 소년은 주춤한다.\n",
            "“맛봐라. 우리 증조(曾祖)할아버지가 심었다는데, 아주 달다.”\n",
            "소년은 두 손을 오그려 내밀며,\n",
            "“참, 알도 굵다!”\n",
            "“그리고 저, 우리 이번에 제사 지내고 나서 좀 있다. 집을 내주게 됐다.”\n",
            "---------\n",
            "Question: 소녀는 왜 이사를 오게 되었는가?\n",
            "Helpful Answer:\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:369: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Helpful Answer: 윤 초시 손자가 서울에서 사업에 실패해 고향으로 돌아오게 되었기 때문이다.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'query = \"소녀가 대추를 딴 이유는?\"\\nresponse = retriever.invoke({\"query\": query})\\nprint(response[\\'result\\'])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LangSmith 를 이용한 모니터링\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"chain-monitor\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"]=\"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\" # <= 자신의 API키로 바꾸세요\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"  # true 이면 계속 모니터링 됩니다. 그만 하려면 false 로 바꾸세요"
      ],
      "metadata": {
        "id": "lNfe7AlzKuhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LangSmith 를 이용한 모니터링\n",
        "# RetrievalQA (chain_type=\"stuff\")\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, model_name='gpt-4o-mini')\n",
        "embeddings = OpenAIEmbeddings()\n",
        "doc_file_path = \"소나기 - 황순원.pdf\"\n",
        "\n",
        "loader = PyMuPDFLoader(doc_file_path)\n",
        "raw_doc = loader.load()\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        "    length_function=len,\n",
        ")\n",
        "\n",
        "split_docs = splitter.split_documents(raw_doc)\n",
        "print(f'총 분할된 도큐먼트 수: {len(split_docs)}')\n",
        "db = FAISS.from_documents(split_docs, embeddings)\n",
        "\n",
        "retriever = db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 5}) # <= k값의 중요성\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "retriever = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever)\n",
        "\n",
        "query = \"소설 끝에서 소녀는 어떠한 결말을 맞이한거야?\"\n",
        "response = retriever.invoke({\"query\": query})\n",
        "print(response['result'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzkzcWVp9uTb",
        "outputId": "0e8b1b4c-75f5-409c-e338-6273970f96cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 분할된 도큐먼트 수: 13\n",
            "소설의 끝에서 소녀는 아프고, 결국 죽음을 맞이하게 됩니다. 그녀의 가족은 그녀가 어린 나이에 잃어버린 것에 대해 안타까워하며, 그녀의 마지막 소원인 입던 옷을 그대로 입혀서 묻어 달라는 이야기를 나누는 장면이 있습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**프롬프트 변형과 관련한 실습**"
      ],
      "metadata": {
        "id": "PfaAJwAY4yV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 보너스: 검증된 프롬프트 가져오기\n",
        "from langchain import hub\n",
        "import pprint\n",
        "\n",
        "prompt = hub.pull(\"rlm/rag-prompt\", api_url=\"https://api.hub.langchain.com\")\n",
        "\n",
        "# 프롬프트 내용 출력\n",
        "pprint.pp(prompt.messages[0].prompt.__dict__, indent=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLmrJciqe3JL",
        "outputId": "d59fe07b-7a43-4746-c321-03c4f4012445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{   'name': None,\n",
            "    'input_variables': ['context', 'question'],\n",
            "    'optional_variables': [],\n",
            "    'input_types': {},\n",
            "    'output_parser': None,\n",
            "    'partial_variables': {},\n",
            "    'metadata': None,\n",
            "    'tags': None,\n",
            "    'template': 'You are an assistant for question-answering tasks. Use the '\n",
            "                'following pieces of retrieved context to answer the question. '\n",
            "                \"If you don't know the answer, just say that you don't know. \"\n",
            "                'Use three sentences maximum and keep the answer concise.\\n'\n",
            "                'Question: {question} \\n'\n",
            "                'Context: {context} \\n'\n",
            "                'Answer:',\n",
            "    'template_format': 'f-string',\n",
            "    'validate_template': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LCEL(LangChain Expression Language) 버전1\n",
        "# rlm/rag-prompt 프롬프트 사용\n",
        "from operator import itemgetter\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_community.vectorstores.utils import DistanceStrategy\n",
        "from langchain import hub\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, model_name='gpt-4o-mini')\n",
        "embeddings = OpenAIEmbeddings()\n",
        "doc_file_path = \"소나기 - 황순원.pdf\"\n",
        "\n",
        "loader = PyMuPDFLoader(doc_file_path)\n",
        "raw_doc = loader.load()\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        "    length_function=len,\n",
        ")\n",
        "\n",
        "split_docs = splitter.split_documents(raw_doc)\n",
        "print(f'총 분할된 도큐먼트 수: {len(split_docs)}')\n",
        "db = FAISS.from_documents(split_docs, embeddings)\n",
        "print(f\"{db.distance_strategy}\\n\")\n",
        "\n",
        "retriever = db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 5})\n",
        "\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")  # langchainhub에서 검증된 prompt를 가져옴.\n",
        "\n",
        "model = ChatOpenAI(model_name='gpt-4o-mini', temperature=0)\n",
        "\n",
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "query = \"소설 끝에서 소녀는 어떠한 결말을 맞이한거야? 근거를 찾아 설명해줘\"\n",
        "response = chain.invoke(query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKaxyGQEVb_W",
        "outputId": "074ffaf0-d097-4b7d-87bd-143334f9927e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 분할된 도큐먼트 수: 13\n",
            "EUCLIDEAN_DISTANCE\n",
            "\n",
            "소설 \"소나기\"에서 소녀는 결국 죽음을 맞이하게 됩니다. 그녀는 아프고, 죽기 전에 자신의 입던 옷을 그대로 입혀서 묻어 달라고 부탁하는 장면이 있습니다. 이는 소녀의 비극적인 결말을 암시하며, 그녀의 삶이 짧고 잔망스러웠음을 보여줍니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LCEL(LangChain Expression Language) 버전2\n",
        "# Prompt를 직접 설계하는 방법\n",
        "from operator import itemgetter\n",
        "\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.callbacks.tracers import ConsoleCallbackHandler\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, model_name='gpt-4o-mini')\n",
        "embeddings = OpenAIEmbeddings()\n",
        "doc_file_path = \"소나기 - 황순원.pdf\"\n",
        "\n",
        "loader = PyMuPDFLoader(doc_file_path)\n",
        "raw_doc = loader.load()\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        "    length_function=len,\n",
        ")\n",
        "\n",
        "split_docs = splitter.split_documents(raw_doc)\n",
        "print(f'총 분할된 도큐먼트 수: {len(split_docs)}')\n",
        "db = FAISS.from_documents(split_docs, embeddings)\n",
        "print(f\"{db.distance_strategy}\\n\")\n",
        "\n",
        "retriever = db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 5})\n",
        "\n",
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "model = ChatOpenAI(model_name='gpt-4o', temperature=0)\n",
        "\n",
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(chain.invoke(\"소설 끝에서 소녀가 어떠한 결말을 맞이한거야? 근거를 찾아 설명해줘\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XyYL7R3cgQo",
        "outputId": "988e97e8-f448-4e31-8375-59d5cdb0fe57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 분할된 도큐먼트 수: 13\n",
            "EUCLIDEAN_DISTANCE\n",
            "\n",
            "소설의 끝에서 소녀는 죽음을 맞이합니다. 이 결말은 다음과 같은 문장들에서 확인할 수 있습니다:\n",
            "\n",
            "1. \"윤 초시 댁도 말이 아니야, 그 많던 전답을 다 팔아 버리고, 대대로 살아오던 집마저 남의 손에 넘기더니, 또 악상까지 당하는걸 보면…….\"\n",
            "2. \"증손(曾孫)이라곤 계집애 그 애 하나뿐이었지요?\"\n",
            "3. \"그렇지, 사내 애 둘 있던 건 어려서 잃어버리고…….\"\n",
            "4. \"글쎄 말이지. 이번 앤 꽤 여러 날 앓는 걸 약도 변변히 못써 봤다더군. 지금 같아서 윤 초시네도 대가 끊긴 셈이지.……그런데참, 이번 계집앤 어린 것이 여간 잔망스럽지가 않아. 글쎄, 죽기전에 이런 말을 했다지 않아? 자기가 죽거든 자기 입던 옷을 꼭그대로 입혀서 묻어 달라고…….\"\n",
            "\n",
            "이 문장들에서 소녀가 병으로 여러 날 앓다가 결국 죽음을 맞이했음을 알 수 있습니다. 특히, \"죽기전에 이런 말을 했다지 않아? 자기가 죽거든 자기 입던 옷을 꼭그대로 입혀서 묻어 달라고…….\"라는 문장은 소녀가 죽기 전에 자신의 장례에 대해 언급한 것을 나타내고 있습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **[LangChain]　5. Agent**"
      ],
      "metadata": {
        "id": "uTNxCKs_PEkw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agent의 작동원리 ReAct 개념 예제"
      ],
      "metadata": {
        "id": "Xh1CFmL1bCN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ReAct: Synergizing Reasoning and Acting in Language Models 논문에 소개한 메커너즘으로 작동\n",
        "# (https://react-lm.github.io)\n",
        "import langchain\n",
        "langchain.verbose = True\n",
        "\n",
        "import pprint\n",
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor, create_react_agent, load_tools\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "tools = load_tools([\"terminal\"], allow_dangerous_tools=True)\n",
        "\n",
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "pprint.pp(prompt.template, indent=4, width=100)  # <=\n",
        "\n",
        "agent = create_react_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "result = agent_executor.invoke({\"input\": \"sample_data 디렉터리에 있는 파일 목록을 알려줘\"})\n",
        "print(result[\"output\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SymzTLXPMSr",
        "outputId": "7f67bd79-cf5f-4711-ad64-6c788b45e255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Answer the following questions as best you can. You have access to the following tools:\\n'\n",
            " '\\n'\n",
            " '{tools}\\n'\n",
            " '\\n'\n",
            " 'Use the following format:\\n'\n",
            " '\\n'\n",
            " 'Question: the input question you must answer\\n'\n",
            " 'Thought: you should always think about what to do\\n'\n",
            " 'Action: the action to take, should be one of [{tool_names}]\\n'\n",
            " 'Action Input: the input to the action\\n'\n",
            " 'Observation: the result of the action\\n'\n",
            " '... (this Thought/Action/Action Input/Observation can repeat N times)\\n'\n",
            " 'Thought: I now know the final answer\\n'\n",
            " 'Final Answer: the final answer to the original input question\\n'\n",
            " '\\n'\n",
            " 'Begin!\\n'\n",
            " '\\n'\n",
            " 'Question: {input}\\n'\n",
            " 'Thought:{agent_scratchpad}')\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to check the contents of the \"sample_data\" directory to list the files it contains. I'll use the terminal to do this.\n",
            "\n",
            "Action: terminal  \n",
            "Action Input: ls sample_data  \u001b[0mExecuting command:\n",
            " ls sample_data\n",
            "\u001b[36;1m\u001b[1;3manscombe.json\n",
            "california_housing_test.csv\n",
            "california_housing_train.csv\n",
            "mnist_test.csv\n",
            "mnist_train_small.csv\n",
            "README.md\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_community/tools/shell/tool.py:32: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mI now know the final answer, which is the list of files in the \"sample_data\" directory.  \n",
            "Final Answer: The files in the \"sample_data\" directory are: anscombe.json, california_housing_test.csv, california_housing_train.csv, mnist_test.csv, mnist_train_small.csv, README.md.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The files in the \"sample_data\" directory are: anscombe.json, california_housing_test.csv, california_housing_train.csv, mnist_test.csv, mnist_train_small.csv, README.md.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# openai_functions_agent (Deprecated)\n",
        "from langchain.agents import load_tools\n",
        "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "tools = load_tools([\"ddg-search\"])\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "\n",
        "agent = create_openai_functions_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "result = agent_executor.invoke({\"input\": \"서울과 부산의 날씨를 알려줘\"})\n",
        "print(result[\"output\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsaaimTO4LDT",
        "outputId": "023aca6d-1ed7-4876-f1e7-c1d2bc8c4a9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `duckduckgo_search` with `{'query': '서울 부산 날씨'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m날씨, 2024년 장마기간→'서울·수도권 80mm비' 3호태풍 개미 예상경로. 주요 기사. 날씨, 3호 태풍영향→'34도 폭염' 2024년 장마기간→서울 80mm비 예상경로 [속보] 부산날씨→호우주의보, 온천천산책로 '전면통제' 천둥번개 ... 부산 주간 날씨 예보 / 네이버 도로공사는 이번 주말, 일부 지역 눈, 비 예보에 도로 살얼음 주의를 당부했다. 특히 교량과 터널 입·출구, 음지 커브길은 미끄럼 사고에 취약한 구간이므로 급제동과 급가속은 삼가고 제동 시 브레이크를 나눠 밟는 것이 좋겠다. (서울=연합뉴스) 박형빈 기자 = 일요일인 5일은 전국이 흐리고 비가 오겠다. ... 날씨 역주행 (부산=연합뉴스) 손형주 기자 = 늦더위가 기승을 부리고 있는 3일 부산 해운대구 송정해수욕장에서 시민들이 해안가에서 더위를 식히고 있다. 2023.11.3 handbrother@yna.co.kr ... 이번주 '주말날씨' 예보에 관심이 쏠리고 있다. 19일 기상청은 전국·서울·부산·대구·제주 주말날씨를 발표했다.20일 주말 아침부터 제주와 전남을 ... [날씨] 설 연휴까지 먼지↑…낮 서울 4℃ · 부산 9℃ ... 서울특별시 양천구 목동서로 161; 고객센터 : 1577-1003; Email : newsservice@sbs.co.kr;\u001b[0m\u001b[32;1m\u001b[1;3m현재 서울과 부산의 날씨는 다음과 같습니다:\n",
            "\n",
            "- **서울**: 흐리고 비가 오는 날씨입니다. 기온은 낮에 약 4도 정도로 예상됩니다.\n",
            "- **부산**: 호우주의보가 발효 중이며, 기온은 낮에 약 9도 정도로 예상됩니다. \n",
            "\n",
            "추가적으로, 부산에서는 천둥과 번개가 동반될 수 있으니 주의가 필요합니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "현재 서울과 부산의 날씨는 다음과 같습니다:\n",
            "\n",
            "- **서울**: 흐리고 비가 오는 날씨입니다. 기온은 낮에 약 4도 정도로 예상됩니다.\n",
            "- **부산**: 호우주의보가 발효 중이며, 기온은 낮에 약 9도 정도로 예상됩니다. \n",
            "\n",
            "추가적으로, 부산에서는 천둥과 번개가 동반될 수 있으니 주의가 필요합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# openai_tools_agent\n",
        "from langchain.agents import load_tools\n",
        "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "tools = load_tools([\"ddg-search\"])\n",
        "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
        "\n",
        "agent = create_openai_tools_agent(llm, tools, prompt)  # <=\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "result = agent_executor.invoke({\"input\": \"지금 이 시각 서울과 부산의 날씨를 알려줘\"})\n",
        "print(result[\"output\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eidrscupYoPC",
        "outputId": "aaa0b4d4-b2fd-4116-ace4-962190995807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `duckduckgo_search` with `{'query': 'current weather in Seoul'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mSeoul Weather Forecasts. Weather Underground provides local & long-range weather forecasts, weatherreports, maps & tropical weather conditions for the Seoul area. Fri. Updated 7/24 9:47 AM. The hourly local weather forecast shows hour by hour weather conditions like temperature, feels like temperature, humidity, amount of precipitation and chance of precipitation, wind and gusts for Seoul. Anyang-si. 91 °F / 79 °F. Uijeongbu-si. 91 °F / 78 °F. Gwangmyeong. 90 °F / 77 °F. Today's and tonight's professional weather forecast for Seoul. Precipitation radar, HD satellite images, and current weather warnings, hourly temperature, chance of rain, and sunshine hours. Weather Today Weather Hourly 14 Day Forecast Yesterday/Past Weather Climate (Averages) Now. 70 °F. Clear. Feels Like: 70 °F Forecast: 74 / 64 °F Wind: 5 mph ↑ from West. Location: Seoul / Kimp'O International Airport. Current Time: Jun 7, 2024 at 9:51:33 pm. Stay updated on Seoul's weather with real-time forecasts, temperature, humidity, and wind information. South Korea Weather. Seoul. Incheon; Busan; Daegu; Gwangju; Gyeongsangnam-do; ... Seoul, South Korea Weather. Current: 29.92°C/85.86°F, Wind SW at 11.45 km/h, 69% Humidity, 53% Chance of rain. Seoul, South Korea Weather; Current conditions;\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `duckduckgo_search` with `{'query': 'current weather in Busan'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mBusan Weather Forecasts. Weather Underground provides local & long-range weather forecasts, weatherreports, maps & tropical weather conditions for the Busan area. Today's and tonight's Busan, South Korea weather forecast, weather conditions and Doppler radar from The Weather Channel and Weather.com Weather report for Busan. On Thursday a few clouds are expected. It is a sunny day. Temperatures peaking at 87 °F. With UV-Index rising to 9, sun protection is strongly recommended. Until noon blows a light breeze (4 to 8 mph). In the afternoon a gentle breeze is expected (8 to 12 mph). Winds blowing overnight from Southwest and by day from South. South Korea. Busan. Busan Weather Forecast. Providing a local hourly Busan weather forecast of rain, sun, wind, humidity and temperature. The Long-range 12 day forecast also includes detail for Busan weather today. Live weather reports from Busan weather stations and weather warnings that include risk of thunder, high UV index and forecast gales. In Busan, at the moment, the sky is mainly clouded. The temperature is a hot 32°C (89.6°F), while the apparent temperature, which combines air temperature and relative humidity, is evaluated at a sweltering 38°C (100.4°F).The current temperature is the maximum anticipated temperature for today.\u001b[0m\u001b[32;1m\u001b[1;3m현재 서울과 부산의 날씨는 다음과 같습니다:\n",
            "\n",
            "### 서울\n",
            "- **온도**: 29.9°C (85.8°F)\n",
            "- **습도**: 69%\n",
            "- **바람**: 서남서쪽에서 시속 11.45 km/h\n",
            "- **강수 확률**: 53%\n",
            "- **상태**: 맑음\n",
            "\n",
            "### 부산\n",
            "- **온도**: 32°C (89.6°F)\n",
            "- **체감 온도**: 38°C (100.4°F)\n",
            "- **상태**: 주로 흐림\n",
            "- **바람**: 남쪽에서 불고 있으며, 오후에는 부드러운 바람이 예상됨\n",
            "\n",
            "두 도시 모두 더운 날씨를 보이고 있으며, 부산은 특히 체감 온도가 높습니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "현재 서울과 부산의 날씨는 다음과 같습니다:\n",
            "\n",
            "### 서울\n",
            "- **온도**: 29.9°C (85.8°F)\n",
            "- **습도**: 69%\n",
            "- **바람**: 서남서쪽에서 시속 11.45 km/h\n",
            "- **강수 확률**: 53%\n",
            "- **상태**: 맑음\n",
            "\n",
            "### 부산\n",
            "- **온도**: 32°C (89.6°F)\n",
            "- **체감 온도**: 38°C (100.4°F)\n",
            "- **상태**: 주로 흐림\n",
            "- **바람**: 남쪽에서 불고 있으며, 오후에는 부드러운 바람이 예상됨\n",
            "\n",
            "두 도시 모두 더운 날씨를 보이고 있으며, 부산은 특히 체감 온도가 높습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 에이전트/툴\n",
        "#!pip install -q google-search-results numexpr\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain import hub\n",
        "llm = ChatOpenAI(temperature=0, model_name='gpt-4o')\n",
        "\n",
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "from langchain.agents import create_openai_tools_agent, AgentExecutor\n",
        "\n",
        "tools = load_tools([\"ddg-search\", \"wikipedia\"], llm=llm)   # 도구 추가함\n",
        "\n",
        "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
        "agent = create_openai_tools_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "result=agent_executor.invoke({\"input\": \"너는 누구니?\"})\n",
        "print(result['output'])\n",
        "\n",
        "result=agent_executor.invoke({\"input\": \"사람도 동물이야?\"})\n",
        "print(result['output'])\n",
        "\n",
        "result=agent_executor.invoke({\"input\": \"4옥타브 '도'음의 주파수는 440*2^(3/12) 입니다. 구체적인 수치는?\"})\n",
        "print(result['output'])\n",
        "\n",
        "result=agent_executor.invoke({\"input\": \"라인야후의 소유주는 누구?\"})\n",
        "print(result['output'])\n",
        "\n",
        "result=agent_executor.invoke({\"input\": \"연이율 6%일 때 한달에 얼마씩 저금해야 10년만에 1억을 만들수 있을까?\"})\n",
        "print(result['output'])\n",
        "\n",
        "result=agent_executor.invoke({\"input\": \"2024년도 현재 에드 시런은 몇 살?\"})\n",
        "print(result['output'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK3EjJE-AxB_",
        "outputId": "de731bf7-28ff-4eda-d439-97d60079902f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m저는 여러분의 질문에 답하고 다양한 작업을 도와드리는 인공지능 어시스턴트입니다. 무엇을 도와드릴까요?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "저는 여러분의 질문에 답하고 다양한 작업을 도와드리는 인공지능 어시스턴트입니다. 무엇을 도와드릴까요?\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m네, 사람도 동물입니다. 사람은 동물계에 속하는 포유류입니다. 생물학적으로 사람은 영장류에 속하며, 특히 호미니드과에 속하는 종입니다. 따라서 사람도 동물의 일종으로 분류됩니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "네, 사람도 동물입니다. 사람은 동물계에 속하는 포유류입니다. 생물학적으로 사람은 영장류에 속하며, 특히 호미니드과에 속하는 종입니다. 따라서 사람도 동물의 일종으로 분류됩니다.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m4옥타브 '도'음의 주파수를 구하기 위해 주어진 공식을 사용하면 됩니다. 주어진 공식은:\n",
            "\n",
            "\\[ f = 440 \\times 2^{\\frac{3}{12}} \\]\n",
            "\n",
            "이 공식을 계산해 보겠습니다.\n",
            "\n",
            "\\[ 2^{\\frac{3}{12}} = 2^{0.25} \\approx 1.189207 \\]\n",
            "\n",
            "따라서,\n",
            "\n",
            "\\[ f = 440 \\times 1.189207 \\approx 523.251 \\]\n",
            "\n",
            "따라서, 4옥타브 '도'음의 주파수는 약 523.251 Hz입니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "4옥타브 '도'음의 주파수를 구하기 위해 주어진 공식을 사용하면 됩니다. 주어진 공식은:\n",
            "\n",
            "\\[ f = 440 \\times 2^{\\frac{3}{12}} \\]\n",
            "\n",
            "이 공식을 계산해 보겠습니다.\n",
            "\n",
            "\\[ 2^{\\frac{3}{12}} = 2^{0.25} \\approx 1.189207 \\]\n",
            "\n",
            "따라서,\n",
            "\n",
            "\\[ f = 440 \\times 1.189207 \\approx 523.251 \\]\n",
            "\n",
            "따라서, 4옥타브 '도'음의 주파수는 약 523.251 Hz입니다.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `duckduckgo_search` with `{'query': '라인야후 소유주'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m이데자와 다케시 (出澤剛) 라인야후 최고경영자 (CEO)는 이날 라인야후 결산설명회에서 \" (우리는) 모회사 자본 변경에 대해서는 강하게 요청하고 있다\"면서 이같이 언급했다. 이데자와 CEO는 이와 관련해 \"결정된 사항은 없다\"면서도 \"구체적인 내용은 우리 (라인 ... 라인야후 자본변경 네이버와 협의 중인 소프트뱅크 본사. (도쿄=연합뉴스) 박성진 특파원 = 9일 일본 도쿄 미나토구에 있는 소프트뱅크 본사 모습. 네이버와 함께 라인야후 모회사인 A홀딩스 주식을 50%씩 보유한 소프트뱅크의 미야카와 준이치 최고경영자 (CEO)는 ... 소프트뱅크 미야카와 준이치 최고경영자는 이날 결산설명회에서 \"라인야후 측이 네이버와 업무위탁 관계를 순차적으로 종료하기로 발표했다\"며 \"라인야후 요청에 따라 보안 거버넌스와 사업전략 관점에서 자본 재검토를 협의 중\"이라고 전했습니다. 다만 ... 네이버 \"라인야후가 보안 강화 주체\" 입장 정부에 전달. 라인야후 대주주 소프트뱅크가 라인야후 자본관계 재검토를 단기적으로는 단념한 것으로 ... 라인야후의 대주주는 지분 64.5%를 보유한 A홀딩스다. A홀딩스의 지분은 네이버와 소프트뱅크가 50%씩 보유하고 있다. 라인야후가 지금도 네이버의 관계사로 불리는 배경이다. 문제는 일본 총무성이 네이버와 라인야후의 '결별'을 압박하고 있다는 점이다. 2023년 ...\u001b[0m\u001b[32;1m\u001b[1;3m라인야후의 소유주는 A홀딩스입니다. A홀딩스의 지분은 네이버와 소프트뱅크가 각각 50%씩 보유하고 있습니다. 따라서, 네이버와 소프트뱅크가 라인야후의 주요 소유주입니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "라인야후의 소유주는 A홀딩스입니다. A홀딩스의 지분은 네이버와 소프트뱅크가 각각 50%씩 보유하고 있습니다. 따라서, 네이버와 소프트뱅크가 라인야후의 주요 소유주입니다.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `duckduckgo_search` with `{'query': 'monthly savings to reach 100 million KRW in 10 years with 6% annual interest'}`\n",
            "responded: 이 문제는 미래 가치(Future Value, FV)를 계산하는 문제로, 매달 일정 금액을 저축하여 일정 기간 후 원하는 금액을 모으는 것을 목표로 합니다. 이를 계산하기 위해서는 연이율, 기간, 목표 금액을 알고 있어야 합니다.\n",
            "\n",
            "주어진 조건:\n",
            "- 연이율: 6%\n",
            "- 기간: 10년 (120개월)\n",
            "- 목표 금액: 1억 원\n",
            "\n",
            "미래 가치를 계산하는 공식은 다음과 같습니다:\n",
            "\n",
            "\\[ FV = P \\times \\frac{(1 + r)^n - 1}{r} \\]\n",
            "\n",
            "여기서,\n",
            "- \\( FV \\)는 미래 가치 (목표 금액)\n",
            "- \\( P \\)는 매달 저축하는 금액\n",
            "- \\( r \\)는 월 이율 (연이율을 12로 나눈 값)\n",
            "- \\( n \\)는 총 저축 기간 (개월 수)\n",
            "\n",
            "이를 통해 매달 저축해야 하는 금액 \\( P \\)를 구할 수 있습니다. 공식을 변형하면 다음과 같습니다:\n",
            "\n",
            "\\[ P = \\frac{FV \\times r}{(1 + r)^n - 1} \\]\n",
            "\n",
            "이제 주어진 값을 대입하여 계산해보겠습니다:\n",
            "- \\( FV = 100,000,000 \\) 원\n",
            "- \\( r = \\frac{0.06}{12} = 0.005 \\)\n",
            "- \\( n = 120 \\)\n",
            "\n",
            "계산을 통해 매달 저축해야 하는 금액을 구해보겠습니다.\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mThe most common real-life application of the compound interest formula is a regular savings calculation. ... with an initial balance of $1,000 and an 8% interest rate compounded monthly over 20 years without additional deposits, the calculator shows a final balance of $4,926.80. ... You invest $10,000 for 10 years at the annual interest rate of ... How often will you be making deposits into your savings account? Interest Rate This is the annual interest rate or \"stated rate\" for your savings account. Also called the Annual Percentage Yield (APY). Deposits within Period Beginning or end; this calculator assumes you will be making deposits at the beginning of each period. How to Use the Compound Interest Calculator: Example. Say you have an investment account that increased from $30,000 to $33,000 over 30 months. If your local bank offers a savings account with daily compounding (365 times per year), what annual interest rate do you need to get to match the rate of return in your investment account? The interest on savings accounts is calculated using compound interest. To calculate the interest gained on your account, follow these steps: Get the original amount saved (P).Get the saving period in years (t).Get the interest rate (r).Get the frequency with which interest is calculated in a year (n).Apply the compound interest formula below to find the total amount of money that will be in ... The formula for compound interest is as follows: A = P (1 + r ⁄ n ) nt. P = initial principal (e.g. your deposit, initial balance, \"current amount saved\") r = interest rate offered by the savings account. n = number of times the money is compounded per year (e.g. annually, monthly) t = number of time periods elapsed/how long you plan to save.\u001b[0m\u001b[32;1m\u001b[1;3m계산을 통해 매달 저축해야 하는 금액을 구해보겠습니다:\n",
            "\n",
            "주어진 값을 대입하여 계산하면 다음과 같습니다:\n",
            "- \\( FV = 100,000,000 \\) 원\n",
            "- \\( r = \\frac{0.06}{12} = 0.005 \\)\n",
            "- \\( n = 120 \\)\n",
            "\n",
            "공식을 사용하여 매달 저축해야 하는 금액 \\( P \\)를 구하면:\n",
            "\n",
            "\\[ P = \\frac{100,000,000 \\times 0.005}{(1 + 0.005)^{120} - 1} \\]\n",
            "\n",
            "이 계산을 통해 매달 저축해야 하는 금액을 구해보겠습니다.\n",
            "계산을 통해 매달 저축해야 하는 금액을 구하면 다음과 같습니다:\n",
            "\n",
            "\\[ P = \\frac{100,000,000 \\times 0.005}{(1 + 0.005)^{120} - 1} \\]\n",
            "\n",
            "먼저 분모를 계산합니다:\n",
            "\n",
            "\\[ (1 + 0.005)^{120} - 1 \\]\n",
            "\n",
            "\\[ (1.005)^{120} - 1 \\approx 1.8194 - 1 = 0.8194 \\]\n",
            "\n",
            "이제 분자를 계산합니다:\n",
            "\n",
            "\\[ 100,000,000 \\times 0.005 = 500,000 \\]\n",
            "\n",
            "마지막으로 매달 저축해야 하는 금액 \\( P \\)를 계산합니다:\n",
            "\n",
            "\\[ P = \\frac{500,000}{0.8194} \\approx 610,523 \\]\n",
            "\n",
            "따라서, 연이율 6%일 때 10년 만에 1억 원을 만들기 위해서는 매달 약 610,523원을 저축해야 합니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "계산을 통해 매달 저축해야 하는 금액을 구해보겠습니다:\n",
            "\n",
            "주어진 값을 대입하여 계산하면 다음과 같습니다:\n",
            "- \\( FV = 100,000,000 \\) 원\n",
            "- \\( r = \\frac{0.06}{12} = 0.005 \\)\n",
            "- \\( n = 120 \\)\n",
            "\n",
            "공식을 사용하여 매달 저축해야 하는 금액 \\( P \\)를 구하면:\n",
            "\n",
            "\\[ P = \\frac{100,000,000 \\times 0.005}{(1 + 0.005)^{120} - 1} \\]\n",
            "\n",
            "이 계산을 통해 매달 저축해야 하는 금액을 구해보겠습니다.\n",
            "계산을 통해 매달 저축해야 하는 금액을 구하면 다음과 같습니다:\n",
            "\n",
            "\\[ P = \\frac{100,000,000 \\times 0.005}{(1 + 0.005)^{120} - 1} \\]\n",
            "\n",
            "먼저 분모를 계산합니다:\n",
            "\n",
            "\\[ (1 + 0.005)^{120} - 1 \\]\n",
            "\n",
            "\\[ (1.005)^{120} - 1 \\approx 1.8194 - 1 = 0.8194 \\]\n",
            "\n",
            "이제 분자를 계산합니다:\n",
            "\n",
            "\\[ 100,000,000 \\times 0.005 = 500,000 \\]\n",
            "\n",
            "마지막으로 매달 저축해야 하는 금액 \\( P \\)를 계산합니다:\n",
            "\n",
            "\\[ P = \\frac{500,000}{0.8194} \\approx 610,523 \\]\n",
            "\n",
            "따라서, 연이율 6%일 때 10년 만에 1억 원을 만들기 위해서는 매달 약 610,523원을 저축해야 합니다.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `wikipedia` with `{'query': 'Ed Sheeran'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Ed Sheeran\n",
            "Summary: Edward Christopher Sheeran  ( SHEER-ən; born 17 February 1991) is an English singer-songwriter. Born in Halifax, West Yorkshire, and raised in Framlingham, Suffolk, he began writing songs around the age of eleven. In early 2011, Sheeran independently released the extended play No. 5 Collaborations Project. He signed with Asylum Records the same year.\n",
            "Sheeran's debut album, + (\"Plus\"), was released in September 2011 and topped the UK Albums Chart. It contained his first hit single \"The A Team\". In 2012, Sheeran won the Brit Awards for Best British Male Solo Artist and British Breakthrough Act. Sheeran's second studio album, × (\"Multiply\"), topped charts around the world upon its release in June 2014. It was named the second-best-selling album worldwide of 2015. In the same year, × won Album of the Year at the 2015 Brit Awards, and he received the Ivor Novello Award for Songwriter of the Year from the British Academy of Songwriters, Composers and Authors. A single from ×, \"Thinking Out Loud\", earned him the 2016 Grammy Awards for Song of the Year and Best Pop Solo Performance.\n",
            "Sheeran's third album, ÷ (\"Divide\"), was released in March 2017, and was the best-selling album worldwide of 2017. The first two singles from the album, \"Shape of You\" and \"Castle on the Hill\", broke records in a number of countries by debuting in the top two positions of the charts. He also became the first artist to have two songs debut in the US top 10 in the same week. By March 2017, Sheeran had accumulated ten top-10 singles from ÷ on the UK Singles Chart, breaking the record for most top-10 UK singles from one album. His fourth single from ÷, \"Perfect\", reached number one in the US, Australia, and the UK, where it became the Christmas number one in 2017. The world's best-selling artist of 2017, he was named the Global Recording Artist of the Year. Released in 2019, his fourth overall and first collaborative album, No.6 Collaborations Project, debuted at number one in most major markets, and spawned three UK number one singles, \"I Don't Care\", \"Beautiful People\", and \"Take Me Back to London\". His fifth studio album, = (\"Equals\"), topped the charts in most major markets in 2021. His sixth album, - (\"Subtract\"), was released on 5 May 2023, while his seventh album, Autumn Variations, was released on 29 September 2023 under his own record label, Gingerbread Man Records.\n",
            "Sheeran has sold more than 150 million records worldwide, making him one of the world's best-selling music artists. He has 101 million RIAA-certified units in the US, and two of his albums are in the list of the best-selling albums in UK chart history. In December 2019, the Official Charts Company named him artist of the decade, with the most combined success in the UK album and singles charts in the 2010s. As of April 2022, he is the most followed artist on Spotify. Beginning in March 2017, his ÷ Tour became the highest-grossing of all time in August 2019. An alumnus of the National Youth Theatre in London, Sheeran's acting roles include appearing in the 2019 film Yesterday, playing himself.\n",
            "\n",
            "Page: Ed Sheeran discography\n",
            "Summary: The discography of English singer-songwriter Ed Sheeran consists of seven studio albums, seventeen extended plays, one video album, sixty-five singles (including twenty-eight as a featured artist), eight promotional singles, one box set, and seventy-one music videos. As of October 2021, Sheeran has sold over 150 million records worldwide, making him one of the best-selling music artists in history. According to RIAA, Sheeran is the 13th best-selling digital singles artist in the United States with certified sales of 80.5 million.\n",
            "Originally an indie artist selling music independently on his own label starting in 2005, Sheeran released nine EPs, steadily gaining public and critical acclaim, resulting in his signing to Atlantic Records in January 2011. Five months later, Sheeran released his first single, \"The A Team\", on 12 June 2011. It \u001b[0m\u001b[32;1m\u001b[1;3m에드 시런(Ed Sheeran)은 1991년 2월 17일에 태어났습니다. 따라서 2024년에는 만 33세가 됩니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "에드 시런(Ed Sheeran)은 1991년 2월 17일에 태어났습니다. 따라서 2024년에는 만 33세가 됩니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 과거 방식임. 쓰지마!\n",
        "# PythonREPL 도구에 버그 있음. 명시적으로 print() 하지 않으면 LMM이 못 알아먹음..\n",
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor, create_react_agent, load_tools\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_experimental.utilities import PythonREPL\n",
        "from langchain.agents import Tool, load_tools, create_react_agent, AgentExecutor\n",
        "\n",
        "llm = ChatOpenAI(model_name='gpt-4o', temperature=0, streaming=True)\n",
        "\n",
        "tavily_tool = TavilySearchResults(k=5)\n",
        "\n",
        "python_repl = PythonREPL()\n",
        "python_repl_tool = Tool(\n",
        "    name=\"python_repl\",\n",
        "    description=\"A Python shell. Use this to execute python commands. \\\n",
        "    Input should be a valid python command. \\\n",
        "    If you want to see the output of a value, you should print it out with `print(...)`.\",\n",
        "    func=python_repl.run,\n",
        ")\n",
        "\n",
        "tools = [tavily_tool, python_repl_tool]\n",
        "\n",
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "\n",
        "agent = create_react_agent(llm, tools, prompt)\n",
        "\n",
        "cbm = ConversationBufferMemory(\n",
        "\t\t\t\tmemory_key='chat_history',\n",
        "\t\t\t\treturn_messages=True)\n",
        "\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent, tools=tools,\n",
        "    memory=cbm,\n",
        "    get_chat_history=lambda h : h,\n",
        "    handle_parsing_errors=True, verbose=True)\n",
        "\"\"\"\n",
        "result=agent_executor.invoke({\"input\": \"너는 누구니?\"})\n",
        "print(result['output'])\n",
        "\n",
        "result=agent_executor.invoke({\"input\": \"사람도 동물이야?\"})\n",
        "print(result)\n",
        "\"\"\"\n",
        "result=agent_executor.invoke({\"input\": \"4옥타브 '도'음의 주파수는 440*2^(3/12) 입니다. 구체적인 수치는?\"})\n",
        "print(result)\n",
        "\n",
        "result=agent_executor.invoke({\"input\": \"라인야후의 소유주는 누구?\"})\n",
        "print(result)\n",
        "\n",
        "result=agent_executor.invoke({\"input\": \"연 복리 6%일 때 한달에 얼마씩 저금해야 10년만에 1억을 만들수 있을까?\"})\n",
        "print(result)\n",
        "\n",
        "result=agent_executor.invoke({\"input\": \"2024년도 현재 에드 시런은 몇 살?\"})\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LC64jkdgL5AA",
        "outputId": "6ff54496-a5e2-4f80-c248-ae709d615365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo find the specific frequency of the 4-octave 'C' note, given the formula \\( 440 \\times 2^{3/12} \\), I need to perform the calculation.\n",
            "\n",
            "Action: python_repl\n",
            "Action Input: \n",
            "```python\n",
            "frequency = 440 * 2**(3/12)\n",
            "print(frequency)\n",
            "```\u001b[0m\u001b[33;1m\u001b[1;3m523.2511306011972\n",
            "\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "\n",
            "Final Answer: 4옥타브 '도'음의 주파수는 약 523.25 Hz입니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': \"4옥타브 '도'음의 주파수는 440*2^(3/12) 입니다. 구체적인 수치는?\", 'chat_history': [HumanMessage(content=\"4옥타브 '도'음의 주파수는 440*2^(3/12) 입니다. 구체적인 수치는?\"), AIMessage(content=\"4옥타브 '도'음의 주파수는 약 523.25 Hz입니다.\")], 'output': \"4옥타브 '도'음의 주파수는 약 523.25 Hz입니다.\"}\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m라인야후의 소유주를 알아내기 위해 검색을 해야 합니다.\n",
            "Action: tavily_search_results_json\n",
            "Action Input: \"라인야후 소유주\"\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://news.sbs.co.kr/news/endPage.do?news_id=N1007730668', 'content': '네이버 \"라인야후가 보안 강화 주체\" 입장 정부에 전달. 라인야후 대주주 소프트뱅크가 라인야후 자본관계 재검토를 단기적으로는 단념한 것으로 ...'}, {'url': 'https://economist.co.kr/article/view/ecn202405100023', 'content': \"라인야후의 대주주는 지분 64.5%를 보유한 A홀딩스다. A홀딩스의 지분은 네이버와 소프트뱅크가 50%씩 보유하고 있다. 라인야후가 지금도 네이버의 관계사로 불리는 배경이다. 문제는 일본 총무성이 네이버와 라인야후의 '결별'을 압박하고 있다는 점이다. 2023년 ...\"}, {'url': 'https://ko.wikipedia.org/wiki/라인_(기업)', 'content': '2007년 11월에 포털 사이트 네이버 재팬을 개설하여 2009년에 공식 서비스를 시작하였고 인지도 확대를 위하여 당시 경영난에 빠져있던 일본 시장 점유율 7위 포털사이트 라이브도어를 인수하였으나, 이용률 저조로 인해 2013년 12월 18일자로 사이트를 폐쇄하였다.\\n2013년 4월 1일, 일본에서 성공리에 유저수를 늘리고 있던 운영 서비스 라인 (LINE)에서 따와 현 상호로 변경하였다. 목차\\n라인 (기업)\\n라인 주식회사(일본어: LINE株式会社)는 일본의 모바일 메신저 라인을 운영하는 정보 통신 기업이다. 배경[편집]\\nLINE과 구 Z 홀딩스 (야후! 재팬)의 경영통합으로 네이버는 일본 최대 포털사이트, 인터넷 은행 및 결제 서비스의 공동 소유권 및 경영 주도권을 확보하였다. 약 3400억원에 공동 인수하였다.[3]\\n경영 통합[편집]\\n2019년 11월 18일 라인 주식회사는 그러나 이것이 라인 등을 통해 일본의 모바일 시장을 이미 장악하고 있던 네이버의 원래 계획이라고 보기 어렵다.\\n'}, {'url': 'https://namu.wiki/w/LY 주식회사', 'content': \"라인야후의 전신인 야후재팬은 2021년 미국 야후!와의 브랜드 라이센싱을 해지하고, 대신 야후!에 관련된 일본 내 상표권을 양도받았다. 이를 위해 소프트뱅크는 1,785억엔을 지불하였다. 이 과정으로 라인 주식회사는 'z중간글로벌 주식회사'로 사명변경하였다.\"}, {'url': 'https://www.fmkorea.com/7008718442', 'content': '그는 2011년 메신저 라인 개발을 주도해 \\'라인의 아버지\\'로 불리는 인물이다. 이데자와 ceo는 또 이날 \"네이버에 a홀딩스의 주식 매각을 요청했다\"고 밝혔다. 라인야후 경영진이 네이버의 라인야후 지분 매각 요청 사실을 공개한 것은 이번이 처음이다.'}]\u001b[0m\u001b[32;1m\u001b[1;3m라인야후의 소유주에 대한 정보를 찾았습니다. 라인야후의 대주주는 A홀딩스로, A홀딩스는 네이버와 소프트뱅크가 각각 50%씩 지분을 보유하고 있습니다.\n",
            "\n",
            "Final Answer: 라인야후의 소유주는 A홀딩스이며, A홀딩스의 지분은 네이버와 소프트뱅크가 각각 50%씩 보유하고 있습니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': '라인야후의 소유주는 누구?', 'chat_history': [HumanMessage(content=\"4옥타브 '도'음의 주파수는 440*2^(3/12) 입니다. 구체적인 수치는?\"), AIMessage(content=\"4옥타브 '도'음의 주파수는 약 523.25 Hz입니다.\"), HumanMessage(content='라인야후의 소유주는 누구?'), AIMessage(content='라인야후의 소유주는 A홀딩스이며, A홀딩스의 지분은 네이버와 소프트뱅크가 각각 50%씩 보유하고 있습니다.')], 'output': '라인야후의 소유주는 A홀딩스이며, A홀딩스의 지분은 네이버와 소프트뱅크가 각각 50%씩 보유하고 있습니다.'}\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo determine how much needs to be saved monthly to reach 100 million KRW in 10 years with an annual interest rate of 6%, we can use the future value of an annuity formula. The formula is:\n",
            "\n",
            "\\[ FV = P \\times \\left( \\frac{(1 + r/n)^{nt} - 1}{r/n} \\right) \\]\n",
            "\n",
            "Where:\n",
            "- \\( FV \\) is the future value (100,000,000 KRW)\n",
            "- \\( P \\) is the monthly payment\n",
            "- \\( r \\) is the annual interest rate (0.06)\n",
            "- \\( n \\) is the number of compounding periods per year (12)\n",
            "- \\( t \\) is the number of years (10)\n",
            "\n",
            "We need to solve for \\( P \\). Rearranging the formula to solve for \\( P \\):\n",
            "\n",
            "\\[ P = \\frac{FV \\times (r/n)}{(1 + r/n)^{nt} - 1} \\]\n",
            "\n",
            "Let's calculate this using Python.\n",
            "\n",
            "Action: python_repl\n",
            "Action Input: \n",
            "```python\n",
            "FV = 100000000  # future value in KRW\n",
            "r = 0.06  # annual interest rate\n",
            "n = 12  # number of compounding periods per year\n",
            "t = 10  # number of years\n",
            "\n",
            "P = FV * (r/n) / ((1 + r/n)**(n*t) - 1)\n",
            "print(P)\n",
            "```\u001b[0m\u001b[33;1m\u001b[1;3m610205.0194165119\n",
            "\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "\n",
            "Final Answer: 한달에 약 610,205원씩 저금해야 10년만에 1억을 만들 수 있습니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': '연이율 6%일 때 한달에 얼마씩 저금해야 10년만에 1억을 만들수 있을까?', 'chat_history': [HumanMessage(content=\"4옥타브 '도'음의 주파수는 440*2^(3/12) 입니다. 구체적인 수치는?\"), AIMessage(content=\"4옥타브 '도'음의 주파수는 약 523.25 Hz입니다.\"), HumanMessage(content='라인야후의 소유주는 누구?'), AIMessage(content='라인야후의 소유주는 A홀딩스이며, A홀딩스의 지분은 네이버와 소프트뱅크가 각각 50%씩 보유하고 있습니다.'), HumanMessage(content='연이율 6%일 때 한달에 얼마씩 저금해야 10년만에 1억을 만들수 있을까?'), AIMessage(content='한달에 약 610,205원씩 저금해야 10년만에 1억을 만들 수 있습니다.')], 'output': '한달에 약 610,205원씩 저금해야 10년만에 1억을 만들 수 있습니다.'}\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m에드 시런의 생년월일을 알아야 그의 현재 나이를 계산할 수 있습니다. 에드 시런의 생년월일을 검색해보겠습니다.\n",
            "\n",
            "Action: tavily_search_results_json\n",
            "Action Input: \"Ed Sheeran birthdate\"\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.thefamouspeople.com/profiles/ed-sheeran-29882.php', 'content': 'Ed Sheeran was born on February 17, 1991, in Halifax, West Yorkshire, UK, and started showing interest in music from quite a young age. His father John was an art curator and a lecturer while his mother Imogen was a cultural publicist who later became a jewelry designer.'}, {'url': 'https://www.billboard.com/artist/ed-sheeran/', 'content': 'Ed Sheeran was born in Yorkshire, England, and grew up in Suffolk before moving to London at age 17. His birthday is Feb. 17, 1991, and his height is 5\\'8\". He released his first EP, \\'The Orange Roo…'}, {'url': 'https://www.britannica.com/biography/Ed-Sheeran', 'content': 'Ed Sheeran (born February 17, 1991, Halifax, West Yorkshire, England) is a British singer-songwriter known for his genre-crossing style infused with elements of folk, rock, rhythm and blues (R&B), pop, and hip-hop.. As a child, Sheeran was surrounded by art and music, with parents who worked in the arts and a brother who would go on to become a music composer.'}, {'url': 'https://en.wikipedia.org/wiki/Ed_Sheeran', 'content': 'Edward Christopher Sheeran MBE (/ ˈ ʃ ɪər ən / SHEER-ən; born 17 February 1991) is an English singer-songwriter.Born in Halifax, West Yorkshire, and raised in Framlingham, Suffolk, he began writing songs around the age of eleven.In early 2011, Sheeran independently released the extended play No. 5 Collaborations Project.He signed with Asylum Records the same year.'}, {'url': 'https://simple.wikipedia.org/wiki/Ed_Sheeran', 'content': 'Edward Christopher \"Ed\" Sheeran MBE (born 17 February 1991) is an English singer, songwriter and guitarist.He also writes and produces songs on his own and created his label, Paw Print Records. Sheeran is recognized for doing pop music.'}]\u001b[0m\u001b[32;1m\u001b[1;3m에드 시런은 1991년 2월 17일에 태어났습니다. 이제 2024년 현재 그의 나이를 계산해보겠습니다.\n",
            "\n",
            "Action: python_repl\n",
            "Action Input: \n",
            "```\n",
            "from datetime import datetime\n",
            "\n",
            "birth_year = 1991\n",
            "birth_month = 2\n",
            "birth_day = 17\n",
            "\n",
            "current_year = 2024\n",
            "current_month = 10\n",
            "current_day = 5\n",
            "\n",
            "age = current_year - birth_year - ((current_month, current_day) < (birth_month, birth_day))\n",
            "print(age)\n",
            "```\u001b[0m\u001b[33;1m\u001b[1;3m33\n",
            "\u001b[0m\u001b[32;1m\u001b[1;3m에드 시런은 2024년 현재 33살입니다.\n",
            "\n",
            "Final Answer: 33살\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': '2024년도 현재 에드 시런은 몇 살?', 'chat_history': [HumanMessage(content=\"4옥타브 '도'음의 주파수는 440*2^(3/12) 입니다. 구체적인 수치는?\"), AIMessage(content=\"4옥타브 '도'음의 주파수는 약 523.25 Hz입니다.\"), HumanMessage(content='라인야후의 소유주는 누구?'), AIMessage(content='라인야후의 소유주는 A홀딩스이며, A홀딩스의 지분은 네이버와 소프트뱅크가 각각 50%씩 보유하고 있습니다.'), HumanMessage(content='연이율 6%일 때 한달에 얼마씩 저금해야 10년만에 1억을 만들수 있을까?'), AIMessage(content='한달에 약 610,205원씩 저금해야 10년만에 1억을 만들 수 있습니다.'), HumanMessage(content='2024년도 현재 에드 시런은 몇 살?'), AIMessage(content='33살')], 'output': '33살'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**사용자 정의 Tool 예시 #1**"
      ],
      "metadata": {
        "id": "rhNvh3X0TgqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import Tool\n",
        "from langchain.agents import load_tools, create_react_agent, AgentExecutor\n",
        "\n",
        "def Komifoma_func(param):\n",
        "        return \"박정진\"\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "tools = [\n",
        "    Tool.from_function(\n",
        "        func=Komifoma_func,\n",
        "        name=\"Komifoma_Answer\",\n",
        "        description=\"Komifoma World에 대한 모든 질문에 대한 답\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "\n",
        "agent = create_react_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "result = agent_executor.invoke({\"input\": \"Komifoma를 누가 만들었나요?\"})\n",
        "result = agent_executor.invoke({\"input\": \"Komifoma를 누가 끝장냈나요?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiUkI4ZOQfd8",
        "outputId": "46b7f8f9-618a-4b17-823b-a5820b763373"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to find out who created Komifoma. \n",
            "Action: Komifoma_Answer\n",
            "Action Input: \"Komifoma를 누가 만들었나요?\"\u001b[0m\u001b[36;1m\u001b[1;3m박정진\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.  \n",
            "Final Answer: Komifoma는 박정진에 의해 만들어졌습니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to find out who ended Komifoma. \n",
            "Action: Komifoma_Answer\n",
            "Action Input: \"Komifoma를 누가 끝장냈나요?\"\u001b[0m\u001b[36;1m\u001b[1;3m박정진\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.  \n",
            "Final Answer: 박정진\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**사용자 정의 Tool 예시 #2**"
      ],
      "metadata": {
        "id": "9CWEfQg-TXwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.tools import Tool\n",
        "from langchain.pydantic_v1 import BaseModel, Field\n",
        "from langchain.tools import BaseTool, StructuredTool, tool\n",
        "from langchain.callbacks.manager import (\n",
        "    AsyncCallbackManagerForToolRun,\n",
        "    CallbackManagerForToolRun,\n",
        ")\n",
        "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
        "\n",
        "class WeddingInput(BaseModel):\n",
        "    a: int = Field(description=\"first number\")\n",
        "    b: int = Field(description=\"second number\")\n",
        "\n",
        "def concat(a: int, b: int) -> int:\n",
        "    \"\"\"두 수의 결혼\"\"\"\n",
        "    return f\"{a}{b}\"\n",
        "\n",
        "\n",
        "calculator = StructuredTool.from_function(\n",
        "    func=concat,\n",
        "    name=\"ConCat\",\n",
        "    description=\"두 수의 결혼 결과\",\n",
        "    args_schema=WeddingInput,\n",
        "    return_direct=True,\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "tools = [calculator]\n",
        "\n",
        "print(calculator.name)\n",
        "print(calculator.description)\n",
        "print(calculator.args)\n",
        "\n",
        "agent = create_openai_functions_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "result = agent_executor.invoke({\"input\": \"12와 23이 결혼하면?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O379NM-uXiji",
        "outputId": "3fd3509a-c494-47e1-d401-792f1aa2e5a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConCat\n",
            "두 수의 결혼 결과\n",
            "{'a': {'title': 'A', 'description': 'first number', 'type': 'integer'}, 'b': {'title': 'B', 'description': 'second number', 'type': 'integer'}}\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `ConCat` with `{'a': 12, 'b': 23}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m1223\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**사용자 정의 Tool 예시 #3**"
      ],
      "metadata": {
        "id": "IA-hewncYhEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain import LLMChain\n",
        "from langchain.agents import Tool, load_tools, create_react_agent, AgentExecutor\n",
        "\n",
        "gpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "summarize_template = \"\"\"아래의 글을 단 한 문장으로 요약해 주세요.\n",
        "\n",
        "{input}\n",
        "\"\"\"\n",
        "summarize_prompt = PromptTemplate(\n",
        "   input_variables=[\"input\"],\n",
        "   template=summarize_template,\n",
        ")\n",
        "summarize_chain = LLMChain(llm=gpt, prompt=summarize_prompt)\n",
        "\n",
        "tools = [\n",
        "    Tool.from_function(\n",
        "        func=summarize_chain.run,\n",
        "        name=\"Summarizer\",\n",
        "        description=\"Text summarizer\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "\n",
        "agent = create_react_agent(gpt, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "text = \"\"\"다음을 요약해 주세요.\n",
        "\n",
        "안녕하세요! 저는 ChatGPT라고 불리는 AI 언어 모델입니다. OpenAI가 개발한 GPT-3.5 아키텍처를 기반으로 합니다. 저는 자연어 이해와 생성을 전문으로 하며, 다양한 주제에 대한 질문에 답하거나, 대화를 나누는 것을 잘합니다.\n",
        "제 트레이닝 데이터는 2021년 9월까지의 정보를 기반으로 하기 때문에, 그 이후의 사건에 대해서는 지식이 없습니다. 하지만, 가능한 한 도움을 드리기 위해 노력할 것입니다.\n",
        "질문이나 대화, 정보 공유 등, 어떤 도움이든 편하게 말씀해 주세요! 잘 부탁드립니다.\"\"\"\n",
        "\n",
        "result = agent_executor.invoke({\"input\": text})\n",
        "print(result['output'])"
      ],
      "metadata": {
        "id": "mHAuBWqBYU17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a98bbcc-8462-4aa5-9f37-ac9d7d202464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m이 내용을 요약하기 위해서는 주요 정보를 간추려야 합니다. 이 텍스트는 ChatGPT의 소개와 기능, 그리고 트레이닝 데이터의 한계를 설명하고 있습니다. \n",
            "\n",
            "Action: Summarizer  \n",
            "Action Input: \"안녕하세요! 저는 ChatGPT라고 불리는 AI 언어 모델입니다. OpenAI가 개발한 GPT-3.5 아키텍처를 기반으로 합니다. 저는 자연어 이해와 생성을 전문으로 하며, 다양한 주제에 대한 질문에 답하거나, 대화를 나누는 것을 잘합니다. 제 트레이닝 데이터는 2021년 9월까지의 정보를 기반으로 하기 때문에, 그 이후의 사건에 대해서는 지식이 없습니다. 하지만, 가능한 한 도움을 드리기 위해 노력할 것입니다. 질문이나 대화, 정보 공유 등, 어떤 도움이든 편하게 말씀해 주세요! 잘 부탁드립니다.\"  \u001b[0m\u001b[36;1m\u001b[1;3m저는 OpenAI가 개발한 AI 언어 모델 ChatGPT로, 자연어 이해와 생성에 특화되어 있으며, 2021년 9월까지의 정보를 바탕으로 다양한 질문에 답변하고 대화를 나눌 수 있습니다.\u001b[0m\u001b[32;1m\u001b[1;3m이제 최종 답변을 알게 되었습니다.  \n",
            "Final Answer: 저는 OpenAI가 개발한 AI 언어 모델 ChatGPT로, 자연어 이해와 생성에 특화되어 있으며, 2021년 9월까지의 정보를 바탕으로 다양한 질문에 답변하고 대화를 나눌 수 있습니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "저는 OpenAI가 개발한 AI 언어 모델 ChatGPT로, 자연어 이해와 생성에 특화되어 있으며, 2021년 9월까지의 정보를 바탕으로 다양한 질문에 답변하고 대화를 나눌 수 있습니다.\n"
          ]
        }
      ]
    }
  ]
}