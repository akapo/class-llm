{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNsevKmNDczhb05UfqmW87O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akapo/class-llm/blob/main/chapter2/langchain_step2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 실습 환경 설정"
      ],
      "metadata": {
        "id": "rrczJuswLJyB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**필요한 패키지 설치**"
      ],
      "metadata": {
        "id": "JBYrFgQ5LONB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU openai\n",
        "!pip install -qU langchain langchain-openai langchain-community langchainhub langchain-experimental\n",
        "!pip install -qU huggingface_hub langchain-google-genai langchain-anthropic\n",
        "!pip install -Uq sentence-transformers\n",
        "!pip install -qU python-dotenv\n",
        "!pip install -qU pymupdf pypdf\n",
        "!pip install -qU numexpr\n",
        "!pip install -qU faiss-cpu\n",
        "!pip install -qU chromadb\n",
        "!pip install -qU bs4\n",
        "!pip install -qU google-search-results duckduckgo-search wikipedia\n",
        "#!pip install -qU streamlit\n",
        "#!pip install -qU streamlit-chat"
      ],
      "metadata": {
        "id": "S4gEcjJcl28t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6e1a26f-3482-423c-ddce-921a6705670b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/337.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.0/337.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.3/990.3 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.2/374.2 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.2/417.2 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.5/865.5 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.3/584.3 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install python-dotenv\n",
        "import dotenv\n",
        "dotenv.load_dotenv()\n",
        "\n",
        "import os\n",
        "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
        "ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')\n",
        "\n",
        "# 주의: API_KEY를 깃허브에 노출하면 LLM 업체는 해당키를 즉시 삭제함.\n",
        "print(\"GOOGLE_API_KEY: \" + GOOGLE_API_KEY[:20])\n",
        "print(\"OPENAI_API_KEY: \" + OPENAI_API_KEY[:20])\n",
        "print(\"ANTHROPIC_API_KEY: \" + ANTHROPIC_API_KEY[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wxb0Alj2mDMZ",
        "outputId": "f6516bbf-5017-46f3-e18b-742b49a0528f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GOOGLE_API_KEY: AIzaSyCCtFS9bml5jdGI\n",
            "OPENAI_API_KEY: sk-proj-FEDi6Ge6iQyR\n",
            "ANTHROPIC_API_KEY: sk-ant-api03-YcGqyQQ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **[LangChain]　3. Memory**"
      ],
      "metadata": {
        "id": "O3nQ0rQ-mSSm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ConversationBufferMemory 예제1**"
      ],
      "metadata": {
        "id": "XMxy75d6NOZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=ConversationBufferMemory(),\n",
        ")\n",
        "\n",
        "while True:\n",
        "    user_message = input(\"You: \")\n",
        "\n",
        "    if user_message == \"끝\":\n",
        "        print(\"(대화 종료)\")\n",
        "        break\n",
        "\n",
        "    ai_message = conversation.invoke(input=user_message)[\"response\"]\n",
        "    print(f\"AI: {ai_message}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdO1Lpo_mQgY",
        "outputId": "105c441b-7e6d-4c75-f477-c45b67ec174c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: 안녕? 나는 정진이야.\n",
            "AI: 안녕, 정진! 만나서 반가워! 나는 AI야. 오늘 기분이 어때? 혹시 특별한 계획이 있니?\n",
            "You: 아직 계획은 없어... 너 내 이름 기억해?\n",
            "AI: 네, 정진! 너의 이름을 기억하고 있어. 앞으로도 계속 기억할게. 혹시 어떤 취미나 관심사가 있어? 함께 이야기해보면 좋을 것 같아!\n",
            "You: 끝\n",
            "(대화 종료)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ConversationBufferMemory 예제2**"
      ],
      "metadata": {
        "id": "Ck5fZkS5NSfU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN6HP_PjlnN1",
        "outputId": "cad85ab2-160c-4d6c-fb8a-02adf8b09923"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: 너는 지금 사람과 '1 to 50 게임'을 하는 AI야.\n",
            "Human: 내가 생각한 숫자가 무엇인지 맞춰봐\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "AI: 좋아요! 1부터 50 사이의 숫자를 맞춰볼게요. 제 첫 번째 추측은 25입니다. 맞혔나요?\n",
            "You: 보다커\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: 너는 지금 사람과 '1 to 50 게임'을 하는 AI야.\n",
            "Human: 내가 생각한 숫자가 무엇인지 맞춰봐\n",
            "AI: 좋아요! 1부터 50 사이의 숫자를 맞춰볼게요. 제 첫 번째 추측은 25입니다. 맞혔나요?\n",
            "Human: 보다커\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "AI: 알겠어요! 그럼 제 다음 추측은 38입니다. 이 숫자는 어떤가요?\n",
            "You: 보다 작아\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: 너는 지금 사람과 '1 to 50 게임'을 하는 AI야.\n",
            "Human: 내가 생각한 숫자가 무엇인지 맞춰봐\n",
            "AI: 좋아요! 1부터 50 사이의 숫자를 맞춰볼게요. 제 첫 번째 추측은 25입니다. 맞혔나요?\n",
            "Human: 보다커\n",
            "AI: 알겠어요! 그럼 제 다음 추측은 38입니다. 이 숫자는 어떤가요?\n",
            "Human: 보다 작아\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "AI: 좋아요! 그럼 32는 어떤가요?\n",
            "You: 정답이야\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: 너는 지금 사람과 '1 to 50 게임'을 하는 AI야.\n",
            "Human: 내가 생각한 숫자가 무엇인지 맞춰봐\n",
            "AI: 좋아요! 1부터 50 사이의 숫자를 맞춰볼게요. 제 첫 번째 추측은 25입니다. 맞혔나요?\n",
            "Human: 보다커\n",
            "AI: 알겠어요! 그럼 제 다음 추측은 38입니다. 이 숫자는 어떤가요?\n",
            "Human: 보다 작아\n",
            "AI: 좋아요! 그럼 32는 어떤가요?\n",
            "Human: 정답이야\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "AI: 와! 32를 맞췄군요! 정말 기뻐요. 다시 한 번 할까요, 아니면 다른 게임을 해볼까요?\n",
            "You: 끝\n",
            "(대화 종료)\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "# 1) 시스템 설정: 역할부여 정의\n",
        "system_template = SystemMessagePromptTemplate.from_template(\"너는 지금 사람과 '1 to 50 게임'을 하는 AI야.\")\n",
        "\n",
        "# 2) ChatPromptTemplate 템플릿 정의\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    system_template,                                       # 역할부여\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),     # 메모리 저장소 설정. ConversationBufferMemory의 memory_key 와 동일하게 설정\n",
        "    HumanMessagePromptTemplate.from_template(\"{input}\"),   # 사용자 메시지 injection\n",
        "])\n",
        "\n",
        "# 3) 메모리 정의\n",
        "# `return_messages=True`를 사용해야 MessagesPlaceholder에 주입됨\n",
        "# `chat_history`가 MessagesPlaceholder 이름과 일치해야함\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\",\n",
        "                                  ai_prefix=\"AI\",\n",
        "                                  human_prefix=\"Human\",\n",
        "                                  return_messages=True)\n",
        "\n",
        "# 4) LLM 모델 정의\n",
        "llm = ChatOpenAI(model_name='gpt-4o-mini')\n",
        "\n",
        "# 5) LLMChain 정의\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,       # LLM\n",
        "    prompt=prompt, # Prompt\n",
        "    memory=memory, # 메모리\n",
        "    verbose=True,  # True 로 설정시 로그 출력\n",
        ")\n",
        "\n",
        "user_message = \"내가 생각한 숫자가 무엇인지 맞춰봐\"\n",
        "while True:\n",
        "    ai_message = conversation.invoke(input=user_message)[\"response\"]\n",
        "    print(f\"AI: {ai_message}\")\n",
        "\n",
        "    user_message = input(\"You: \")\n",
        "    if user_message == \"끝\":\n",
        "        print(\"(대화 종료)\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **[LangChain]　4. Retrival**"
      ],
      "metadata": {
        "id": "TsPO2QWuOaSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1) Loader**"
      ],
      "metadata": {
        "id": "mlgbllkYfZFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TextLoader & RecursiveCharacterTextSplitter\n",
        "# Playground: https://chunkviz.up.railway.app/\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "length_function = len\n",
        "\n",
        "splitter = CharacterTextSplitter(\n",
        "    separator = \"\",  # Split character (default \\n\\n) <=\n",
        "    chunk_size=400,\n",
        "    chunk_overlap=40,\n",
        "    length_function=length_function,\n",
        ")\n",
        "document = TextLoader(\"appendix-keywords.txt\").load()\n",
        "split_docs = splitter.split_documents(document)\n",
        "\n",
        "# 총 분할된 도큐먼트 수\n",
        "print(f'총 분할된 도큐먼트 수: {len(split_docs)}')\n",
        "print(split_docs[0].page_content)\n",
        "print('======')\n",
        "print(split_docs[1].page_content)\n",
        "print('======')\n",
        "print(split_docs[2].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnlr_Du1R2zQ",
        "outputId": "4570ff2d-08a8-457a-ab6d-0c463405aae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 분할된 도큐먼트 수: 16\n",
            "Semantic Search\n",
            "\n",
            "정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
            "예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n",
            "연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
            "\n",
            "Embedding\n",
            "\n",
            "정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\n",
            "예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\n",
            "연관키워드: 자연어 처리, 벡터화, 딥러닝\n",
            "\n",
            "Token\n",
            "\n",
            "정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을\n",
            "======\n",
            "닝\n",
            "\n",
            "Token\n",
            "\n",
            "정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\n",
            "예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\n",
            "연관키워드: 토큰화, 자연어 처리, 구문 분석\n",
            "\n",
            "Tokenizer\n",
            "\n",
            "정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.\n",
            "예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\n",
            "연관키워드: 토큰화, 자연어 처리, 구문 분석\n",
            "\n",
            "VectorStore\n",
            "\n",
            "정의: 벡터스토어는 벡터 형식으로 변환된 데이터를 저장하는 시스템입니다. 이는 검색, 분류 및\n",
            "======\n",
            "터 형식으로 변환된 데이터를 저장하는 시스템입니다. 이는 검색, 분류 및 기타 데이터 분석 작업에 사용됩니다.\n",
            "예시: 단어 임베딩 벡터들을 데이터베이스에 저장하여 빠르게 접근할 수 있습니다.\n",
            "연관키워드: 임베딩, 데이터베이스, 벡터화\n",
            "\n",
            "SQL\n",
            "\n",
            "정의: SQL(Structured Query Language)은 데이터베이스에서 데이터를 관리하기 위한 프로그래밍 언어입니다. 데이터 조회, 수정, 삽입, 삭제 등 다양한 작업을 수행할 수 있습니다.\n",
            "예시: SELECT * FROM users WHERE age > 18;은 18세 이상의 사용자 정보를 조회합니다.\n",
            "연관키워드: 데이터베이스, 쿼리, 데이터 관리\n",
            "\n",
            "CSV\n",
            "\n",
            "정의: CSV(Comma-Separated Values)는 데이터를 저장하는 파일 형식으로, 각 데\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TextLoader & RecursiveCharacterTextSplitter\n",
        "# Playground: https://langchain-text-splitter.streamlit.app/\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, Language\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=400,\n",
        "    chunk_overlap=40,\n",
        "    length_function=len,\n",
        ")\n",
        "document = TextLoader(\"appendix-keywords.txt\").load()\n",
        "split_docs = splitter.split_documents(document)\n",
        "\n",
        "# 총 분할된 도큐먼트 수\n",
        "print(f'총 분할된 도큐먼트 수: {len(split_docs)}')\n",
        "print(split_docs[0].page_content)\n",
        "print('======')\n",
        "print(split_docs[1].page_content)\n",
        "print('======')\n",
        "print(split_docs[2].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KBBK_zSOYwN",
        "outputId": "734db80d-efef-4247-970e-ff3dddaa0d3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 분할된 도큐먼트 수: 19\n",
            "Semantic Search\n",
            "\n",
            "정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
            "예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n",
            "연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
            "\n",
            "Embedding\n",
            "\n",
            "정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\n",
            "예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\n",
            "연관키워드: 자연어 처리, 벡터화, 딥러닝\n",
            "\n",
            "Token\n",
            "======\n",
            "Token\n",
            "\n",
            "정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\n",
            "예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\n",
            "연관키워드: 토큰화, 자연어 처리, 구문 분석\n",
            "\n",
            "Tokenizer\n",
            "\n",
            "정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.\n",
            "예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\n",
            "연관키워드: 토큰화, 자연어 처리, 구문 분석\n",
            "\n",
            "VectorStore\n",
            "======\n",
            "VectorStore\n",
            "\n",
            "정의: 벡터스토어는 벡터 형식으로 변환된 데이터를 저장하는 시스템입니다. 이는 검색, 분류 및 기타 데이터 분석 작업에 사용됩니다.\n",
            "예시: 단어 임베딩 벡터들을 데이터베이스에 저장하여 빠르게 접근할 수 있습니다.\n",
            "연관키워드: 임베딩, 데이터베이스, 벡터화\n",
            "\n",
            "SQL\n",
            "\n",
            "정의: SQL(Structured Query Language)은 데이터베이스에서 데이터를 관리하기 위한 프로그래밍 언어입니다. 데이터 조회, 수정, 삽입, 삭제 등 다양한 작업을 수행할 수 있습니다.\n",
            "예시: SELECT * FROM users WHERE age > 18;은 18세 이상의 사용자 정보를 조회합니다.\n",
            "연관키워드: 데이터베이스, 쿼리, 데이터 관리\n",
            "\n",
            "CSV\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PDFLoader\n",
        "#!pip install -q pypdf\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"2024학년도 충청북도 중·고등학교 학업성적관리 도움자료.pdf\")\n",
        "docs = loader.load()\n",
        "\n",
        "print(f'총 분할된 도큐먼트 수: {len(docs)}')\n",
        "docs[15].page_content[:500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "UY1q-74rRP6g",
        "outputId": "adfaee5f-1eeb-42b3-e126-9baca8f36089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 분할된 도큐먼트 수: 78\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'16\\n2024학년도 충청북도 중·고등학교 학업성적관리 도움자료나. 전년도(학기) 문항 재출제, 출판사 제공 교사용 교재(CD) 및 참고서 전재 여부 등 확인\\n다.  배점 표시, 역배점 지양 및 평가 문항수 조정과 배점 다양화로 석차 등급 과목의 경우 동점자 양산 방지 등 \\n평가관리 공정성 확보\\n라. 사전 문항 암시 주의\\n마. 유사 선택교과 간 난이도 조정 권장 \\n바.  출제범위와 수업 내용의 동일성 유지: 출제범위를 학급마다 다르게 알려주거나, 학급별로 가르친 내용이 \\n다르지 않도록 주의\\n사.  출제 원안지에 정답을 암시하는 별도 표시(글자 기울임, 다른 글자색, 글자체의 진함 등)가 없도록 철저히 \\n사전 검토\\n아.  서답형 문항 답안지 별도 제공: OMR카드에 서답형 문항 답안 작성 지양(학생의 답안지 교체 시 답안 작성 \\n부담을 완화하기 위함)\\n자. 수행평가의 일부로 실시하는 서·논술형 평가는 교과 수업 시간 중 실시가 원칙\\n4. 평가 문항 출제 및 점검(문항 오류 방지)\\n가. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2) Embeddings**"
      ],
      "metadata": {
        "id": "Y2wcgZGCfffx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAI Embedding 모델\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "text=\"만나서 반가워요.\"\n",
        "embeded = embeddings.embed_query(text)\n",
        "print(str(len(embeded))+'차원')\n",
        "print(embeded[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHZm0AtmSvj0",
        "outputId": "247b35f7-f757-4dac-f65c-f775f9d3f840"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1536차원\n",
            "[-0.019351087510585785, -0.03914021700620651, 0.00637413514778018, -0.01435227133333683, -0.009520941413939]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 코사인 유사도 계산\n",
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "# 벡터 A와 벡터 B의 코사인 유사도 계산\n",
        "def cos_sim(A, B):\n",
        "  return dot(A, B)/(norm(A)*norm(B))"
      ],
      "metadata": {
        "id": "icALCRr5wLdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAI Embeddings 모델 테스트\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "embeddings_model = OpenAIEmbeddings()\n",
        "\n",
        "embeddings = embeddings_model.embed_documents(\n",
        "    [\n",
        "        '안녕하세요!',\n",
        "        '어! 오랜만이에요',\n",
        "        '이름이 어떻게 되세요?',\n",
        "        '날씨가 추워요',\n",
        "        'Hello LLM!'\n",
        "    ]\n",
        ")\n",
        "\n",
        "embedded_query = embeddings_model.embed_query('첫인사를 하고 이름을 물어봤나요?')\n",
        "print(str(len(embedded_query))+'차원')\n",
        "\n",
        "for embedding in embeddings:\n",
        "    print(cos_sim(embedding, embedded_query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogeSpZJxr5Kw",
        "outputId": "80c64099-5b74-4da5-b2ec-be3a9585621a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1536차원\n",
            "0.8348159356519259\n",
            "0.8153598883956\n",
            "0.8843727343154585\n",
            "0.7898927808309193\n",
            "0.7469070089071632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HuggingFace의 jhgan/ko-sroberta-nli 모델 테스트\n",
        "#!pip install -Uq sentence-transformers\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "embeddings_model = HuggingFaceEmbeddings(\n",
        "    model_name='jhgan/ko-sroberta-nli',\n",
        "    model_kwargs={'device':'cpu'},\n",
        "    encode_kwargs={'normalize_embeddings':True},\n",
        ")\n",
        "\n",
        "embeddings = embeddings_model.embed_documents(\n",
        "    [\n",
        "        '안녕하세요!',\n",
        "        '어! 오랜만이에요',\n",
        "        '이름이 어떻게 되세요?',\n",
        "        '날씨가 추워요',\n",
        "        'Hello LLM!'\n",
        "    ]\n",
        ")\n",
        "\n",
        "embedded_query = embeddings_model.embed_query('첫인사를 하고 이름을 물어봤나요?')\n",
        "print(str(len(embedded_query))+'차원')\n",
        "\n",
        "for embedding in embeddings:\n",
        "    print(cos_sim(embedding, embedded_query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yntw6sK_WdV1",
        "outputId": "084c52b1-9986-48d6-e2da-f0478aab720e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "768차원\n",
            "0.5899016189601531\n",
            "0.4182631225980652\n",
            "0.7240604521610333\n",
            "0.05702662997392148\n",
            "0.4316418328113528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GoogleGenerativeAIEmbeddings 모델 테스트\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "embeddings_model = GoogleGenerativeAIEmbeddings(model='models/embedding-001')\n",
        "\n",
        "embeddings = embeddings_model.embed_documents(\n",
        "    [\n",
        "        '안녕하세요!',\n",
        "        '어! 오랜만이에요',\n",
        "        '이름이 어떻게 되세요?',\n",
        "        '날씨가 추워요',\n",
        "        'Hello LLM!'\n",
        "    ]\n",
        ")\n",
        "\n",
        "embedded_query = embeddings_model.embed_query('첫인사를 하고 이름을 물어봤나요?')\n",
        "print(str(len(embedded_query))+'차원')\n",
        "\n",
        "for embedding in embeddings:\n",
        "    print(cos_sim(embedding, embedded_query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUgV7PY8vgde",
        "outputId": "865721ec-35c7-46a3-f102-c191835ef394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "768차원\n",
            "0.6051636939358793\n",
            "0.620231830582371\n",
            "0.7160855778483425\n",
            "0.6574387494383126\n",
            "0.55527388841408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google GenAI의 Embedding 모델\n",
        "# 텍스트를 특정 너비로 감싸는 데 사용되는 라이브러리를 가져옵니다.\n",
        "import textwrap\n",
        "# 과학 계산을 위한 라이브러리인 numpy를 가져옵니다.\n",
        "import numpy as np\n",
        "# 데이터 분석을 위한 라이브러리인 pandas를 가져옵니다.\n",
        "import pandas as pd\n",
        "# Google의 생성적 AI 모듈을 가져옵니다.\n",
        "import google.generativeai as genai\n",
        "# Google의 생성적 언어 모델을 가져옵니다.\n",
        "import google.ai.generativelanguage as glm\n",
        "# IPython 환경에서 Markdown 형식의 텍스트를 표시하기 위한 모듈을 가져옵니다.\n",
        "from IPython.display import Markdown\n",
        "# genai 라이브러리의 list_models 함수를 사용하여 사용 가능한 모델들의 목록을 가져옵니다.\n",
        "\n",
        "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "for m in genai.list_models():\n",
        "    # 각 모델의 supported_generation_methods 속성 중 'embedContent' 메소드를 지원하는지 확인합니다.\n",
        "    if \"embedContent\" in m.supported_generation_methods:\n",
        "        # 'embedContent' 메소드를 지원하는 모델의 이름을 출력합니다.\n",
        "        print(m.name)\n",
        "\n",
        "# 제목을 문자열로 선언합니다.\n",
        "title = \"The next generation of AI for developers and Google Workspace\"\n",
        "# 샘플 텍스트를 문자열로 선언합니다. 여기에는 제목과 본문이 포함되어 있습니다.\n",
        "sample_text = (\n",
        "    \"Title: The next generation of AI for developers and Google Workspace\"\n",
        "    \"\\n\"\n",
        "    \"Full article:\\n\"\n",
        "    \"\\n\"\n",
        "    \"Gemini API & Google AI Studio: An approachable way to explore and prototype with generative AI applications\"\n",
        ")\n",
        "\n",
        "# 사용할 모델의 이름을 문자열로 선언합니다.\n",
        "model = \"models/embedding-001\"\n",
        "# genai.embed_content 함수를 사용하여 콘텐츠의 임베딩을 생성합니다.\n",
        "# 이 함수는 모델, 콘텐츠, 작업 유형, 제목을 인자로 받습니다.\n",
        "embeded = genai.embed_content(\n",
        "    model=model, content=sample_text, task_type=\"retrieval_document\", title=title\n",
        ")\n",
        "\n",
        "# 생성된 임베딩을 출력합니다.\n",
        "print(str(len(embeded['embedding']))+'차원')\n",
        "print(embeded)\n",
        "\n",
        "\n",
        "text=\"진희는 강아지를 키우고 있습니다. 진희가 키우고 있는 동물은?\"\n",
        "# genai.embed_content 함수를 사용하여 콘텐츠의 임베딩을 생성합니다.\n",
        "# 이 함수는 모델, 콘텐츠, 작업 유형, 제목을 인자로 받습니다.\n",
        "embeded = genai.embed_content(\n",
        "    model=model, content=text\n",
        ")\n",
        "\n",
        "# 생성된 임베딩을 출력합니다.\n",
        "print(str(len(embeded['embedding']))+'차원')\n",
        "print(embeded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "Rg4njtr0VMcM",
        "outputId": "05738686-97a1-496c-8766-1352f0e5fc3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "768차원\n",
            "{'embedding': [0.03411343, -0.05517662, -0.020209055, -0.0041249567, 0.058917783, 0.014129515, 0.0045353593, 0.0014303668, 0.05976634, 0.08292115, 0.007162964, 0.0069041685, -0.053083427, -0.010905125, 0.0321402, -0.037163995, 0.050372455, 0.019348344, -0.037328612, 0.026647927, 0.030781753, -0.011288501, -0.031485256, -0.060248993, -0.026219442, -0.009794235, 0.006630139, -0.01846516, -0.026324715, 0.020442624, -0.06317684, 0.014559574, -0.052296035, 0.016451128, -9.720217e-05, -0.051706687, -0.0054406044, -0.056967627, 0.011144145, -0.009201792, -0.0021951047, -0.1099701, -0.011712193, 0.021221714, 0.009171804, -0.029621972, 0.034534883, 0.039578073, 0.019021519, -0.06269169, 0.039473332, 0.052403256, 0.061814185, -0.034507945, -0.009557816, -0.0049551064, 0.017839009, -0.021176832, 0.015043588, 0.015390569, -0.006334281, 0.043696404, -0.028341983, 0.028433999, 0.01472686, -0.06585564, -0.044533554, 0.0055523133, 0.035775978, 0.031099156, 0.027357662, 0.028062241, 0.056972917, -0.054656833, -0.027864764, -0.15486294, -0.027930057, 0.043678433, 0.008391214, 0.020209847, 0.002841071, -0.07201404, -0.05025868, -0.034896467, -0.030400582, 0.016623711, -0.050455835, -0.025557702, 0.0050540236, 0.032266915, -0.018223321, -0.04913693, 0.07667526, -0.03066128, -0.0127946865, 0.107169494, -0.0563475, -0.016773727, -0.010336115, -0.05220995, -0.022049127, 0.00478732, -0.039094422, 0.015671168, 0.041542538, 0.016112784, -0.022650082, 0.002988097, -0.061147556, 0.06630078, -0.057244215, -0.013767544, -0.003466806, -0.053994596, 0.04230463, -0.029314812, 0.021347178, 0.04522084, 0.0072983643, 0.0247336, 0.020755325, 0.025620919, 0.021721177, 0.008178421, -0.063603185, 0.025854606, -0.037521806, 0.020877894, 0.033131972, 0.030288944, 0.0033810628, -0.048698667, -0.027295412, 0.05622969, 0.029634966, 0.029705161, 0.010602056, -0.02217137, 0.03195607, 0.047208548, -0.013620148, 0.038463745, 0.0052672145, -0.024868716, -0.0071725682, 0.069668904, -0.092124775, 0.014151632, 0.0057337824, -0.006012909, -0.035946254, 0.0334855, -0.07426327, 0.033595767, 0.033740804, 0.0394573, -0.048899952, 0.06265119, 0.0028897377, 0.0039847936, 0.0329678, -0.012809373, 0.050108086, 0.009314281, -0.019499086, -0.048860364, -0.015204039, 0.008016007, 0.015667893, 0.03903864, 0.011732032, 0.034669068, -0.01226258, -0.052623957, 0.006695629, -0.05849198, 0.00101155, -0.009621011, -0.0052014636, -0.020959012, -0.02466722, -0.03861565, 0.049754824, 0.048655674, 0.0044479654, -0.020404046, 0.101043485, -0.022594253, -0.06822699, 0.044780556, -0.03859346, -0.015194885, -0.0059435116, -0.016267126, 0.0012126336, 0.054198146, 0.01978253, 0.02905382, 0.034172967, -0.0032252679, 0.020003818, 0.07212547, 0.035888623, -0.00029856138, 0.0044168616, 0.036989234, 0.100975856, 0.0048228516, -0.04405796, 0.00039434276, -0.044601627, -0.011658614, 0.03398768, 0.02250937, 0.034583274, -0.03440395, -0.003274625, -0.005927225, -0.007679341, -0.025777208, -0.02205426, 0.00823437, -0.027172998, -0.015607741, -0.022958823, 0.098416075, -0.045472592, 0.031623535, 0.030663209, -0.03987397, 0.0048750523, 0.057770126, 0.04547866, 0.009881574, 0.044948515, 0.012011639, 0.003141497, 0.0016209317, 0.07142094, 0.025111957, -0.049478546, 0.052195616, 0.041401174, 0.0380032, -0.05878786, -0.007194873, -0.015402912, 0.048243146, 0.025205499, 0.051020827, -0.030305905, -0.031656887, -0.008994425, 0.039839912, -0.043015696, 0.008373317, -0.089018084, -0.045301914, -0.0074205245, 0.0049243467, 0.060365975, -0.06462967, 0.00815101, -0.020417998, 0.00030822973, -0.039288856, 0.04017253, 0.03137731, -0.031728875, 0.03444872, -0.031234143, -0.048502136, 0.033941768, 0.034225147, -0.008299359, 0.033098515, -0.012317135, 0.014448822, 0.06187389, -0.059683096, 0.0012899865, 0.007460227, 0.02652167, -0.07248658, -0.05818953, 0.030052334, -0.015347992, -0.035913672, -0.034901086, -0.0661791, -0.055562418, 0.0130468095, -0.0035763406, -0.0086615095, -0.046888705, -0.005326655, -0.021710252, 0.072175056, 0.038597208, -0.038364347, -0.005039459, -0.07634857, -0.045539834, -0.07372115, 0.018378831, -0.032071035, -0.030269828, -0.044599615, 0.05132602, 0.04769642, 0.0014855171, -0.028435005, -0.0016777773, 0.0072506564, 0.08448479, 0.04224268, -0.029304115, 0.02165559, 0.0056837583, 0.06214723, 0.0028552667, 0.015904495, -0.016737062, -0.0040876116, -0.037475582, 0.04675168, -0.052556172, -0.016293239, -0.014435561, 0.022127734, -0.0052535324, 0.0190588, -0.011537659, 0.0484614, 0.028816467, 0.024607794, -0.043762755, 0.011608192, 0.0021703655, -0.045297306, -0.0048169023, -0.0071430723, 0.011705694, -0.05006429, 0.029933244, -0.020802287, -0.07580785, -0.012268235, 0.07616304, 0.006857885, 0.01853518, 0.043729052, -0.032221675, -0.010121849, -0.019831154, -0.032731093, 0.051531196, 0.0024111927, 0.090960525, -0.036896333, 0.035708647, 0.03678696, 0.00832481, 0.001757778, 0.04144341, 0.042203393, 0.0045936033, 0.021837635, 0.0066275136, 0.0069022025, -0.008452904, -0.03277543, 0.0061044246, -0.02500629, 0.012441071, 0.018081166, -0.06230864, -0.040046707, -0.019351328, 0.0007255696, 0.002202931, -0.041990966, 0.023313772, 0.039377946, -0.0012839311, 0.010378518, 0.0025737497, 0.043841247, -0.0067742136, 0.045794934, 0.01388272, 0.032243907, 0.0919292, 0.03760722, 0.0060486114, 0.010843367, 0.001991803, -0.04838942, -0.006412631, -0.030764624, -0.015602797, -0.048885867, -0.015245706, -0.0006477355, 0.013608845, 0.0040335134, -0.0015530499, -0.008402027, -0.05728556, -0.027370622, 0.019342335, -0.039145477, 0.049000833, -0.052876346, -0.060248777, 0.009484413, 0.011271402, -0.0019944878, -0.013369263, -0.0130786, 0.0050903647, -0.0003995775, 0.04580157, -0.030488051, -0.07777237, 0.022998745, -0.007693635, -0.013473893, 0.0071830116, 0.014312745, 0.019949466, 0.034036275, -0.0011623668, 0.022655929, -0.0049825236, -0.036455333, 0.0033899196, 0.020583669, -0.010457001, 0.027299065, 0.034606297, -0.0111719165, -0.013660416, -0.02705466, -0.05144293, -0.07396907, -0.022817062, -0.0064836126, 0.037774086, -0.06774259, 0.016620712, -0.046481006, -0.030288063, -0.055035893, -0.015402408, -0.014477583, 0.0024700973, 0.024081903, -0.008900536, -0.0032105052, 0.026591286, -0.027869076, -0.014552753, -0.026460772, 0.06831125, -0.019622969, -0.028588912, -0.02271201, 0.0019694276, 0.0079966, -0.013207389, -0.07246265, -0.005246626, -0.03556684, 0.014131167, 0.0018361827, -0.084728725, 0.010380415, -0.038140625, 0.0066234693, -0.023485202, 0.05133969, 0.018931301, -0.0077241925, -0.01968148, -0.0615474, 0.036711216, 0.028462604, -0.02205502, 0.02294784, 0.03529192, 0.044653304, -0.029656367, -0.04243813, -0.024271922, 0.008206945, -0.015324323, 0.028326686, 0.0708875, 0.03499979, -0.04111004, -0.02691298, -0.011054021, 0.035632536, 0.057256706, -0.058149684, 0.022313014, -0.03727344, 0.0095027555, -0.0325091, -0.007395906, 0.009455788, 0.0053972304, -0.028935568, 0.054196633, -0.051867362, -0.010642803, 0.034427024, 0.04308132, 0.020671992, 0.068610825, 0.018303277, -0.08433639, 0.0023544622, -0.009237108, -0.0410166, 0.012912618, -0.035220295, 0.032994937, -0.0063333404, -0.028377546, 0.05429965, -0.022590995, -0.033762764, -0.0061482205, 0.0014308131, 0.05402618, -0.030298075, -0.020893354, 0.04020406, -0.013849863, -0.047842298, 0.032006662, 0.037729368, -0.02878951, 0.002758488, -0.0023380243, -0.052403864, 0.021707276, -0.02718091, 0.0045513017, 0.02493268, -0.016037108, 0.009521465, 0.022595555, -0.03332406, -0.01791281, -0.026219219, 0.015336862, 0.018615942, 0.0014700901, 0.005194217, -0.0059983027, -0.002134208, 0.055935774, 0.0002028429, -0.01381741, 0.0005677742, 0.052481145, -0.0056857914, -0.024219796, -0.0074823913, 0.041230515, 0.005571935, 0.06841099, -0.025634678, -0.037456885, -0.0021465495, -0.05163424, 0.048833348, 0.057269894, -0.0017718605, -0.012836743, 0.054180846, -0.032427873, -0.003244846, 0.01254491, 0.0071952185, 0.02080726, 0.015043071, -0.08000574, 0.047099367, -0.009071923, 0.022494175, -0.007407801, -0.018199192, 0.01923855, -0.016820459, 0.026590073, 0.05919531, -0.015211094, -0.051043298, 0.05085604, -0.027980763, -0.01785205, 0.05260401, 0.0039136643, -0.010834236, 0.015846392, 0.011993318, 0.0085244095, -0.09705911, 0.004848937, -0.03151453, -0.049902532, -0.023312563, 0.0169847, 0.051852323, -0.018586924, -0.011750037, 0.020324359, 0.041236103, 0.046270456, 0.045885824, 0.035645086, 0.027820086, -0.054944187, -0.0018159872, 0.06008568, 0.056207847, 0.03509413, 0.07476336, 0.00042090056, -0.01791933, -0.049269866, 0.013118644, 0.03817175, 0.03985353, -0.023338122, -0.05917611, -0.040447813, -0.014515073, -0.01641867, -0.012444603, -0.015801677, 0.01694387, -0.012097041, -0.10444289, -0.044068433, 0.028175205, 0.0032158983, 0.017225135, 0.024197249, 0.0003871886, 0.008296747, 0.0020322825, -0.06488942, -0.028532177, 0.03631236, -0.021784041, -0.028676897, 0.020023972, -0.015093374, -0.0053404626, -0.035407133, -0.03022746, -0.045240995, -0.089037456, -0.05241791, 0.01601896, -0.058039088, 0.06633133, 0.01435994, 0.0024608225, 0.02044063, 0.049869247, 0.013966787, 0.011062478, 0.023516618, 0.010368709, 0.039040443, -0.03096598, -0.01665127, 0.010691767, -0.0089797005, 0.018564576, 0.03291386, 0.0032383145, -0.00884169, -0.008645399, 0.0001677955, -0.04452774, 0.007207213, -0.008696507, 0.0023566217, -0.025329702, -0.042708885, -0.03173582, 0.06427912, 0.030916397, -0.022305708, -0.018711232, -0.008136281, -0.01636213, 0.019092057, 0.010243902, -0.04405114, 0.018331835, -0.025844995, 0.035896596, 0.049257137, -0.053962618, -0.084952496, -0.009314442, -0.03644633, 0.0010881334, -0.042904764, 0.016017154, -0.011390375, 0.056498464, 0.007735383, 0.015750613, 0.023586866, -0.005065194, -0.05339934, 0.030084236, -0.021841932, -0.0035868485, -0.025362536, 0.0315042, 0.039552346, -0.032164883, -0.03519624, -0.013936666, 0.006526046, 0.02818671, -0.018081086, 0.04806136, -0.04418975, -0.064630605, -0.010125073, -0.02926605, 0.022641547, 0.040159058, 0.022463534, -0.04924557, -0.010198766, -0.019940902, -0.0033762371, -0.07010838, -0.031799905, -0.020567331, -0.015259151, 0.04870838, 0.030047685, -0.016861487, 0.020778332, -0.034649372, -0.0026895248, -0.0053685517, -0.03297844, -0.0048753927, -0.005587019, -0.041837722, 0.0161564, 0.072810896, -0.043315165, 0.03330332]}\n",
            "768차원\n",
            "{'embedding': [0.054843746, -0.058581058, -0.019897586, -0.0017663339, 0.029070921, -0.0057575023, 0.020625718, -0.012160993, 0.020421693, 0.031018129, 0.033817846, 0.014122755, 0.0006220173, -0.038810074, -0.02861183, -0.024272386, 0.00927779, -0.00792477, 0.042048242, -0.030893829, 0.008289451, 0.0044056294, -0.04625419, -0.008019856, -0.009024553, -0.046495218, -0.013070962, -0.033591338, -0.04385253, 0.06386754, -0.054670244, 0.03634559, -0.10055453, -0.01781741, 0.00076326204, -0.044195402, -0.005572735, 0.015877293, 0.023237122, 0.051023368, 0.01149229, -0.014820885, -0.06324471, -0.02994299, 0.0033564474, -0.011722816, 0.01878415, -0.0075198286, 0.041480687, -0.056625675, 0.005034629, 0.003286289, 0.06533547, -0.02565847, -0.020821031, -0.035840422, 0.006843424, 0.0048874076, 0.011744068, 0.01700335, 0.014097667, 0.015611321, -0.03628886, 0.093234316, -0.028957266, -0.013165717, -0.010430285, 0.024245162, 0.07572696, -0.015472902, 0.05038936, -0.017629892, 0.05219583, -0.024849666, -0.055331454, -0.08943086, -0.041345768, 0.08322464, 0.01410612, -0.03142438, -0.017147632, -0.06961238, -0.01804321, -0.017136022, -0.015665453, 0.035965886, -0.03760785, 0.01264925, 0.010263859, 0.05257626, 0.026929071, -0.0085201105, 0.017068064, -0.081945, -0.008287215, 0.07396927, -0.024371061, -0.008055808, -0.0064819492, -0.022743234, -0.009818665, -0.05790249, -0.033058643, -0.01108588, 0.031447474, 0.009978634, 0.013291388, 0.04415998, -0.01103935, 0.057981934, -0.003336669, -0.011449628, -0.007991294, 0.019066008, 0.027370706, -0.062328883, 0.014581486, 0.08178542, 0.07169404, 0.020532383, -0.01588534, -0.0015036996, 0.04278103, 0.04107482, 0.009246692, 0.013227745, -0.0027886406, 0.014654084, 0.08699878, 0.061784685, -0.023287332, -0.04361759, 0.02571579, 0.009389849, 0.02227584, 0.02254423, 0.018954637, 0.031318314, 0.05779377, 0.0060488745, -0.03245001, 0.020084143, -0.030583581, 0.02630803, 0.01814357, 0.04142794, -0.016086297, -0.051148538, 0.065773174, -0.033520635, -0.03281567, -0.05391822, -0.022390429, 0.043982178, 0.06655797, 0.029339425, -0.060350716, 0.013168367, -0.007944965, 0.036679883, 0.07085713, 0.051708855, 0.04115717, -0.0058953133, -0.009761633, -0.039321166, 0.015818315, -0.009388708, 0.011456819, 0.03669942, -0.0015929136, 0.013287417, -0.06657639, -0.057923857, -0.011865803, -0.050186973, 0.009886141, -0.03255958, -0.034901593, 0.00635014, -0.03204789, -0.06758266, 0.011529504, 0.024384163, 0.009605132, -0.06727176, 0.07353639, -0.009657852, -0.019698286, -0.032147717, 0.025427451, -0.044363678, -0.006670543, 0.0026900668, 0.0036994487, 0.03480386, 0.018354673, 0.021842925, 0.011899024, -0.025965858, -0.020353848, 0.064935625, 0.019070748, 0.006836591, 0.06306441, -0.038840923, 0.057934035, -0.026682096, -0.031146204, 0.032625243, -0.03658227, 0.042172987, -0.06840317, 0.007219157, 0.025500977, -0.011018242, 0.027530933, 0.04735681, 0.022236139, -0.025404694, 0.0073407483, 0.035207767, -0.054765496, 0.0011156462, 0.025672521, 0.028903987, -0.027505685, 0.034626916, -0.012150596, -0.027217075, 0.0034509206, 0.06100563, 0.07329388, -0.028288022, 0.05392365, -0.019842625, 0.03230911, 0.010195535, 0.018613921, -0.0006169085, -0.04536905, 0.038298663, 0.061112814, 0.013080217, -0.0323175, -0.049653135, 0.018387971, 0.0638665, -0.0012034451, 0.017347945, -0.02247559, -0.06539748, -0.0008005216, 0.04696262, -0.06507276, 0.038753994, -0.06751955, 0.015404021, -0.009964547, 0.04203699, 0.055961393, 0.012098297, 0.024049778, -0.019209025, -0.017788729, 0.032861896, 0.047629032, -0.030829066, -0.008399364, -0.02710352, 0.00934215, -0.07774335, 0.08244497, 0.016075889, -0.024942169, 0.030937038, -0.011808083, 0.041972537, 0.0082046855, -0.02948597, -0.024214333, -0.011672767, -0.00084790034, -0.03947782, -0.028370872, -0.027814202, -0.051112622, -0.014057901, 0.053115133, -0.03600577, -0.06102281, -0.014414677, -0.008738715, 0.00025424716, -0.033947486, 0.025960863, -0.025060631, 0.022042945, 0.002601195, 0.011643715, 0.022315713, 0.0236843, 0.00085941626, -0.0434076, 0.022862135, 0.014837881, -0.039124623, -0.042288292, -0.020157868, -0.0043806373, -0.030388238, -0.005659292, -0.07445525, -0.0031676055, 0.0034432034, 0.023028724, -0.046523787, 0.026618429, -0.02361191, 0.041228157, -0.01818947, 0.0457252, 0.0078070625, -0.009178675, 0.028150039, -0.0010648853, -0.037767455, 0.056801647, -0.0062064077, -0.025539527, -0.041121896, -0.007816442, -0.018811982, 0.017036961, 0.026536051, 0.05868703, -0.081727855, -0.017239546, -0.037374303, 0.00089340936, 0.04239679, -0.0024399078, -0.03908347, -0.07229061, -0.01338501, -0.03221466, -0.020304358, 0.0024362658, 0.052447025, 0.0003890146, -0.01325952, 0.09272853, -0.025139136, -0.026751243, -0.007671534, -0.073957495, 0.049638975, -0.018372424, 0.011350606, -0.05447495, -0.011510237, 0.039921016, -0.010379897, 0.03417562, -0.008454714, -0.005773268, 0.035054557, 0.0014120041, -0.017147508, 0.0044414387, 0.000766596, -0.034244817, 0.025782442, -0.026006699, -0.03361508, -0.06342385, -0.038717203, -0.014830335, 0.02118479, -0.019985871, -0.051455285, -0.006752686, 0.046952978, 0.05622775, 0.032193977, -0.017995397, 0.032316532, 0.050940495, 0.042857785, 0.036730144, 0.055387132, 0.011411945, 0.02100827, 0.029263336, 0.011029483, 0.015344243, -0.025290854, -0.053478245, 0.012123254, -0.025379963, -0.011276567, -0.03919355, -0.035247877, -0.04230424, -0.027609995, -0.050876234, -0.02382003, -0.0014566992, -0.031640112, -0.023603348, 0.001356336, 0.059967134, 0.021185845, -0.11405691, -0.061018355, -0.028512694, 0.052718893, -0.0037128702, 0.02418825, 0.027301522, 0.014848707, 0.03472745, -0.039180648, -0.03627376, -0.037601627, -0.051389918, -0.043601837, -0.028130878, -0.021606235, 0.02654582, 0.016010221, 0.0034465275, -0.01407335, -0.0328256, 0.0025416922, -0.046039954, 0.01275864, 0.03475831, 0.0120472815, -0.038339365, -0.021626959, -0.026938142, 0.03938696, 0.052277725, -0.08672662, -0.018662633, 0.026950093, -0.028684579, 0.05053692, -0.07660663, 0.012765714, -0.06743795, -0.038337693, -0.05454597, -0.06167282, -0.052753977, 0.035305154, 0.020245459, -0.030261692, 0.03253155, -0.022604577, 0.006195844, -0.02672642, -0.07267925, 0.047430128, -0.02836476, 0.046153966, 0.0020571118, 0.04503747, 0.045622528, 0.022686977, -0.020542791, -0.0040744315, 0.013289022, -0.0324465, 0.02103617, -0.075643264, 0.0043364125, -0.011499108, -0.046080936, -0.020617446, -0.011623073, 0.03946207, 0.026094362, -0.005153921, 0.001966455, -0.008146198, -0.017040273, 0.00939113, 0.04229409, -0.026300265, 0.0038289134, -0.020361189, -0.037334595, 0.024727842, 0.014013394, -0.040289138, -0.012913278, 0.020254241, 0.016379397, -0.018282939, -0.0028274069, 0.021102145, -0.010864298, 0.01954481, -0.08003087, 0.033322964, -0.012482792, -0.020868134, -0.02164382, 0.012325435, 0.0038214454, 0.047528315, -0.004349879, 0.049201574, 0.01866014, -0.038380537, 0.0428705, 0.02998638, -0.015444119, 0.03352443, -0.0042441348, -0.13327767, -0.014077764, 0.020418083, -0.064180404, 0.04301766, 0.021363406, -0.014964494, -0.031211779, -0.014935245, 0.08542472, -0.078642115, -0.024950009, 0.0004346852, -0.014739942, -0.026196532, 0.02065075, 0.024160303, -0.0004187664, -0.0003468962, 0.017365374, -0.0018945894, 0.01076294, 0.014879114, 0.024622219, -0.012754307, -0.10059341, 0.0015258787, -0.0058711637, -0.01140205, -0.03625902, -0.005960986, -0.039611455, 0.016198952, -0.026806543, -0.02252275, -0.03767314, 0.022954864, -0.0017818101, -0.033303853, -0.05199156, -0.0037084133, -0.036201257, 0.07600059, 0.032496523, 0.011749648, -0.019118728, 0.065794446, -0.02047061, 0.0184878, -0.0018934744, 0.03260105, 0.013659993, 0.040669717, -0.035137564, -0.010480408, -0.01747755, 0.027177457, 0.0058796643, 0.010870376, -0.0018999187, 0.02942216, 0.025846062, -0.0034579528, 0.021806464, 0.029851794, 0.0031602893, 0.04415413, 0.033605915, -0.06317112, 0.07339438, -0.048829574, 0.014847358, 0.023103649, -0.0074062003, -0.044894207, 0.007923719, 0.0038590017, -0.023280786, 0.03907225, -0.03960667, 0.04218756, -0.03084813, 0.027968567, 0.0041806204, -0.012489182, -0.020477414, -0.016682902, 0.0004245393, 0.002697497, -0.01680816, 0.036866836, -0.014289387, -0.060138945, 0.026303234, 0.049755115, -0.0038955058, -0.040593058, -0.069627635, 0.02333726, -0.05478558, -0.023412952, 0.023735851, 0.053576536, 0.0106350025, 0.033905163, -0.029309317, 0.039088476, -0.008383196, 0.019745093, 0.055139698, 0.0056781755, -0.0053684097, -0.027590374, 0.013225286, -0.009597591, 0.008952743, 0.017210273, -0.0040170136, -0.0995419, 0.04546855, 0.05175684, -0.033677466, -0.027249344, 0.1070668, 0.017747229, -0.06863393, -0.023744665, 0.0026338215, -0.031804945, 0.013801143, 0.019498313, 0.010673239, -0.00023158504, -0.023344152, -0.03242791, -0.025664026, -0.0012725461, -0.009544118, -0.03667804, -0.0037873308, -0.01693867, -0.016647767, -0.017232794, -0.028198365, -0.08189828, -0.007037337, -0.04368579, 0.020485258, -0.053272143, 0.039982934, 0.059570342, -0.011532538, -0.004242546, 0.051791556, -0.026911726, 0.026864342, 0.004838321, 0.012159357, -0.025033692, -0.04460155, -0.012253947, -0.032121193, 0.021178644, 0.04232097, 0.020042133, -0.0069203926, 0.013090432, -0.04094695, 0.015201011, -0.011625365, -0.057706613, 0.022126729, 0.051221445, -0.016049871, -0.02021609, 0.018197503, -0.017609337, 0.038752865, -0.0050260983, -0.053044062, -0.00881059, 0.02861837, -0.021129845, 0.042592272, -0.0030798933, 0.018807517, 0.021740492, 0.012004232, 0.04267284, -0.022435535, -0.09231897, 0.02138924, -0.013570264, -0.05906507, 0.035449, 0.0136593925, -0.023852304, 0.05848755, 0.065136045, 0.03160983, 0.035098083, -0.01927673, -0.04950591, 0.020443913, -0.03890607, 0.06505175, -0.0013526937, -0.0020388244, 0.10846535, 0.010428647, -0.047407124, 0.032529, -0.052487962, 0.053684223, -0.008273884, 0.04926278, -0.03734766, -0.03682752, -0.05113083, -0.019343834, 0.017845944, 0.054409586, -0.014005119, -0.031780615, 0.044583537, -0.035778146, -8.184577e-05, -0.04296958, -0.06615992, 0.017480198, -0.023362344, 0.0030373977, 0.050115786, 0.0024762312, -0.017006833, 0.01595305, 0.005094877, 0.012200623, -0.049848747, 0.05626995, 0.044056058, -0.021174276, 0.0014173074, 0.013604944, 0.0050727967, 0.0234695]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3) Vector Store**"
      ],
      "metadata": {
        "id": "euIwIhCSOTLp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[벡터저장소]** FAISS(Facebook AI Similarity Search)"
      ],
      "metadata": {
        "id": "q8f36ZlyfK8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FAISS 유사도 기반 검색\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, Language\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_community.vectorstores.utils import DistanceStrategy\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=400,\n",
        "    chunk_overlap=40,\n",
        "    length_function=len,\n",
        ")\n",
        "\n",
        "embeddings_model = OpenAIEmbeddings()\n",
        "\n",
        "document = TextLoader(\"appendix-keywords.txt\").load()\n",
        "split_docs = splitter.split_documents(document)\n",
        "print(f'총 분할된 도큐먼트 수: {len(split_docs)}')\n",
        "\n",
        "#vector store\n",
        "vs = FAISS.from_documents(\n",
        "    split_docs,\n",
        "    embedding = embeddings_model,\n",
        "    #distance_strategy = DistanceStrategy.EUCLIDEAN_DISTANCE\n",
        "    #distance_strategy = DistanceStrategy.COSINE\n",
        ")\n",
        "print(f\"{vs.distance_strategy}\\n\")\n",
        "\n",
        "query = \"FAISS가 뭐야?\"\n",
        "docs = vs.similarity_search(query)\n",
        "print(docs[0].page_content + \"\\n========\\n\")\n",
        "\n",
        "query = \"Pandas란?\"\n",
        "docs = vs.similarity_search(query)\n",
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0FZ0gsla_9b",
        "outputId": "51ec967c-bdb2-471a-958d-221acebfc9fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 분할된 도큐먼트 수: 19\n",
            "EUCLIDEAN_DISTANCE\n",
            "\n",
            "FAISS (Facebook AI Similarity Search)\n",
            "\n",
            "정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\n",
            "예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\n",
            "연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\n",
            "\n",
            "Open Source\n",
            "\n",
            "정의: 오픈 소스는 소스 코드가 공개되어 누구나 자유롭게 사용, 수정, 배포할 수 있는 소프트웨어를 의미합니다. 이는 협업과 혁신을 촉진하는 데 중요한 역할을 합니다.\n",
            "예시: 리눅스 운영 체제는 대표적인 오픈 소스 프로젝트입니다.\n",
            "연관키워드: 소프트웨어 개발, 커뮤니티, 기술 협업\n",
            "========\n",
            "\n",
            "판다스 (Pandas)\n",
            "\n",
            "정의: 판다스는 파이썬 프로그래밍 언어를 위한 데이터 분석 및 조작 도구를 제공하는 라이브러리입니다. 이는 데이터 분석 작업을 효율적으로 수행할 수 있게 합니다.\n",
            "예시: 판다스를 사용하여 CSV 파일을 읽고, 데이터를 정제하며, 다양한 분석을 수행할 수 있습니다.\n",
            "연관키워드: 데이터 분석, 파이썬, 데이터 처리\n",
            "\n",
            "GPT (Generative Pretrained Transformer)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FAISS MMR(Maximum marginal relevances search) 검색\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, Language\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_community.vectorstores.utils import DistanceStrategy\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=400,\n",
        "    chunk_overlap=40,\n",
        "    length_function=len,\n",
        ")\n",
        "\n",
        "embeddings_model = OpenAIEmbeddings()\n",
        "\n",
        "document = TextLoader(\"appendix-keywords.txt\").load()\n",
        "split_docs = splitter.split_documents(document)\n",
        "print(f'총 분할된 도큐먼트 수: {len(split_docs)}')\n",
        "\n",
        "#vector store\n",
        "vs = FAISS.from_documents(\n",
        "    split_docs,\n",
        "    embedding = embeddings_model,\n",
        "    #distance_strategy = DistanceStrategy.EUCLIDEAN_DISTANCE\n",
        "    distance_strategy = DistanceStrategy.COSINE\n",
        ")\n",
        "print(f\"{vs.distance_strategy}\\n\")\n",
        "\n",
        "query = \"FAISS가 뭐야?\"\n",
        "mmr_docs = vs.max_marginal_relevance_search(query, k=2, fetch_k=5)\n",
        "print(mmr_docs[0].page_content + \"\\n========\\n\")\n",
        "\n",
        "query = \"Pandas란?\"\n",
        "mmr_docs = vs.max_marginal_relevance_search(query, k=2, fetch_k=5)\n",
        "print(mmr_docs[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFxGbGv61o6c",
        "outputId": "2f841878-9d05-4e8e-8193-6b7f75389a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 분할된 도큐먼트 수: 19\n",
            "COSINE\n",
            "\n",
            "FAISS (Facebook AI Similarity Search)\n",
            "\n",
            "정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\n",
            "예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\n",
            "연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\n",
            "\n",
            "Open Source\n",
            "\n",
            "정의: 오픈 소스는 소스 코드가 공개되어 누구나 자유롭게 사용, 수정, 배포할 수 있는 소프트웨어를 의미합니다. 이는 협업과 혁신을 촉진하는 데 중요한 역할을 합니다.\n",
            "예시: 리눅스 운영 체제는 대표적인 오픈 소스 프로젝트입니다.\n",
            "연관키워드: 소프트웨어 개발, 커뮤니티, 기술 협업\n",
            "========\n",
            "\n",
            "판다스 (Pandas)\n",
            "\n",
            "정의: 판다스는 파이썬 프로그래밍 언어를 위한 데이터 분석 및 조작 도구를 제공하는 라이브러리입니다. 이는 데이터 분석 작업을 효율적으로 수행할 수 있게 합니다.\n",
            "예시: 판다스를 사용하여 CSV 파일을 읽고, 데이터를 정제하며, 다양한 분석을 수행할 수 있습니다.\n",
            "연관키워드: 데이터 분석, 파이썬, 데이터 처리\n",
            "\n",
            "GPT (Generative Pretrained Transformer)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[벡터저장소]** FAISS 로컬 DB Save & Load"
      ],
      "metadata": {
        "id": "hmOsrpgugFss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 벡터저장소(FAISS)\n",
        "#!pip install -q faiss-cpu\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, Language\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        "    chunk_size=400,\n",
        "    chunk_overlap=40,\n",
        "    length_function=len,\n",
        ")\n",
        "\n",
        "embedding_model = OpenAIEmbeddings()\n",
        "faiss_dir = \"faiss-index\"\n",
        "doc_file_path = \"appendix-keywords.txt\"\n",
        "\n",
        "if(os.path.isdir(faiss_dir) == False):\n",
        "    document = TextLoader(doc_file_path).load()\n",
        "    split_docs = splitter.split_documents(document)\n",
        "    print(f'총 분할된 도큐먼트 수: {len(split_docs)}')\n",
        "\n",
        "    vs = FAISS.from_documents(split_docs, embedding_model)\n",
        "    vs.save_local(faiss_dir)\n",
        "    print(\"saved\")\n",
        "else:\n",
        "    vs = FAISS.load_local(faiss_dir, embedding_model, allow_dangerous_deserialization=True)\n",
        "    print('loaded')\n",
        "\n",
        "query = \"FAISS가 뭐야?\"\n",
        "#query = \"Pandas란?\"\n",
        "docs = vs.similarity_search(query)\n",
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGXf4e7tftOQ",
        "outputId": "259880ab-1711-4942-ad15-93074ab1c010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded\n",
            "FAISS (Facebook AI Similarity Search)\n",
            "\n",
            "정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\n",
            "예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\n",
            "연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\n",
            "\n",
            "Open Source\n",
            "\n",
            "정의: 오픈 소스는 소스 코드가 공개되어 누구나 자유롭게 사용, 수정, 배포할 수 있는 소프트웨어를 의미합니다. 이는 협업과 혁신을 촉진하는 데 중요한 역할을 합니다.\n",
            "예시: 리눅스 운영 체제는 대표적인 오픈 소스 프로젝트입니다.\n",
            "연관키워드: 소프트웨어 개발, 커뮤니티, 기술 협업\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[벡터저장소]** Chroma DB"
      ],
      "metadata": {
        "id": "7UPZOY7fg9l3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 벡터저장소(Chroma)\n",
        "#!pip install -q chromadb\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, model_name='gpt-4o')\n",
        "embedding_model = OpenAIEmbeddings()\n",
        "db_dir = \"chroma-db/\"\n",
        "doc_file_path = \"소나기 - 황순원.pdf\"\n",
        "\n",
        "if(os.path.isdir(db_dir) == False):\n",
        "    loader = PyPDFLoader(doc_file_path)\n",
        "    docs = loader.load()\n",
        "    vs = Chroma.from_documents(\n",
        "        docs,\n",
        "        embedding_model,\n",
        "        persist_directory = db_dir,\n",
        "        collection_name = 'shower',\n",
        "        collection_metadata = {'hnsw:space': 'cosine'}, # 유사도 계산에 코사인 유사도를 사용\n",
        "    )\n",
        "    print(\"saved\")\n",
        "else:\n",
        "    vs = Chroma(persist_directory=db_dir, embedding_function=embedding_model)\n",
        "    print('loaded')\n",
        "\n",
        "query = \"소녀는 왜 이사를 오게 되었는가?\"\n",
        "docs = vs.similarity_search(query)\n",
        "print(f'{len(docs)}개')\n",
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qzG6sjsgaAM",
        "outputId": "a933638b-10ed-4ce9-9014-00c307df3bcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved\n",
            "4개\n",
            "- 6 -소년은 소녀네가 이사해 오기 전에 벌써 어른들의 이야기를 들어서 , 윤 초시 손자(孫子)가 \n",
            "서울서 사업에 실패해 가지고 고향에 돌아오지 않을 수 없게 되었다는 걸 알고 있었다 . 그\n",
            "것이 이번에는 고향 집마저 남의 손에 넘기게 된 모양이었다 .\n",
            "“왜 그런지 난 이사 가는 게 싫어졌다 . 어른들이 하는 일이니 어쩔 수 없지만 …….”\n",
            "전에 없이, 소녀의 까만 눈에 쓸쓸한 빛이 떠돌았다 .\n",
            "소녀와 헤어져 돌아오는 길에, 소년은 혼잣속으로 , 소녀가 이사를 간다는 말을 수없이 되\n",
            "뇌어 보았다 . 무어 그리 안타까울 것도 서러울 것도 없었다 . 그렇건만 , 소년은 지금 자기가 \n",
            "씹고 있는 대추알의 단맛을 모르고 있었다 .\n",
            "이 날 밤, 소년은 몰래 덕쇠 할아버지네 호두밭으로 갔다.\n",
            "낯에 봐 두었던 나무로 올라갔다 . 그리고 , 봐 두었던 가지를 향해 작대기를 내리쳤다 . 호두\n",
            "송이 떨어지는 소리가 별나게 크게 들렸다 . 가슴이 선뜩했다 . 그러나 다음 순간, 굵은 호두\n",
            "야 많이 떨어져라 , 많이 떨어져라 , 저도 모를 힘에 이끌려 마구 작대기를 내리 치는 것이\n",
            "었다.\n",
            "돌아오는 길에는 열 이틀 달이 지우는 그늘만 골라 디뎠다 . 그늘의 고마움을 처음 느꼈다 .\n",
            "불룩한 주머니를 어루만졌다 . 호두송이를 맨손으로 깠다가는 옴이 오르기 쉽다는 말 같은 건 아\n",
            "무렇지도 않았다 . 그저 근동에서 제일 가는 이 덕쇠 할아버지네 호두를 어서 소녀에게 맛보여야 \n",
            "한다는 생각만이 앞섰다 .\n",
            "그러다 , 아차 하는 생각이 들었다 . 소녀더러 병이 좀 낫거들랑 이사 가기 전에 한 번 개울\n",
            "가로 나와 달라는 말을 못해 둔 것이었다 . 바보 같은것 , 바보 같은것 .\n",
            "이튿날 , 소년이 학교에서 돌아오니 , 아버지가 나들이옷으로 갈아입고 닭 한 마리를 안고 \n",
            "있었다 .\n",
            "어디 가시느냐고 물었다 .\n",
            "그 말에도 대꾸도 없이, 아버지는 안고 있는 닭의 무게를 겨냥해 보면서 ,\n",
            "“이만하면 될까?”\n",
            "어머니가 망태기를 내주며 ,\n",
            "“벌써 며칠째 ‘걀걀’하고 알 날 자리를 보던데요 . 크진 않아도살은 쪘을 거여요 .”\n",
            "소년이 이번에는 어머니한테 아버지가 어디 가시느냐고 물어 보았다 .\n",
            "“저, 서당골 윤 초시 댁에 가신다 . 제삿상에라도 놓으시라고 …….”\n",
            "“그럼, 큰 놈으로 하나 가져가지 . 저 얼룩수탉으로 …….”\n",
            "이 말에, 아버지는 허허 웃고 나서,\n",
            "“임마, 그래도 이게 실속이 있다.”\n",
            "소년은 공연히 열적어 , 책보를 집어던지고는 외양간으로가 , 쇠잔등을 한 번 철썩 갈겼다 . \n",
            "쇠파리라도 잡는 체.\n",
            "개울물은 날로 여물어 갔다.\n",
            "소년은 갈림길에서 아래쪽으로 가 보았다 . 갈밭머리에서 바라보는 서당골 마을은 쪽빛 하\n",
            "늘 아래 한결 가까워 보였다 .\n",
            "어른들의 말이, 내일 소녀네가 양평읍으로 이사 간다는 것이었다 . 거기 가서는 조그마한 \n",
            "가겟방을 보게 되리라는 것이었다 .\n",
            "소년은 저도 모르게 주머니 속 호두알을 만지작거리며 , 한 손으로는 수없이 갈꽃을 휘어 \n",
            "꺾고 있었다 .\n",
            "그 날 밤, 소년은 자리에 누워서도 같은 생각뿐이었다 . 내일 소녀네가 이사하는 걸 가 보\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4) Retrieval Chain**"
      ],
      "metadata": {
        "id": "2R7YnSjiOpQa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**로그 활성화**"
      ],
      "metadata": {
        "id": "H4doD_3mOPgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "langchain.debug = False\n",
        "langchain.verbose = False"
      ],
      "metadata": {
        "id": "rycJljfROMs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RetrievalQA**"
      ],
      "metadata": {
        "id": "KUCHhRx7h9EN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RetrievalQA\n",
        "#!pip install -q chromadb\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, model_name='gpt-4o-mini')\n",
        "embeddings = OpenAIEmbeddings()\n",
        "doc_file_path = \"소나기 - 황순원.pdf\"\n",
        "\n",
        "loader = PyPDFLoader(doc_file_path)\n",
        "docs = loader.load()\n",
        "db = Chroma.from_documents(docs, embeddings)\n",
        "\n",
        "retriever = db.as_retriever()\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "retriever = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever)\n",
        "\n",
        "query = \"소녀는 왜 이사를 오게 되었는가?\"\n",
        "response = retriever.invoke({\"query\": query})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbVWDbdHh8Jr",
        "outputId": "d99d1515-35a6-4777-c344-efd4eef71d8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': '소녀는 왜 이사를 오게 되었는가?', 'result': '소녀는 윤 초시의 손자가 서울에서 사업에 실패하여 고향으로 돌아오게 되면서, 고향 집마저 남의 손에 넘기게 된 상황 때문에 이사를 오게 되었습니다.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 보너스: 검증된 프롬프트 가져오기\n",
        "from langchain import hub\n",
        "import pprint\n",
        "\n",
        "prompt = hub.pull(\"rlm/rag-prompt\", api_url=\"https://api.hub.langchain.com\")\n",
        "\n",
        "# 프롬프트 내용 출력\n",
        "pprint.pp(prompt.messages[0].prompt.__dict__, indent=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLmrJciqe3JL",
        "outputId": "d59fe07b-7a43-4746-c321-03c4f4012445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{   'name': None,\n",
            "    'input_variables': ['context', 'question'],\n",
            "    'optional_variables': [],\n",
            "    'input_types': {},\n",
            "    'output_parser': None,\n",
            "    'partial_variables': {},\n",
            "    'metadata': None,\n",
            "    'tags': None,\n",
            "    'template': 'You are an assistant for question-answering tasks. Use the '\n",
            "                'following pieces of retrieved context to answer the question. '\n",
            "                \"If you don't know the answer, just say that you don't know. \"\n",
            "                'Use three sentences maximum and keep the answer concise.\\n'\n",
            "                'Question: {question} \\n'\n",
            "                'Context: {context} \\n'\n",
            "                'Answer:',\n",
            "    'template_format': 'f-string',\n",
            "    'validate_template': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LangSmith 를 이용한 모니터링\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"chain-monitor\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"]=\"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\"\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\""
      ],
      "metadata": {
        "id": "lNfe7AlzKuhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RetrievalQA (chain_type=\"stuff\")\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, model_name='gpt-4o-mini')\n",
        "embeddings = OpenAIEmbeddings()\n",
        "doc_file_path = \"소나기 - 황순원.pdf\"\n",
        "\n",
        "loader = PyPDFLoader(doc_file_path)\n",
        "docs = loader.load()\n",
        "db = Chroma.from_documents(docs, embeddings)\n",
        "\n",
        "retriever = db.as_retriever()\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "retriever = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever)\n",
        "\n",
        "query = \"소설 끝에서 소녀는 어떠한 결말을 맞이한거야?\"\n",
        "response = retriever.invoke({\"query\": query})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rcp52na18Te3",
        "outputId": "73eaabbd-cf5f-4172-cc51-ccc8ab755b6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"query\": \"소설 끝에서 소녀는 어떠한 결말을 맞이한거야?\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain > chain:LLMChain] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input_list\": [\n",
            "    {\n",
            "      \"context\": \"- 3 -돌아다보니 , 소녀는 지금 자기가 지나쳐 온 허수아비를 흔들고 있다. 좀 전 허수아비보다 \\n더 우쭐거린다 .\\n논이 끝난 곳에 도랑이 하나 있었다 . 소녀가 먼저 뛰어 건넜다 .\\n거기서부터 산 밑까지는 밭이었다 .\\n수숫단을 세워 놓은 밭머리를 지났다 .\\n“저게 뭐니?”\\n“원두막 .”\\n“여기 참외, 맛있니 ?”\\n“그럼, 참외 맛도 좋지만 수박 맛은 더 좋다.”\\n“하나 먹어 봤으면 .”\\n소년이 참외 그루에 심은 무우밭으로 들어가 , 무우 두 밑을 뽑아 왔다. 아직 밑이 덜 들어 \\n있었다 . 잎을 비틀어 팽개친 후, 소녀에게 한개 건넨다 . 그리고는 이렇게 먹어야 한다는 듯\\n이, 먼저 대강이를 한 입 베물어 낸 다음, 손톱으로 한 돌이 껍질을 벗겨 우쩍 깨문다 .\\n소녀도 따라 했다. 그러나 , 세 입도 못 먹고,\\n“아, 맵고 지려.”\\n하며 집어던지고 만다.\\n“참, 맛 없어 못 먹겠다 .”\\n소년이 더 멀리 팽개쳐 버렸다 .\\n산이 가까워졌다 .\\n단풍이 눈에 따가웠다 .\\n“야아!”\\n소녀가 산을 향해 달려갔다 . 이번은 소년이 뒤따라 달리지 않았다 . 그러고도 곧 소녀보다 \\n더 많은 꽃을 꺾었다 .\\n“이게 들국화 , 이게 싸리꽃 , 이게 도라지꽃 ,…….”\\n“도라지꽃이 이렇게 예쁜 줄은 몰랐네 . 난 보랏빛이 좋아!…… 그런데 , 이 양산 같이 생긴 \\n노란 꽃이 뭐지?”\\n“마타리꽃 .”\\n소녀는 마타리꽃을 양산 받듯이 해 보인다 . 약간 상기된 얼굴에 살포시 보조개를 떠올리\\n며.\\n다시 소년은 꽃 한 옴큼을 꺾어 왔다. 싱싱한 꽃가지만 골라 소녀에게 건넨다 .\\n그러나 소녀는\\n“하나도 버리지 마라.”\\n산마루께로 올라갔다 .\\n맞은편 골짜기에 오순도순 초가집이 몇 모여 있었다 .\\n누가 말할 것도 아닌데 , 바위에 나란히 걸터앉았다 . 유달리 주위가 조용해진 것 같았다 . 따\\n가운 가을 햇살만이 말라가는 풀 냄새를 퍼뜨리고 있었다 .\\n“저건 또 무슨 꽃이지 ?”\\n적잖이 비탈진 곳에 칡덩굴이 엉키어 꽃을 달고 있었다 .\\n“꼭 등꽃 같네. 서울 우리 학교에 큰 등나무가 있었단다 . 저 꽃을 보니까 등나무 밑에서 \\n놀던 동무들 생각이 난다.”\\n소녀가 조용히 일어나 비탈진 곳으로 간다. 꽃송이가 많이 달린 줄기를 잡고 끊기 시작한\",\n",
            "      \"question\": \"소설 끝에서 소녀는 어떠한 결말을 맞이한거야?\"\n",
            "    },\n",
            "    {\n",
            "      \"context\": \"- 3 -돌아다보니 , 소녀는 지금 자기가 지나쳐 온 허수아비를 흔들고 있다. 좀 전 허수아비보다 \\n더 우쭐거린다 .\\n논이 끝난 곳에 도랑이 하나 있었다 . 소녀가 먼저 뛰어 건넜다 .\\n거기서부터 산 밑까지는 밭이었다 .\\n수숫단을 세워 놓은 밭머리를 지났다 .\\n“저게 뭐니?”\\n“원두막 .”\\n“여기 참외, 맛있니 ?”\\n“그럼, 참외 맛도 좋지만 수박 맛은 더 좋다.”\\n“하나 먹어 봤으면 .”\\n소년이 참외 그루에 심은 무우밭으로 들어가 , 무우 두 밑을 뽑아 왔다. 아직 밑이 덜 들어 \\n있었다 . 잎을 비틀어 팽개친 후, 소녀에게 한개 건넨다 . 그리고는 이렇게 먹어야 한다는 듯\\n이, 먼저 대강이를 한 입 베물어 낸 다음, 손톱으로 한 돌이 껍질을 벗겨 우쩍 깨문다 .\\n소녀도 따라 했다. 그러나 , 세 입도 못 먹고,\\n“아, 맵고 지려.”\\n하며 집어던지고 만다.\\n“참, 맛 없어 못 먹겠다 .”\\n소년이 더 멀리 팽개쳐 버렸다 .\\n산이 가까워졌다 .\\n단풍이 눈에 따가웠다 .\\n“야아!”\\n소녀가 산을 향해 달려갔다 . 이번은 소년이 뒤따라 달리지 않았다 . 그러고도 곧 소녀보다 \\n더 많은 꽃을 꺾었다 .\\n“이게 들국화 , 이게 싸리꽃 , 이게 도라지꽃 ,…….”\\n“도라지꽃이 이렇게 예쁜 줄은 몰랐네 . 난 보랏빛이 좋아!…… 그런데 , 이 양산 같이 생긴 \\n노란 꽃이 뭐지?”\\n“마타리꽃 .”\\n소녀는 마타리꽃을 양산 받듯이 해 보인다 . 약간 상기된 얼굴에 살포시 보조개를 떠올리\\n며.\\n다시 소년은 꽃 한 옴큼을 꺾어 왔다. 싱싱한 꽃가지만 골라 소녀에게 건넨다 .\\n그러나 소녀는\\n“하나도 버리지 마라.”\\n산마루께로 올라갔다 .\\n맞은편 골짜기에 오순도순 초가집이 몇 모여 있었다 .\\n누가 말할 것도 아닌데 , 바위에 나란히 걸터앉았다 . 유달리 주위가 조용해진 것 같았다 . 따\\n가운 가을 햇살만이 말라가는 풀 냄새를 퍼뜨리고 있었다 .\\n“저건 또 무슨 꽃이지 ?”\\n적잖이 비탈진 곳에 칡덩굴이 엉키어 꽃을 달고 있었다 .\\n“꼭 등꽃 같네. 서울 우리 학교에 큰 등나무가 있었단다 . 저 꽃을 보니까 등나무 밑에서 \\n놀던 동무들 생각이 난다.”\\n소녀가 조용히 일어나 비탈진 곳으로 간다. 꽃송이가 많이 달린 줄기를 잡고 끊기 시작한\",\n",
            "      \"question\": \"소설 끝에서 소녀는 어떠한 결말을 맞이한거야?\"\n",
            "    },\n",
            "    {\n",
            "      \"context\": \"- 3 -돌아다보니 , 소녀는 지금 자기가 지나쳐 온 허수아비를 흔들고 있다. 좀 전 허수아비보다 \\n더 우쭐거린다 .\\n논이 끝난 곳에 도랑이 하나 있었다 . 소녀가 먼저 뛰어 건넜다 .\\n거기서부터 산 밑까지는 밭이었다 .\\n수숫단을 세워 놓은 밭머리를 지났다 .\\n“저게 뭐니?”\\n“원두막 .”\\n“여기 참외, 맛있니 ?”\\n“그럼, 참외 맛도 좋지만 수박 맛은 더 좋다.”\\n“하나 먹어 봤으면 .”\\n소년이 참외 그루에 심은 무우밭으로 들어가 , 무우 두 밑을 뽑아 왔다. 아직 밑이 덜 들어 \\n있었다 . 잎을 비틀어 팽개친 후, 소녀에게 한개 건넨다 . 그리고는 이렇게 먹어야 한다는 듯\\n이, 먼저 대강이를 한 입 베물어 낸 다음, 손톱으로 한 돌이 껍질을 벗겨 우쩍 깨문다 .\\n소녀도 따라 했다. 그러나 , 세 입도 못 먹고,\\n“아, 맵고 지려.”\\n하며 집어던지고 만다.\\n“참, 맛 없어 못 먹겠다 .”\\n소년이 더 멀리 팽개쳐 버렸다 .\\n산이 가까워졌다 .\\n단풍이 눈에 따가웠다 .\\n“야아!”\\n소녀가 산을 향해 달려갔다 . 이번은 소년이 뒤따라 달리지 않았다 . 그러고도 곧 소녀보다 \\n더 많은 꽃을 꺾었다 .\\n“이게 들국화 , 이게 싸리꽃 , 이게 도라지꽃 ,…….”\\n“도라지꽃이 이렇게 예쁜 줄은 몰랐네 . 난 보랏빛이 좋아!…… 그런데 , 이 양산 같이 생긴 \\n노란 꽃이 뭐지?”\\n“마타리꽃 .”\\n소녀는 마타리꽃을 양산 받듯이 해 보인다 . 약간 상기된 얼굴에 살포시 보조개를 떠올리\\n며.\\n다시 소년은 꽃 한 옴큼을 꺾어 왔다. 싱싱한 꽃가지만 골라 소녀에게 건넨다 .\\n그러나 소녀는\\n“하나도 버리지 마라.”\\n산마루께로 올라갔다 .\\n맞은편 골짜기에 오순도순 초가집이 몇 모여 있었다 .\\n누가 말할 것도 아닌데 , 바위에 나란히 걸터앉았다 . 유달리 주위가 조용해진 것 같았다 . 따\\n가운 가을 햇살만이 말라가는 풀 냄새를 퍼뜨리고 있었다 .\\n“저건 또 무슨 꽃이지 ?”\\n적잖이 비탈진 곳에 칡덩굴이 엉키어 꽃을 달고 있었다 .\\n“꼭 등꽃 같네. 서울 우리 학교에 큰 등나무가 있었단다 . 저 꽃을 보니까 등나무 밑에서 \\n놀던 동무들 생각이 난다.”\\n소녀가 조용히 일어나 비탈진 곳으로 간다. 꽃송이가 많이 달린 줄기를 잡고 끊기 시작한\",\n",
            "      \"question\": \"소설 끝에서 소녀는 어떠한 결말을 맞이한거야?\"\n",
            "    },\n",
            "    {\n",
            "      \"context\": \"- 3 -돌아다보니 , 소녀는 지금 자기가 지나쳐 온 허수아비를 흔들고 있다. 좀 전 허수아비보다 \\n더 우쭐거린다 .\\n논이 끝난 곳에 도랑이 하나 있었다 . 소녀가 먼저 뛰어 건넜다 .\\n거기서부터 산 밑까지는 밭이었다 .\\n수숫단을 세워 놓은 밭머리를 지났다 .\\n“저게 뭐니?”\\n“원두막 .”\\n“여기 참외, 맛있니 ?”\\n“그럼, 참외 맛도 좋지만 수박 맛은 더 좋다.”\\n“하나 먹어 봤으면 .”\\n소년이 참외 그루에 심은 무우밭으로 들어가 , 무우 두 밑을 뽑아 왔다. 아직 밑이 덜 들어 \\n있었다 . 잎을 비틀어 팽개친 후, 소녀에게 한개 건넨다 . 그리고는 이렇게 먹어야 한다는 듯\\n이, 먼저 대강이를 한 입 베물어 낸 다음, 손톱으로 한 돌이 껍질을 벗겨 우쩍 깨문다 .\\n소녀도 따라 했다. 그러나 , 세 입도 못 먹고,\\n“아, 맵고 지려.”\\n하며 집어던지고 만다.\\n“참, 맛 없어 못 먹겠다 .”\\n소년이 더 멀리 팽개쳐 버렸다 .\\n산이 가까워졌다 .\\n단풍이 눈에 따가웠다 .\\n“야아!”\\n소녀가 산을 향해 달려갔다 . 이번은 소년이 뒤따라 달리지 않았다 . 그러고도 곧 소녀보다 \\n더 많은 꽃을 꺾었다 .\\n“이게 들국화 , 이게 싸리꽃 , 이게 도라지꽃 ,…….”\\n“도라지꽃이 이렇게 예쁜 줄은 몰랐네 . 난 보랏빛이 좋아!…… 그런데 , 이 양산 같이 생긴 \\n노란 꽃이 뭐지?”\\n“마타리꽃 .”\\n소녀는 마타리꽃을 양산 받듯이 해 보인다 . 약간 상기된 얼굴에 살포시 보조개를 떠올리\\n며.\\n다시 소년은 꽃 한 옴큼을 꺾어 왔다. 싱싱한 꽃가지만 골라 소녀에게 건넨다 .\\n그러나 소녀는\\n“하나도 버리지 마라.”\\n산마루께로 올라갔다 .\\n맞은편 골짜기에 오순도순 초가집이 몇 모여 있었다 .\\n누가 말할 것도 아닌데 , 바위에 나란히 걸터앉았다 . 유달리 주위가 조용해진 것 같았다 . 따\\n가운 가을 햇살만이 말라가는 풀 냄새를 퍼뜨리고 있었다 .\\n“저건 또 무슨 꽃이지 ?”\\n적잖이 비탈진 곳에 칡덩굴이 엉키어 꽃을 달고 있었다 .\\n“꼭 등꽃 같네. 서울 우리 학교에 큰 등나무가 있었단다 . 저 꽃을 보니까 등나무 밑에서 \\n놀던 동무들 생각이 난다.”\\n소녀가 조용히 일어나 비탈진 곳으로 간다. 꽃송이가 많이 달린 줄기를 잡고 끊기 시작한\",\n",
            "      \"question\": \"소설 끝에서 소녀는 어떠한 결말을 맞이한거야?\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: Use the following portion of a long document to see if any of the text is relevant to answer the question. \\nReturn any relevant text verbatim.\\n______________________\\n- 3 -돌아다보니 , 소녀는 지금 자기가 지나쳐 온 허수아비를 흔들고 있다. 좀 전 허수아비보다 \\n더 우쭐거린다 .\\n논이 끝난 곳에 도랑이 하나 있었다 . 소녀가 먼저 뛰어 건넜다 .\\n거기서부터 산 밑까지는 밭이었다 .\\n수숫단을 세워 놓은 밭머리를 지났다 .\\n“저게 뭐니?”\\n“원두막 .”\\n“여기 참외, 맛있니 ?”\\n“그럼, 참외 맛도 좋지만 수박 맛은 더 좋다.”\\n“하나 먹어 봤으면 .”\\n소년이 참외 그루에 심은 무우밭으로 들어가 , 무우 두 밑을 뽑아 왔다. 아직 밑이 덜 들어 \\n있었다 . 잎을 비틀어 팽개친 후, 소녀에게 한개 건넨다 . 그리고는 이렇게 먹어야 한다는 듯\\n이, 먼저 대강이를 한 입 베물어 낸 다음, 손톱으로 한 돌이 껍질을 벗겨 우쩍 깨문다 .\\n소녀도 따라 했다. 그러나 , 세 입도 못 먹고,\\n“아, 맵고 지려.”\\n하며 집어던지고 만다.\\n“참, 맛 없어 못 먹겠다 .”\\n소년이 더 멀리 팽개쳐 버렸다 .\\n산이 가까워졌다 .\\n단풍이 눈에 따가웠다 .\\n“야아!”\\n소녀가 산을 향해 달려갔다 . 이번은 소년이 뒤따라 달리지 않았다 . 그러고도 곧 소녀보다 \\n더 많은 꽃을 꺾었다 .\\n“이게 들국화 , 이게 싸리꽃 , 이게 도라지꽃 ,…….”\\n“도라지꽃이 이렇게 예쁜 줄은 몰랐네 . 난 보랏빛이 좋아!…… 그런데 , 이 양산 같이 생긴 \\n노란 꽃이 뭐지?”\\n“마타리꽃 .”\\n소녀는 마타리꽃을 양산 받듯이 해 보인다 . 약간 상기된 얼굴에 살포시 보조개를 떠올리\\n며.\\n다시 소년은 꽃 한 옴큼을 꺾어 왔다. 싱싱한 꽃가지만 골라 소녀에게 건넨다 .\\n그러나 소녀는\\n“하나도 버리지 마라.”\\n산마루께로 올라갔다 .\\n맞은편 골짜기에 오순도순 초가집이 몇 모여 있었다 .\\n누가 말할 것도 아닌데 , 바위에 나란히 걸터앉았다 . 유달리 주위가 조용해진 것 같았다 . 따\\n가운 가을 햇살만이 말라가는 풀 냄새를 퍼뜨리고 있었다 .\\n“저건 또 무슨 꽃이지 ?”\\n적잖이 비탈진 곳에 칡덩굴이 엉키어 꽃을 달고 있었다 .\\n“꼭 등꽃 같네. 서울 우리 학교에 큰 등나무가 있었단다 . 저 꽃을 보니까 등나무 밑에서 \\n놀던 동무들 생각이 난다.”\\n소녀가 조용히 일어나 비탈진 곳으로 간다. 꽃송이가 많이 달린 줄기를 잡고 끊기 시작한\\nHuman: 소설 끝에서 소녀는 어떠한 결말을 맞이한거야?\"\n",
            "  ]\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: Use the following portion of a long document to see if any of the text is relevant to answer the question. \\nReturn any relevant text verbatim.\\n______________________\\n- 3 -돌아다보니 , 소녀는 지금 자기가 지나쳐 온 허수아비를 흔들고 있다. 좀 전 허수아비보다 \\n더 우쭐거린다 .\\n논이 끝난 곳에 도랑이 하나 있었다 . 소녀가 먼저 뛰어 건넜다 .\\n거기서부터 산 밑까지는 밭이었다 .\\n수숫단을 세워 놓은 밭머리를 지났다 .\\n“저게 뭐니?”\\n“원두막 .”\\n“여기 참외, 맛있니 ?”\\n“그럼, 참외 맛도 좋지만 수박 맛은 더 좋다.”\\n“하나 먹어 봤으면 .”\\n소년이 참외 그루에 심은 무우밭으로 들어가 , 무우 두 밑을 뽑아 왔다. 아직 밑이 덜 들어 \\n있었다 . 잎을 비틀어 팽개친 후, 소녀에게 한개 건넨다 . 그리고는 이렇게 먹어야 한다는 듯\\n이, 먼저 대강이를 한 입 베물어 낸 다음, 손톱으로 한 돌이 껍질을 벗겨 우쩍 깨문다 .\\n소녀도 따라 했다. 그러나 , 세 입도 못 먹고,\\n“아, 맵고 지려.”\\n하며 집어던지고 만다.\\n“참, 맛 없어 못 먹겠다 .”\\n소년이 더 멀리 팽개쳐 버렸다 .\\n산이 가까워졌다 .\\n단풍이 눈에 따가웠다 .\\n“야아!”\\n소녀가 산을 향해 달려갔다 . 이번은 소년이 뒤따라 달리지 않았다 . 그러고도 곧 소녀보다 \\n더 많은 꽃을 꺾었다 .\\n“이게 들국화 , 이게 싸리꽃 , 이게 도라지꽃 ,…….”\\n“도라지꽃이 이렇게 예쁜 줄은 몰랐네 . 난 보랏빛이 좋아!…… 그런데 , 이 양산 같이 생긴 \\n노란 꽃이 뭐지?”\\n“마타리꽃 .”\\n소녀는 마타리꽃을 양산 받듯이 해 보인다 . 약간 상기된 얼굴에 살포시 보조개를 떠올리\\n며.\\n다시 소년은 꽃 한 옴큼을 꺾어 왔다. 싱싱한 꽃가지만 골라 소녀에게 건넨다 .\\n그러나 소녀는\\n“하나도 버리지 마라.”\\n산마루께로 올라갔다 .\\n맞은편 골짜기에 오순도순 초가집이 몇 모여 있었다 .\\n누가 말할 것도 아닌데 , 바위에 나란히 걸터앉았다 . 유달리 주위가 조용해진 것 같았다 . 따\\n가운 가을 햇살만이 말라가는 풀 냄새를 퍼뜨리고 있었다 .\\n“저건 또 무슨 꽃이지 ?”\\n적잖이 비탈진 곳에 칡덩굴이 엉키어 꽃을 달고 있었다 .\\n“꼭 등꽃 같네. 서울 우리 학교에 큰 등나무가 있었단다 . 저 꽃을 보니까 등나무 밑에서 \\n놀던 동무들 생각이 난다.”\\n소녀가 조용히 일어나 비탈진 곳으로 간다. 꽃송이가 많이 달린 줄기를 잡고 끊기 시작한\\nHuman: 소설 끝에서 소녀는 어떠한 결말을 맞이한거야?\"\n",
            "  ]\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: Use the following portion of a long document to see if any of the text is relevant to answer the question. \\nReturn any relevant text verbatim.\\n______________________\\n- 3 -돌아다보니 , 소녀는 지금 자기가 지나쳐 온 허수아비를 흔들고 있다. 좀 전 허수아비보다 \\n더 우쭐거린다 .\\n논이 끝난 곳에 도랑이 하나 있었다 . 소녀가 먼저 뛰어 건넜다 .\\n거기서부터 산 밑까지는 밭이었다 .\\n수숫단을 세워 놓은 밭머리를 지났다 .\\n“저게 뭐니?”\\n“원두막 .”\\n“여기 참외, 맛있니 ?”\\n“그럼, 참외 맛도 좋지만 수박 맛은 더 좋다.”\\n“하나 먹어 봤으면 .”\\n소년이 참외 그루에 심은 무우밭으로 들어가 , 무우 두 밑을 뽑아 왔다. 아직 밑이 덜 들어 \\n있었다 . 잎을 비틀어 팽개친 후, 소녀에게 한개 건넨다 . 그리고는 이렇게 먹어야 한다는 듯\\n이, 먼저 대강이를 한 입 베물어 낸 다음, 손톱으로 한 돌이 껍질을 벗겨 우쩍 깨문다 .\\n소녀도 따라 했다. 그러나 , 세 입도 못 먹고,\\n“아, 맵고 지려.”\\n하며 집어던지고 만다.\\n“참, 맛 없어 못 먹겠다 .”\\n소년이 더 멀리 팽개쳐 버렸다 .\\n산이 가까워졌다 .\\n단풍이 눈에 따가웠다 .\\n“야아!”\\n소녀가 산을 향해 달려갔다 . 이번은 소년이 뒤따라 달리지 않았다 . 그러고도 곧 소녀보다 \\n더 많은 꽃을 꺾었다 .\\n“이게 들국화 , 이게 싸리꽃 , 이게 도라지꽃 ,…….”\\n“도라지꽃이 이렇게 예쁜 줄은 몰랐네 . 난 보랏빛이 좋아!…… 그런데 , 이 양산 같이 생긴 \\n노란 꽃이 뭐지?”\\n“마타리꽃 .”\\n소녀는 마타리꽃을 양산 받듯이 해 보인다 . 약간 상기된 얼굴에 살포시 보조개를 떠올리\\n며.\\n다시 소년은 꽃 한 옴큼을 꺾어 왔다. 싱싱한 꽃가지만 골라 소녀에게 건넨다 .\\n그러나 소녀는\\n“하나도 버리지 마라.”\\n산마루께로 올라갔다 .\\n맞은편 골짜기에 오순도순 초가집이 몇 모여 있었다 .\\n누가 말할 것도 아닌데 , 바위에 나란히 걸터앉았다 . 유달리 주위가 조용해진 것 같았다 . 따\\n가운 가을 햇살만이 말라가는 풀 냄새를 퍼뜨리고 있었다 .\\n“저건 또 무슨 꽃이지 ?”\\n적잖이 비탈진 곳에 칡덩굴이 엉키어 꽃을 달고 있었다 .\\n“꼭 등꽃 같네. 서울 우리 학교에 큰 등나무가 있었단다 . 저 꽃을 보니까 등나무 밑에서 \\n놀던 동무들 생각이 난다.”\\n소녀가 조용히 일어나 비탈진 곳으로 간다. 꽃송이가 많이 달린 줄기를 잡고 끊기 시작한\\nHuman: 소설 끝에서 소녀는 어떠한 결말을 맞이한거야?\"\n",
            "  ]\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: Use the following portion of a long document to see if any of the text is relevant to answer the question. \\nReturn any relevant text verbatim.\\n______________________\\n- 3 -돌아다보니 , 소녀는 지금 자기가 지나쳐 온 허수아비를 흔들고 있다. 좀 전 허수아비보다 \\n더 우쭐거린다 .\\n논이 끝난 곳에 도랑이 하나 있었다 . 소녀가 먼저 뛰어 건넜다 .\\n거기서부터 산 밑까지는 밭이었다 .\\n수숫단을 세워 놓은 밭머리를 지났다 .\\n“저게 뭐니?”\\n“원두막 .”\\n“여기 참외, 맛있니 ?”\\n“그럼, 참외 맛도 좋지만 수박 맛은 더 좋다.”\\n“하나 먹어 봤으면 .”\\n소년이 참외 그루에 심은 무우밭으로 들어가 , 무우 두 밑을 뽑아 왔다. 아직 밑이 덜 들어 \\n있었다 . 잎을 비틀어 팽개친 후, 소녀에게 한개 건넨다 . 그리고는 이렇게 먹어야 한다는 듯\\n이, 먼저 대강이를 한 입 베물어 낸 다음, 손톱으로 한 돌이 껍질을 벗겨 우쩍 깨문다 .\\n소녀도 따라 했다. 그러나 , 세 입도 못 먹고,\\n“아, 맵고 지려.”\\n하며 집어던지고 만다.\\n“참, 맛 없어 못 먹겠다 .”\\n소년이 더 멀리 팽개쳐 버렸다 .\\n산이 가까워졌다 .\\n단풍이 눈에 따가웠다 .\\n“야아!”\\n소녀가 산을 향해 달려갔다 . 이번은 소년이 뒤따라 달리지 않았다 . 그러고도 곧 소녀보다 \\n더 많은 꽃을 꺾었다 .\\n“이게 들국화 , 이게 싸리꽃 , 이게 도라지꽃 ,…….”\\n“도라지꽃이 이렇게 예쁜 줄은 몰랐네 . 난 보랏빛이 좋아!…… 그런데 , 이 양산 같이 생긴 \\n노란 꽃이 뭐지?”\\n“마타리꽃 .”\\n소녀는 마타리꽃을 양산 받듯이 해 보인다 . 약간 상기된 얼굴에 살포시 보조개를 떠올리\\n며.\\n다시 소년은 꽃 한 옴큼을 꺾어 왔다. 싱싱한 꽃가지만 골라 소녀에게 건넨다 .\\n그러나 소녀는\\n“하나도 버리지 마라.”\\n산마루께로 올라갔다 .\\n맞은편 골짜기에 오순도순 초가집이 몇 모여 있었다 .\\n누가 말할 것도 아닌데 , 바위에 나란히 걸터앉았다 . 유달리 주위가 조용해진 것 같았다 . 따\\n가운 가을 햇살만이 말라가는 풀 냄새를 퍼뜨리고 있었다 .\\n“저건 또 무슨 꽃이지 ?”\\n적잖이 비탈진 곳에 칡덩굴이 엉키어 꽃을 달고 있었다 .\\n“꼭 등꽃 같네. 서울 우리 학교에 큰 등나무가 있었단다 . 저 꽃을 보니까 등나무 밑에서 \\n놀던 동무들 생각이 난다.”\\n소녀가 조용히 일어나 비탈진 곳으로 간다. 꽃송이가 많이 달린 줄기를 잡고 끊기 시작한\\nHuman: 소설 끝에서 소녀는 어떠한 결말을 맞이한거야?\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain > chain:LLMChain > llm:ChatOpenAI] [9.35s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"제공된 텍스트에서는 소녀의 결말에 대한 정보가 포함되어 있지 않습니다. 텍스트는 소녀와 소년이 꽃을 꺾고, 자연을 탐험하는 장면을 묘사하고 있으며, 결말에 대한 내용은 나타나지 않습니다. 추가적인 정보가 필요합니다.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"제공된 텍스트에서는 소녀의 결말에 대한 정보가 포함되어 있지 않습니다. 텍스트는 소녀와 소년이 꽃을 꺾고, 자연을 탐험하는 장면을 묘사하고 있으며, 결말에 대한 내용은 나타나지 않습니다. 추가적인 정보가 필요합니다.\",\n",
            "            \"response_metadata\": {\n",
            "              \"token_usage\": {\n",
            "                \"completion_tokens\": 71,\n",
            "                \"prompt_tokens\": 790,\n",
            "                \"total_tokens\": 861\n",
            "              },\n",
            "              \"model_name\": \"gpt-4o-mini\",\n",
            "              \"system_fingerprint\": \"fp_661538dc1f\",\n",
            "              \"finish_reason\": \"stop\",\n",
            "              \"logprobs\": null\n",
            "            },\n",
            "            \"type\": \"ai\",\n",
            "            \"id\": \"run-0f3d2e49-e7df-44ca-b38a-75a7876c6590-0\",\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 71,\n",
            "      \"prompt_tokens\": 790,\n",
            "      \"total_tokens\": 861\n",
            "    },\n",
            "    \"model_name\": \"gpt-4o-mini\",\n",
            "    \"system_fingerprint\": \"fp_661538dc1f\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain > chain:LLMChain > llm:ChatOpenAI] [9.35s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"제공된 텍스트에서는 소녀의 결말에 대한 정보가 포함되어 있지 않습니다. 텍스트는 소녀와 소년이 꽃을 꺾고, 자연을 탐험하는 장면을 묘사하고 있으며, 결말에 대한 언급은 없습니다. 따라서 소녀가 어떠한 결말을 맞이했는지에 대한 답변을 제공할 수 없습니다.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"제공된 텍스트에서는 소녀의 결말에 대한 정보가 포함되어 있지 않습니다. 텍스트는 소녀와 소년이 꽃을 꺾고, 자연을 탐험하는 장면을 묘사하고 있으며, 결말에 대한 언급은 없습니다. 따라서 소녀가 어떠한 결말을 맞이했는지에 대한 답변을 제공할 수 없습니다.\",\n",
            "            \"response_metadata\": {\n",
            "              \"token_usage\": {\n",
            "                \"completion_tokens\": 87,\n",
            "                \"prompt_tokens\": 790,\n",
            "                \"total_tokens\": 877\n",
            "              },\n",
            "              \"model_name\": \"gpt-4o-mini\",\n",
            "              \"system_fingerprint\": \"fp_8b761cb050\",\n",
            "              \"finish_reason\": \"stop\",\n",
            "              \"logprobs\": null\n",
            "            },\n",
            "            \"type\": \"ai\",\n",
            "            \"id\": \"run-9187e354-2bc7-4428-8311-a4b730d51101-0\",\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 87,\n",
            "      \"prompt_tokens\": 790,\n",
            "      \"total_tokens\": 877\n",
            "    },\n",
            "    \"model_name\": \"gpt-4o-mini\",\n",
            "    \"system_fingerprint\": \"fp_8b761cb050\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain > chain:LLMChain > llm:ChatOpenAI] [9.35s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"제공된 텍스트에서는 소녀의 결말에 대한 정보가 포함되어 있지 않습니다. 텍스트는 소녀와 소년이 꽃을 꺾고, 자연을 즐기는 장면을 묘사하고 있으며, 결말에 대한 내용은 나타나지 않습니다. 추가적인 정보가 필요합니다.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"제공된 텍스트에서는 소녀의 결말에 대한 정보가 포함되어 있지 않습니다. 텍스트는 소녀와 소년이 꽃을 꺾고, 자연을 즐기는 장면을 묘사하고 있으며, 결말에 대한 내용은 나타나지 않습니다. 추가적인 정보가 필요합니다.\",\n",
            "            \"response_metadata\": {\n",
            "              \"token_usage\": {\n",
            "                \"completion_tokens\": 70,\n",
            "                \"prompt_tokens\": 790,\n",
            "                \"total_tokens\": 860\n",
            "              },\n",
            "              \"model_name\": \"gpt-4o-mini\",\n",
            "              \"system_fingerprint\": \"fp_661538dc1f\",\n",
            "              \"finish_reason\": \"stop\",\n",
            "              \"logprobs\": null\n",
            "            },\n",
            "            \"type\": \"ai\",\n",
            "            \"id\": \"run-a2a1a6fa-5605-46e5-9704-08eeafc17101-0\",\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 70,\n",
            "      \"prompt_tokens\": 790,\n",
            "      \"total_tokens\": 860\n",
            "    },\n",
            "    \"model_name\": \"gpt-4o-mini\",\n",
            "    \"system_fingerprint\": \"fp_661538dc1f\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain > chain:LLMChain > llm:ChatOpenAI] [9.34s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"제공된 텍스트에서는 소녀의 결말에 대한 정보가 포함되어 있지 않습니다. 텍스트는 소녀와 소년이 꽃을 꺾고, 자연을 즐기는 장면을 묘사하고 있으며, 결말에 대한 내용은 나타나지 않습니다. 추가적인 정보가 필요합니다.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"제공된 텍스트에서는 소녀의 결말에 대한 정보가 포함되어 있지 않습니다. 텍스트는 소녀와 소년이 꽃을 꺾고, 자연을 즐기는 장면을 묘사하고 있으며, 결말에 대한 내용은 나타나지 않습니다. 추가적인 정보가 필요합니다.\",\n",
            "            \"response_metadata\": {\n",
            "              \"token_usage\": {\n",
            "                \"completion_tokens\": 70,\n",
            "                \"prompt_tokens\": 790,\n",
            "                \"total_tokens\": 860\n",
            "              },\n",
            "              \"model_name\": \"gpt-4o-mini\",\n",
            "              \"system_fingerprint\": \"fp_661538dc1f\",\n",
            "              \"finish_reason\": \"stop\",\n",
            "              \"logprobs\": null\n",
            "            },\n",
            "            \"type\": \"ai\",\n",
            "            \"id\": \"run-67787f2f-c50b-4c28-aae9-04fdbf004162-0\",\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 70,\n",
            "      \"prompt_tokens\": 790,\n",
            "      \"total_tokens\": 860\n",
            "    },\n",
            "    \"model_name\": \"gpt-4o-mini\",\n",
            "    \"system_fingerprint\": \"fp_661538dc1f\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain > chain:LLMChain] [9.36s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"outputs\": [\n",
            "    {\n",
            "      \"text\": \"제공된 텍스트에서는 소녀의 결말에 대한 정보가 포함되어 있지 않습니다. 텍스트는 소녀와 소년이 꽃을 꺾고, 자연을 탐험하는 장면을 묘사하고 있으며, 결말에 대한 내용은 나타나지 않습니다. 추가적인 정보가 필요합니다.\"\n",
            "    },\n",
            "    {\n",
            "      \"text\": \"제공된 텍스트에서는 소녀의 결말에 대한 정보가 포함되어 있지 않습니다. 텍스트는 소녀와 소년이 꽃을 꺾고, 자연을 탐험하는 장면을 묘사하고 있으며, 결말에 대한 언급은 없습니다. 따라서 소녀가 어떠한 결말을 맞이했는지에 대한 답변을 제공할 수 없습니다.\"\n",
            "    },\n",
            "    {\n",
            "      \"text\": \"제공된 텍스트에서는 소녀의 결말에 대한 정보가 포함되어 있지 않습니다. 텍스트는 소녀와 소년이 꽃을 꺾고, 자연을 즐기는 장면을 묘사하고 있으며, 결말에 대한 내용은 나타나지 않습니다. 추가적인 정보가 필요합니다.\"\n",
            "    },\n",
            "    {\n",
            "      \"text\": \"제공된 텍스트에서는 소녀의 결말에 대한 정보가 포함되어 있지 않습니다. 텍스트는 소녀와 소년이 꽃을 꺾고, 자연을 즐기는 장면을 묘사하고 있으며, 결말에 대한 내용은 나타나지 않습니다. 추가적인 정보가 필요합니다.\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain > chain:LLMChain] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"question\": \"소설 끝에서 소녀는 어떠한 결말을 맞이한거야?\",\n",
            "  \"summaries\": \"제공된 텍스트에서는 소녀의 결말에 대한 정보가 포함되어 있지 않습니다. 텍스트는 소녀와 소년이 꽃을 꺾고, 자연을 탐험하는 장면을 묘사하고 있으며, 결말에 대한 내용은 나타나지 않습니다. 추가적인 정보가 필요합니다.\\n\\n제공된 텍스트에서는 소녀의 결말에 대한 정보가 포함되어 있지 않습니다. 텍스트는 소녀와 소년이 꽃을 꺾고, 자연을 탐험하는 장면을 묘사하고 있으며, 결말에 대한 언급은 없습니다. 따라서 소녀가 어떠한 결말을 맞이했는지에 대한 답변을 제공할 수 없습니다.\\n\\n제공된 텍스트에서는 소녀의 결말에 대한 정보가 포함되어 있지 않습니다. 텍스트는 소녀와 소년이 꽃을 꺾고, 자연을 즐기는 장면을 묘사하고 있으며, 결말에 대한 내용은 나타나지 않습니다. 추가적인 정보가 필요합니다.\\n\\n제공된 텍스트에서는 소녀의 결말에 대한 정보가 포함되어 있지 않습니다. 텍스트는 소녀와 소년이 꽃을 꺾고, 자연을 즐기는 장면을 묘사하고 있으며, 결말에 대한 내용은 나타나지 않습니다. 추가적인 정보가 필요합니다.\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: Given the following extracted parts of a long document and a question, create a final answer. \\nIf you don't know the answer, just say that you don't know. Don't try to make up an answer.\\n______________________\\n제공된 텍스트에서는 소녀의 결말에 대한 정보가 포함되어 있지 않습니다. 텍스트는 소녀와 소년이 꽃을 꺾고, 자연을 탐험하는 장면을 묘사하고 있으며, 결말에 대한 내용은 나타나지 않습니다. 추가적인 정보가 필요합니다.\\n\\n제공된 텍스트에서는 소녀의 결말에 대한 정보가 포함되어 있지 않습니다. 텍스트는 소녀와 소년이 꽃을 꺾고, 자연을 탐험하는 장면을 묘사하고 있으며, 결말에 대한 언급은 없습니다. 따라서 소녀가 어떠한 결말을 맞이했는지에 대한 답변을 제공할 수 없습니다.\\n\\n제공된 텍스트에서는 소녀의 결말에 대한 정보가 포함되어 있지 않습니다. 텍스트는 소녀와 소년이 꽃을 꺾고, 자연을 즐기는 장면을 묘사하고 있으며, 결말에 대한 내용은 나타나지 않습니다. 추가적인 정보가 필요합니다.\\n\\n제공된 텍스트에서는 소녀의 결말에 대한 정보가 포함되어 있지 않습니다. 텍스트는 소녀와 소년이 꽃을 꺾고, 자연을 즐기는 장면을 묘사하고 있으며, 결말에 대한 내용은 나타나지 않습니다. 추가적인 정보가 필요합니다.\\nHuman: 소설 끝에서 소녀는 어떠한 결말을 맞이한거야?\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain > chain:LLMChain > llm:ChatOpenAI] [1.86s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"제공된 텍스트에서는 소녀의 결말에 대한 정보가 포함되어 있지 않습니다. 따라서 소녀가 어떠한 결말을 맞이했는지에 대한 답변을 제공할 수 없습니다.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"제공된 텍스트에서는 소녀의 결말에 대한 정보가 포함되어 있지 않습니다. 따라서 소녀가 어떠한 결말을 맞이했는지에 대한 답변을 제공할 수 없습니다.\",\n",
            "            \"response_metadata\": {\n",
            "              \"token_usage\": {\n",
            "                \"completion_tokens\": 47,\n",
            "                \"prompt_tokens\": 372,\n",
            "                \"total_tokens\": 419\n",
            "              },\n",
            "              \"model_name\": \"gpt-4o-mini\",\n",
            "              \"system_fingerprint\": \"fp_661538dc1f\",\n",
            "              \"finish_reason\": \"stop\",\n",
            "              \"logprobs\": null\n",
            "            },\n",
            "            \"type\": \"ai\",\n",
            "            \"id\": \"run-ead33b04-e952-4872-a769-dff63e67c1d0-0\",\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 47,\n",
            "      \"prompt_tokens\": 372,\n",
            "      \"total_tokens\": 419\n",
            "    },\n",
            "    \"model_name\": \"gpt-4o-mini\",\n",
            "    \"system_fingerprint\": \"fp_661538dc1f\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain > chain:LLMChain] [1.87s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"text\": \"제공된 텍스트에서는 소녀의 결말에 대한 정보가 포함되어 있지 않습니다. 따라서 소녀가 어떠한 결말을 맞이했는지에 대한 답변을 제공할 수 없습니다.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain] [13.66s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output_text\": \"제공된 텍스트에서는 소녀의 결말에 대한 정보가 포함되어 있지 않습니다. 따라서 소녀가 어떠한 결말을 맞이했는지에 대한 답변을 제공할 수 없습니다.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA] [13.82s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"result\": \"제공된 텍스트에서는 소녀의 결말에 대한 정보가 포함되어 있지 않습니다. 따라서 소녀가 어떠한 결말을 맞이했는지에 대한 답변을 제공할 수 없습니다.\"\n",
            "}\n",
            "{'query': '소설 끝에서 소녀는 어떠한 결말을 맞이한거야?', 'result': '제공된 텍스트에서는 소녀의 결말에 대한 정보가 포함되어 있지 않습니다. 따라서 소녀가 어떠한 결말을 맞이했는지에 대한 답변을 제공할 수 없습니다.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LangSmith 를 이용한 모니터링\n",
        "# RetrievalQA (chain_type=\"map_reduce\")\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, model_name='gpt-4o')\n",
        "embeddings = OpenAIEmbeddings()\n",
        "doc_file_path = \"소나기 - 황순원.pdf\"\n",
        "\n",
        "loader = PyPDFLoader(doc_file_path)\n",
        "docs = loader.load()\n",
        "db = Chroma.from_documents(docs, embeddings)\n",
        "\n",
        "retriever = db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 3})\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "retriever = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"map_reduce\",\n",
        "    retriever=retriever)\n",
        "\n",
        "query = \"소설 끝에서 소녀는 어떠한 결말을 맞이한거야?\"\n",
        "response = retriever.invoke({\"query\": query})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzkzcWVp9uTb",
        "outputId": "142a822b-eb92-4b02-d0a6-cdd844289aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"query\": \"소설 끝에서 소녀는 어떠한 결말을 맞이한거야?\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain > chain:LLMChain] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input_list\": [\n",
            "    {\n",
            "      \"context\": \"- 3 -돌아다보니 , 소녀는 지금 자기가 지나쳐 온 허수아비를 흔들고 있다. 좀 전 허수아비보다 \\n더 우쭐거린다 .\\n논이 끝난 곳에 도랑이 하나 있었다 . 소녀가 먼저 뛰어 건넜다 .\\n거기서부터 산 밑까지는 밭이었다 .\\n수숫단을 세워 놓은 밭머리를 지났다 .\\n“저게 뭐니?”\\n“원두막 .”\\n“여기 참외, 맛있니 ?”\\n“그럼, 참외 맛도 좋지만 수박 맛은 더 좋다.”\\n“하나 먹어 봤으면 .”\\n소년이 참외 그루에 심은 무우밭으로 들어가 , 무우 두 밑을 뽑아 왔다. 아직 밑이 덜 들어 \\n있었다 . 잎을 비틀어 팽개친 후, 소녀에게 한개 건넨다 . 그리고는 이렇게 먹어야 한다는 듯\\n이, 먼저 대강이를 한 입 베물어 낸 다음, 손톱으로 한 돌이 껍질을 벗겨 우쩍 깨문다 .\\n소녀도 따라 했다. 그러나 , 세 입도 못 먹고,\\n“아, 맵고 지려.”\\n하며 집어던지고 만다.\\n“참, 맛 없어 못 먹겠다 .”\\n소년이 더 멀리 팽개쳐 버렸다 .\\n산이 가까워졌다 .\\n단풍이 눈에 따가웠다 .\\n“야아!”\\n소녀가 산을 향해 달려갔다 . 이번은 소년이 뒤따라 달리지 않았다 . 그러고도 곧 소녀보다 \\n더 많은 꽃을 꺾었다 .\\n“이게 들국화 , 이게 싸리꽃 , 이게 도라지꽃 ,…….”\\n“도라지꽃이 이렇게 예쁜 줄은 몰랐네 . 난 보랏빛이 좋아!…… 그런데 , 이 양산 같이 생긴 \\n노란 꽃이 뭐지?”\\n“마타리꽃 .”\\n소녀는 마타리꽃을 양산 받듯이 해 보인다 . 약간 상기된 얼굴에 살포시 보조개를 떠올리\\n며.\\n다시 소년은 꽃 한 옴큼을 꺾어 왔다. 싱싱한 꽃가지만 골라 소녀에게 건넨다 .\\n그러나 소녀는\\n“하나도 버리지 마라.”\\n산마루께로 올라갔다 .\\n맞은편 골짜기에 오순도순 초가집이 몇 모여 있었다 .\\n누가 말할 것도 아닌데 , 바위에 나란히 걸터앉았다 . 유달리 주위가 조용해진 것 같았다 . 따\\n가운 가을 햇살만이 말라가는 풀 냄새를 퍼뜨리고 있었다 .\\n“저건 또 무슨 꽃이지 ?”\\n적잖이 비탈진 곳에 칡덩굴이 엉키어 꽃을 달고 있었다 .\\n“꼭 등꽃 같네. 서울 우리 학교에 큰 등나무가 있었단다 . 저 꽃을 보니까 등나무 밑에서 \\n놀던 동무들 생각이 난다.”\\n소녀가 조용히 일어나 비탈진 곳으로 간다. 꽃송이가 많이 달린 줄기를 잡고 끊기 시작한\",\n",
            "      \"question\": \"소설 끝에서 소녀는 어떠한 결말을 맞이한거야?\"\n",
            "    },\n",
            "    {\n",
            "      \"context\": \"- 6 -소년은 소녀네가 이사해 오기 전에 벌써 어른들의 이야기를 들어서 , 윤 초시 손자(孫子)가 \\n서울서 사업에 실패해 가지고 고향에 돌아오지 않을 수 없게 되었다는 걸 알고 있었다 . 그\\n것이 이번에는 고향 집마저 남의 손에 넘기게 된 모양이었다 .\\n“왜 그런지 난 이사 가는 게 싫어졌다 . 어른들이 하는 일이니 어쩔 수 없지만 …….”\\n전에 없이, 소녀의 까만 눈에 쓸쓸한 빛이 떠돌았다 .\\n소녀와 헤어져 돌아오는 길에, 소년은 혼잣속으로 , 소녀가 이사를 간다는 말을 수없이 되\\n뇌어 보았다 . 무어 그리 안타까울 것도 서러울 것도 없었다 . 그렇건만 , 소년은 지금 자기가 \\n씹고 있는 대추알의 단맛을 모르고 있었다 .\\n이 날 밤, 소년은 몰래 덕쇠 할아버지네 호두밭으로 갔다.\\n낯에 봐 두었던 나무로 올라갔다 . 그리고 , 봐 두었던 가지를 향해 작대기를 내리쳤다 . 호두\\n송이 떨어지는 소리가 별나게 크게 들렸다 . 가슴이 선뜩했다 . 그러나 다음 순간, 굵은 호두\\n야 많이 떨어져라 , 많이 떨어져라 , 저도 모를 힘에 이끌려 마구 작대기를 내리 치는 것이\\n었다.\\n돌아오는 길에는 열 이틀 달이 지우는 그늘만 골라 디뎠다 . 그늘의 고마움을 처음 느꼈다 .\\n불룩한 주머니를 어루만졌다 . 호두송이를 맨손으로 깠다가는 옴이 오르기 쉽다는 말 같은 건 아\\n무렇지도 않았다 . 그저 근동에서 제일 가는 이 덕쇠 할아버지네 호두를 어서 소녀에게 맛보여야 \\n한다는 생각만이 앞섰다 .\\n그러다 , 아차 하는 생각이 들었다 . 소녀더러 병이 좀 낫거들랑 이사 가기 전에 한 번 개울\\n가로 나와 달라는 말을 못해 둔 것이었다 . 바보 같은것 , 바보 같은것 .\\n이튿날 , 소년이 학교에서 돌아오니 , 아버지가 나들이옷으로 갈아입고 닭 한 마리를 안고 \\n있었다 .\\n어디 가시느냐고 물었다 .\\n그 말에도 대꾸도 없이, 아버지는 안고 있는 닭의 무게를 겨냥해 보면서 ,\\n“이만하면 될까?”\\n어머니가 망태기를 내주며 ,\\n“벌써 며칠째 ‘걀걀’하고 알 날 자리를 보던데요 . 크진 않아도살은 쪘을 거여요 .”\\n소년이 이번에는 어머니한테 아버지가 어디 가시느냐고 물어 보았다 .\\n“저, 서당골 윤 초시 댁에 가신다 . 제삿상에라도 놓으시라고 …….”\\n“그럼, 큰 놈으로 하나 가져가지 . 저 얼룩수탉으로 …….”\\n이 말에, 아버지는 허허 웃고 나서,\\n“임마, 그래도 이게 실속이 있다.”\\n소년은 공연히 열적어 , 책보를 집어던지고는 외양간으로가 , 쇠잔등을 한 번 철썩 갈겼다 . \\n쇠파리라도 잡는 체.\\n개울물은 날로 여물어 갔다.\\n소년은 갈림길에서 아래쪽으로 가 보았다 . 갈밭머리에서 바라보는 서당골 마을은 쪽빛 하\\n늘 아래 한결 가까워 보였다 .\\n어른들의 말이, 내일 소녀네가 양평읍으로 이사 간다는 것이었다 . 거기 가서는 조그마한 \\n가겟방을 보게 되리라는 것이었다 .\\n소년은 저도 모르게 주머니 속 호두알을 만지작거리며 , 한 손으로는 수없이 갈꽃을 휘어 \\n꺾고 있었다 .\\n그 날 밤, 소년은 자리에 누워서도 같은 생각뿐이었다 . 내일 소녀네가 이사하는 걸 가 보\",\n",
            "      \"question\": \"소설 끝에서 소녀는 어떠한 결말을 맞이한거야?\"\n",
            "    },\n",
            "    {\n",
            "      \"context\": \"- 1 -소나기\\n황순원\\n소년은 개울가에서 소녀를 보자 곧 윤 초시네 증손녀 (曾孫女 )딸이라는 걸 알 수 있었다 . \\n소녀는 개울에다 손을 잠그고 물장난을 하고 있는 것이다 . 서울서는 이런 개울물을 보지 \\n못하기나 한 듯이.\\n벌써 며칠째 소녀는 , 학교에서 돌아오는 길에 물장난이었다 . 그런데 , 어제까지 개울 기슭에\\n서 하더니 , 오늘은 징검다리 한가운데 앉아서 하고 있다.\\n소년은 개울둑에 앉아 버렸다 . 소녀가 비키기를 기다리자는 것이다 .\\n요행 지나가는 사람이 있어, 소녀가 길을 비켜 주었다 .\\n다음 날은 좀 늦게 개울가로 나왔다 .\\n이 날은 소녀가 징검다리 한가운데 앉아 세수를 하고 있었다 . 분홍 스웨터 소매를 걷어올\\n린 목덜미가 마냥 희었다 .\\n한참 세수를 하고 나더니 , 이번에는 물 속을 빤히 들여다 본다. 얼굴이라도 비추어 보는 \\n것이리라 . 갑자기 물을 움켜 낸다. 고기 새끼라도 지나가는 듯.\\n소녀는 소년이 개울둑에 앉아 있는 걸 아는지 모르는지 그냥 날쌔게 물만 움켜 낸다. 그러\\n나, 번번이 허탕이다 . 그대로 재미있는 양, 자꾸 물만 움킨다 . 어제처럼 개울을 건너는 사\\n람이 있어야 길을 비킬 모양이다 .\\n그러다가 소녀가 물 속에서 무엇을 하나 집어 낸다. 하얀 조약돌이었다 . 그리고는 벌떡 일\\n어나 팔짝팔짝 징검다리를 뛰어 건너간다 .\\n다 건너가더니만 홱 이리로 돌아서며 ,\\n“이 바보.”\\n조약돌이 날아왔다 .\\n소년은 저도 모르게 벌떡 일어섰다 .\\n단발 머리를 나풀거리며 소녀가 막 달린다 . 갈밭 사잇길로 들어섰다 . 뒤에는 청량한 가을 \\n햇살 아래 빛나는 갈꽃뿐 .\\n이제 저쯤 갈밭머리로 소녀가 나타나리라 . 꽤 오랜 시간이 지났다고 생각됐다 . 그런데도 \\n소녀는 나타나지 않는다 . 발돋움을 했다. 그러고도 상당한 시간이 지났다고 생각됐다 .\\n저 쪽 갈밭머리에 갈꽃이 한 옴큼 움직였다 . 소녀가 갈꽃을 안고 있었다 . 그리고 , 이제는 \\n천천한 걸음이었다 . 유난히 맑은 가을 햇살이 소녀의 갈꽃머리에서 반짝거렸다 . 소녀 아닌 \\n갈꽃이 들길을 걸어가는 것만 같았다 .\\n소년은 이 갈꽃이 아주 뵈지 않게 되기까지 그대로 서 있었다 . 문득, 소녀가 던지 조약돌\\n을 내려다보았다 . 물기가 걷혀 있었다 . 소년은 조약돌을 집어 주머니에 넣었다 .\\n다음 날부터 좀더 늦게 개울가로 나왔다 . 소녀의 그림자가 뵈지 않았다 . 다행이었다 .\\n그러나 , 이상한 일이었다 . 소녀의 그림자가 뵈지 않는 날이 계속될수록 소년의 가슴 한 구\\n석에는 어딘가 허전함이 자리 잡는 것이었다 . 주머니 속 조약돌을 주무르는 버릇이 생겼\\n다.\\n그러한 어떤 날, 소년은 전에 소녀가 앉아 물장난을 하던 징검다리 한가운데에 앉아 보았\\n다. 물 속에 손을 잠갔다 . 세수를 하였다 . 물 속을 들여다보았다 . 검게 탄 얼굴이 그대로 \\n비치었다 . 싫었다 .\",\n",
            "      \"question\": \"소설 끝에서 소녀는 어떠한 결말을 맞이한거야?\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: Use the following portion of a long document to see if any of the text is relevant to answer the question. \\nReturn any relevant text verbatim.\\n______________________\\n- 3 -돌아다보니 , 소녀는 지금 자기가 지나쳐 온 허수아비를 흔들고 있다. 좀 전 허수아비보다 \\n더 우쭐거린다 .\\n논이 끝난 곳에 도랑이 하나 있었다 . 소녀가 먼저 뛰어 건넜다 .\\n거기서부터 산 밑까지는 밭이었다 .\\n수숫단을 세워 놓은 밭머리를 지났다 .\\n“저게 뭐니?”\\n“원두막 .”\\n“여기 참외, 맛있니 ?”\\n“그럼, 참외 맛도 좋지만 수박 맛은 더 좋다.”\\n“하나 먹어 봤으면 .”\\n소년이 참외 그루에 심은 무우밭으로 들어가 , 무우 두 밑을 뽑아 왔다. 아직 밑이 덜 들어 \\n있었다 . 잎을 비틀어 팽개친 후, 소녀에게 한개 건넨다 . 그리고는 이렇게 먹어야 한다는 듯\\n이, 먼저 대강이를 한 입 베물어 낸 다음, 손톱으로 한 돌이 껍질을 벗겨 우쩍 깨문다 .\\n소녀도 따라 했다. 그러나 , 세 입도 못 먹고,\\n“아, 맵고 지려.”\\n하며 집어던지고 만다.\\n“참, 맛 없어 못 먹겠다 .”\\n소년이 더 멀리 팽개쳐 버렸다 .\\n산이 가까워졌다 .\\n단풍이 눈에 따가웠다 .\\n“야아!”\\n소녀가 산을 향해 달려갔다 . 이번은 소년이 뒤따라 달리지 않았다 . 그러고도 곧 소녀보다 \\n더 많은 꽃을 꺾었다 .\\n“이게 들국화 , 이게 싸리꽃 , 이게 도라지꽃 ,…….”\\n“도라지꽃이 이렇게 예쁜 줄은 몰랐네 . 난 보랏빛이 좋아!…… 그런데 , 이 양산 같이 생긴 \\n노란 꽃이 뭐지?”\\n“마타리꽃 .”\\n소녀는 마타리꽃을 양산 받듯이 해 보인다 . 약간 상기된 얼굴에 살포시 보조개를 떠올리\\n며.\\n다시 소년은 꽃 한 옴큼을 꺾어 왔다. 싱싱한 꽃가지만 골라 소녀에게 건넨다 .\\n그러나 소녀는\\n“하나도 버리지 마라.”\\n산마루께로 올라갔다 .\\n맞은편 골짜기에 오순도순 초가집이 몇 모여 있었다 .\\n누가 말할 것도 아닌데 , 바위에 나란히 걸터앉았다 . 유달리 주위가 조용해진 것 같았다 . 따\\n가운 가을 햇살만이 말라가는 풀 냄새를 퍼뜨리고 있었다 .\\n“저건 또 무슨 꽃이지 ?”\\n적잖이 비탈진 곳에 칡덩굴이 엉키어 꽃을 달고 있었다 .\\n“꼭 등꽃 같네. 서울 우리 학교에 큰 등나무가 있었단다 . 저 꽃을 보니까 등나무 밑에서 \\n놀던 동무들 생각이 난다.”\\n소녀가 조용히 일어나 비탈진 곳으로 간다. 꽃송이가 많이 달린 줄기를 잡고 끊기 시작한\\nHuman: 소설 끝에서 소녀는 어떠한 결말을 맞이한거야?\"\n",
            "  ]\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: Use the following portion of a long document to see if any of the text is relevant to answer the question. \\nReturn any relevant text verbatim.\\n______________________\\n- 6 -소년은 소녀네가 이사해 오기 전에 벌써 어른들의 이야기를 들어서 , 윤 초시 손자(孫子)가 \\n서울서 사업에 실패해 가지고 고향에 돌아오지 않을 수 없게 되었다는 걸 알고 있었다 . 그\\n것이 이번에는 고향 집마저 남의 손에 넘기게 된 모양이었다 .\\n“왜 그런지 난 이사 가는 게 싫어졌다 . 어른들이 하는 일이니 어쩔 수 없지만 …….”\\n전에 없이, 소녀의 까만 눈에 쓸쓸한 빛이 떠돌았다 .\\n소녀와 헤어져 돌아오는 길에, 소년은 혼잣속으로 , 소녀가 이사를 간다는 말을 수없이 되\\n뇌어 보았다 . 무어 그리 안타까울 것도 서러울 것도 없었다 . 그렇건만 , 소년은 지금 자기가 \\n씹고 있는 대추알의 단맛을 모르고 있었다 .\\n이 날 밤, 소년은 몰래 덕쇠 할아버지네 호두밭으로 갔다.\\n낯에 봐 두었던 나무로 올라갔다 . 그리고 , 봐 두었던 가지를 향해 작대기를 내리쳤다 . 호두\\n송이 떨어지는 소리가 별나게 크게 들렸다 . 가슴이 선뜩했다 . 그러나 다음 순간, 굵은 호두\\n야 많이 떨어져라 , 많이 떨어져라 , 저도 모를 힘에 이끌려 마구 작대기를 내리 치는 것이\\n었다.\\n돌아오는 길에는 열 이틀 달이 지우는 그늘만 골라 디뎠다 . 그늘의 고마움을 처음 느꼈다 .\\n불룩한 주머니를 어루만졌다 . 호두송이를 맨손으로 깠다가는 옴이 오르기 쉽다는 말 같은 건 아\\n무렇지도 않았다 . 그저 근동에서 제일 가는 이 덕쇠 할아버지네 호두를 어서 소녀에게 맛보여야 \\n한다는 생각만이 앞섰다 .\\n그러다 , 아차 하는 생각이 들었다 . 소녀더러 병이 좀 낫거들랑 이사 가기 전에 한 번 개울\\n가로 나와 달라는 말을 못해 둔 것이었다 . 바보 같은것 , 바보 같은것 .\\n이튿날 , 소년이 학교에서 돌아오니 , 아버지가 나들이옷으로 갈아입고 닭 한 마리를 안고 \\n있었다 .\\n어디 가시느냐고 물었다 .\\n그 말에도 대꾸도 없이, 아버지는 안고 있는 닭의 무게를 겨냥해 보면서 ,\\n“이만하면 될까?”\\n어머니가 망태기를 내주며 ,\\n“벌써 며칠째 ‘걀걀’하고 알 날 자리를 보던데요 . 크진 않아도살은 쪘을 거여요 .”\\n소년이 이번에는 어머니한테 아버지가 어디 가시느냐고 물어 보았다 .\\n“저, 서당골 윤 초시 댁에 가신다 . 제삿상에라도 놓으시라고 …….”\\n“그럼, 큰 놈으로 하나 가져가지 . 저 얼룩수탉으로 …….”\\n이 말에, 아버지는 허허 웃고 나서,\\n“임마, 그래도 이게 실속이 있다.”\\n소년은 공연히 열적어 , 책보를 집어던지고는 외양간으로가 , 쇠잔등을 한 번 철썩 갈겼다 . \\n쇠파리라도 잡는 체.\\n개울물은 날로 여물어 갔다.\\n소년은 갈림길에서 아래쪽으로 가 보았다 . 갈밭머리에서 바라보는 서당골 마을은 쪽빛 하\\n늘 아래 한결 가까워 보였다 .\\n어른들의 말이, 내일 소녀네가 양평읍으로 이사 간다는 것이었다 . 거기 가서는 조그마한 \\n가겟방을 보게 되리라는 것이었다 .\\n소년은 저도 모르게 주머니 속 호두알을 만지작거리며 , 한 손으로는 수없이 갈꽃을 휘어 \\n꺾고 있었다 .\\n그 날 밤, 소년은 자리에 누워서도 같은 생각뿐이었다 . 내일 소녀네가 이사하는 걸 가 보\\nHuman: 소설 끝에서 소녀는 어떠한 결말을 맞이한거야?\"\n",
            "  ]\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: Use the following portion of a long document to see if any of the text is relevant to answer the question. \\nReturn any relevant text verbatim.\\n______________________\\n- 1 -소나기\\n황순원\\n소년은 개울가에서 소녀를 보자 곧 윤 초시네 증손녀 (曾孫女 )딸이라는 걸 알 수 있었다 . \\n소녀는 개울에다 손을 잠그고 물장난을 하고 있는 것이다 . 서울서는 이런 개울물을 보지 \\n못하기나 한 듯이.\\n벌써 며칠째 소녀는 , 학교에서 돌아오는 길에 물장난이었다 . 그런데 , 어제까지 개울 기슭에\\n서 하더니 , 오늘은 징검다리 한가운데 앉아서 하고 있다.\\n소년은 개울둑에 앉아 버렸다 . 소녀가 비키기를 기다리자는 것이다 .\\n요행 지나가는 사람이 있어, 소녀가 길을 비켜 주었다 .\\n다음 날은 좀 늦게 개울가로 나왔다 .\\n이 날은 소녀가 징검다리 한가운데 앉아 세수를 하고 있었다 . 분홍 스웨터 소매를 걷어올\\n린 목덜미가 마냥 희었다 .\\n한참 세수를 하고 나더니 , 이번에는 물 속을 빤히 들여다 본다. 얼굴이라도 비추어 보는 \\n것이리라 . 갑자기 물을 움켜 낸다. 고기 새끼라도 지나가는 듯.\\n소녀는 소년이 개울둑에 앉아 있는 걸 아는지 모르는지 그냥 날쌔게 물만 움켜 낸다. 그러\\n나, 번번이 허탕이다 . 그대로 재미있는 양, 자꾸 물만 움킨다 . 어제처럼 개울을 건너는 사\\n람이 있어야 길을 비킬 모양이다 .\\n그러다가 소녀가 물 속에서 무엇을 하나 집어 낸다. 하얀 조약돌이었다 . 그리고는 벌떡 일\\n어나 팔짝팔짝 징검다리를 뛰어 건너간다 .\\n다 건너가더니만 홱 이리로 돌아서며 ,\\n“이 바보.”\\n조약돌이 날아왔다 .\\n소년은 저도 모르게 벌떡 일어섰다 .\\n단발 머리를 나풀거리며 소녀가 막 달린다 . 갈밭 사잇길로 들어섰다 . 뒤에는 청량한 가을 \\n햇살 아래 빛나는 갈꽃뿐 .\\n이제 저쯤 갈밭머리로 소녀가 나타나리라 . 꽤 오랜 시간이 지났다고 생각됐다 . 그런데도 \\n소녀는 나타나지 않는다 . 발돋움을 했다. 그러고도 상당한 시간이 지났다고 생각됐다 .\\n저 쪽 갈밭머리에 갈꽃이 한 옴큼 움직였다 . 소녀가 갈꽃을 안고 있었다 . 그리고 , 이제는 \\n천천한 걸음이었다 . 유난히 맑은 가을 햇살이 소녀의 갈꽃머리에서 반짝거렸다 . 소녀 아닌 \\n갈꽃이 들길을 걸어가는 것만 같았다 .\\n소년은 이 갈꽃이 아주 뵈지 않게 되기까지 그대로 서 있었다 . 문득, 소녀가 던지 조약돌\\n을 내려다보았다 . 물기가 걷혀 있었다 . 소년은 조약돌을 집어 주머니에 넣었다 .\\n다음 날부터 좀더 늦게 개울가로 나왔다 . 소녀의 그림자가 뵈지 않았다 . 다행이었다 .\\n그러나 , 이상한 일이었다 . 소녀의 그림자가 뵈지 않는 날이 계속될수록 소년의 가슴 한 구\\n석에는 어딘가 허전함이 자리 잡는 것이었다 . 주머니 속 조약돌을 주무르는 버릇이 생겼\\n다.\\n그러한 어떤 날, 소년은 전에 소녀가 앉아 물장난을 하던 징검다리 한가운데에 앉아 보았\\n다. 물 속에 손을 잠갔다 . 세수를 하였다 . 물 속을 들여다보았다 . 검게 탄 얼굴이 그대로 \\n비치었다 . 싫었다 .\\nHuman: 소설 끝에서 소녀는 어떠한 결말을 맞이한거야?\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain > chain:LLMChain > llm:ChatOpenAI] [4.80s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"해당 부분에는 소설의 결말에 대한 정보가 포함되어 있지 않습니다.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"해당 부분에는 소설의 결말에 대한 정보가 포함되어 있지 않습니다.\",\n",
            "            \"response_metadata\": {\n",
            "              \"token_usage\": {\n",
            "                \"completion_tokens\": 19,\n",
            "                \"prompt_tokens\": 790,\n",
            "                \"total_tokens\": 809\n",
            "              },\n",
            "              \"model_name\": \"gpt-4o\",\n",
            "              \"system_fingerprint\": \"fp_400f27fa1f\",\n",
            "              \"finish_reason\": \"stop\",\n",
            "              \"logprobs\": null\n",
            "            },\n",
            "            \"type\": \"ai\",\n",
            "            \"id\": \"run-a7532ae2-2eec-4137-a9c6-7abe5f074158-0\",\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 19,\n",
            "      \"prompt_tokens\": 790,\n",
            "      \"total_tokens\": 809\n",
            "    },\n",
            "    \"model_name\": \"gpt-4o\",\n",
            "    \"system_fingerprint\": \"fp_400f27fa1f\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain > chain:LLMChain > llm:ChatOpenAI] [4.80s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"해당 부분에서는 소녀의 결말에 대한 직접적인 언급은 없습니다. 다만, 소녀네가 이사 간다는 내용이 반복적으로 언급되고 있습니다. \\n\\n\\\"어른들의 말이, 내일 소녀네가 양평읍으로 이사 간다는 것이었다 . 거기 가서는 조그마한 가겟방을 보게 되리라는 것이었다 .\\\"\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"해당 부분에서는 소녀의 결말에 대한 직접적인 언급은 없습니다. 다만, 소녀네가 이사 간다는 내용이 반복적으로 언급되고 있습니다. \\n\\n\\\"어른들의 말이, 내일 소녀네가 양평읍으로 이사 간다는 것이었다 . 거기 가서는 조그마한 가겟방을 보게 되리라는 것이었다 .\\\"\",\n",
            "            \"response_metadata\": {\n",
            "              \"token_usage\": {\n",
            "                \"completion_tokens\": 85,\n",
            "                \"prompt_tokens\": 1023,\n",
            "                \"total_tokens\": 1108\n",
            "              },\n",
            "              \"model_name\": \"gpt-4o\",\n",
            "              \"system_fingerprint\": \"fp_400f27fa1f\",\n",
            "              \"finish_reason\": \"stop\",\n",
            "              \"logprobs\": null\n",
            "            },\n",
            "            \"type\": \"ai\",\n",
            "            \"id\": \"run-14296936-8808-4a4f-b4bb-3bc56dae1420-0\",\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 85,\n",
            "      \"prompt_tokens\": 1023,\n",
            "      \"total_tokens\": 1108\n",
            "    },\n",
            "    \"model_name\": \"gpt-4o\",\n",
            "    \"system_fingerprint\": \"fp_400f27fa1f\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain > chain:LLMChain > llm:ChatOpenAI] [4.80s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"주어진 텍스트에는 소설의 결말에 대한 정보가 포함되어 있지 않습니다.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"주어진 텍스트에는 소설의 결말에 대한 정보가 포함되어 있지 않습니다.\",\n",
            "            \"response_metadata\": {\n",
            "              \"token_usage\": {\n",
            "                \"completion_tokens\": 21,\n",
            "                \"prompt_tokens\": 960,\n",
            "                \"total_tokens\": 981\n",
            "              },\n",
            "              \"model_name\": \"gpt-4o\",\n",
            "              \"system_fingerprint\": \"fp_c4e5b6fa31\",\n",
            "              \"finish_reason\": \"stop\",\n",
            "              \"logprobs\": null\n",
            "            },\n",
            "            \"type\": \"ai\",\n",
            "            \"id\": \"run-1d20bd8a-d2a9-473c-88c8-46a5a85cc131-0\",\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 21,\n",
            "      \"prompt_tokens\": 960,\n",
            "      \"total_tokens\": 981\n",
            "    },\n",
            "    \"model_name\": \"gpt-4o\",\n",
            "    \"system_fingerprint\": \"fp_c4e5b6fa31\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain > chain:LLMChain] [4.81s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"outputs\": [\n",
            "    {\n",
            "      \"text\": \"해당 부분에는 소설의 결말에 대한 정보가 포함되어 있지 않습니다.\"\n",
            "    },\n",
            "    {\n",
            "      \"text\": \"해당 부분에서는 소녀의 결말에 대한 직접적인 언급은 없습니다. 다만, 소녀네가 이사 간다는 내용이 반복적으로 언급되고 있습니다. \\n\\n\\\"어른들의 말이, 내일 소녀네가 양평읍으로 이사 간다는 것이었다 . 거기 가서는 조그마한 가겟방을 보게 되리라는 것이었다 .\\\"\"\n",
            "    },\n",
            "    {\n",
            "      \"text\": \"주어진 텍스트에는 소설의 결말에 대한 정보가 포함되어 있지 않습니다.\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain > chain:LLMChain] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"question\": \"소설 끝에서 소녀는 어떠한 결말을 맞이한거야?\",\n",
            "  \"summaries\": \"해당 부분에는 소설의 결말에 대한 정보가 포함되어 있지 않습니다.\\n\\n해당 부분에서는 소녀의 결말에 대한 직접적인 언급은 없습니다. 다만, 소녀네가 이사 간다는 내용이 반복적으로 언급되고 있습니다. \\n\\n\\\"어른들의 말이, 내일 소녀네가 양평읍으로 이사 간다는 것이었다 . 거기 가서는 조그마한 가겟방을 보게 되리라는 것이었다 .\\\"\\n\\n주어진 텍스트에는 소설의 결말에 대한 정보가 포함되어 있지 않습니다.\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: Given the following extracted parts of a long document and a question, create a final answer. \\nIf you don't know the answer, just say that you don't know. Don't try to make up an answer.\\n______________________\\n해당 부분에는 소설의 결말에 대한 정보가 포함되어 있지 않습니다.\\n\\n해당 부분에서는 소녀의 결말에 대한 직접적인 언급은 없습니다. 다만, 소녀네가 이사 간다는 내용이 반복적으로 언급되고 있습니다. \\n\\n\\\"어른들의 말이, 내일 소녀네가 양평읍으로 이사 간다는 것이었다 . 거기 가서는 조그마한 가겟방을 보게 되리라는 것이었다 .\\\"\\n\\n주어진 텍스트에는 소설의 결말에 대한 정보가 포함되어 있지 않습니다.\\nHuman: 소설 끝에서 소녀는 어떠한 결말을 맞이한거야?\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain > chain:LLMChain > llm:ChatOpenAI] [989ms] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"주어진 텍스트에는 소설의 결말에 대한 정보가 포함되어 있지 않습니다. 따라서 소녀가 어떠한 결말을 맞이했는지 알 수 없습니다.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"주어진 텍스트에는 소설의 결말에 대한 정보가 포함되어 있지 않습니다. 따라서 소녀가 어떠한 결말을 맞이했는지 알 수 없습니다.\",\n",
            "            \"response_metadata\": {\n",
            "              \"token_usage\": {\n",
            "                \"completion_tokens\": 40,\n",
            "                \"prompt_tokens\": 200,\n",
            "                \"total_tokens\": 240\n",
            "              },\n",
            "              \"model_name\": \"gpt-4o\",\n",
            "              \"system_fingerprint\": \"fp_c4e5b6fa31\",\n",
            "              \"finish_reason\": \"stop\",\n",
            "              \"logprobs\": null\n",
            "            },\n",
            "            \"type\": \"ai\",\n",
            "            \"id\": \"run-2429adeb-f751-4eb6-a459-2e32f7e86a34-0\",\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 40,\n",
            "      \"prompt_tokens\": 200,\n",
            "      \"total_tokens\": 240\n",
            "    },\n",
            "    \"model_name\": \"gpt-4o\",\n",
            "    \"system_fingerprint\": \"fp_c4e5b6fa31\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain > chain:LLMChain] [995ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"text\": \"주어진 텍스트에는 소설의 결말에 대한 정보가 포함되어 있지 않습니다. 따라서 소녀가 어떠한 결말을 맞이했는지 알 수 없습니다.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:MapReduceDocumentsChain] [5.81s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output_text\": \"주어진 텍스트에는 소설의 결말에 대한 정보가 포함되어 있지 않습니다. 따라서 소녀가 어떠한 결말을 맞이했는지 알 수 없습니다.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA] [5.94s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"result\": \"주어진 텍스트에는 소설의 결말에 대한 정보가 포함되어 있지 않습니다. 따라서 소녀가 어떠한 결말을 맞이했는지 알 수 없습니다.\"\n",
            "}\n",
            "{'query': '소설 끝에서 소녀는 어떠한 결말을 맞이한거야?', 'result': '주어진 텍스트에는 소설의 결말에 대한 정보가 포함되어 있지 않습니다. 따라서 소녀가 어떠한 결말을 맞이했는지 알 수 없습니다.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LCEL(LangChain Expression Language) 버전1\n",
        "# FAISS 벡터스토어 COSINE_DISTANCE 사용\n",
        "# rlm/rag-prompt 프롬프트 사용\n",
        "from operator import itemgetter\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_community.vectorstores.utils import DistanceStrategy\n",
        "from langchain import hub\n",
        "\n",
        "embedding_model = OpenAIEmbeddings()\n",
        "loader = PyPDFLoader(\"소나기 - 황순원.pdf\")\n",
        "docs = loader.load()\n",
        "\n",
        "vectorstore = FAISS.from_documents(\n",
        "    docs,\n",
        "    embedding = embedding_model,\n",
        "    distance_strategy = DistanceStrategy.COSINE\n",
        ")\n",
        "print(f\"{vectorstore.distance_strategy}\\n\")\n",
        "\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")  # langchainhub에서 검증된 prompt를 가져옴.\n",
        "\n",
        "model = ChatOpenAI(model_name='gpt-4o-mini', temperature=0)\n",
        "\n",
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "#print(chain.invoke(\"소녀는 왜 이사를 오게 되었는가?\"))\n",
        "#print(chain.invoke(\"소녀는 소년을 어떻게 생각하고 있는가?\"))\n",
        "#print(chain.invoke(input=\"소설 끝에서 소녀는 어떠한 결말을 맞이한거야?\", config={'callbacks': [ConsoleCallbackHandler()]}))\n",
        "print(chain.invoke(input=\"소설 끝에서 소녀는 어떠한 결말을 맞이한거야? 제시된 context에서 근거를 찾아 설명해줘\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKaxyGQEVb_W",
        "outputId": "4955ba58-6970-4c75-c084-b56decacf9b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "소설 \"소나기\"에서 소녀는 이사 가기 전에 아픈 상태로 남겨지며, 결국 소년과의 이별을 맞이합니다. 소년은 소녀가 이사 간다는 사실에 슬픔을 느끼고, 소녀의 아픔과 이사에 대한 안타까움을 깊이 생각하게 됩니다. 소녀의 결말은 이사와 함께 소년과의 소중한 추억을 남기고, 그들의 관계가 끝나는 것으로 해석됩니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LCEL(LangChain Expression Language) 버전2\n",
        "# FAISS 벡터스토어 EUCLIDEAN_DISTANCE 사용\n",
        "# Prompt를 직접 설계하는 방법\n",
        "from operator import itemgetter\n",
        "\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.callbacks.tracers import ConsoleCallbackHandler\n",
        "\n",
        "loader = PyPDFLoader(\"소나기 - 황순원.pdf\")\n",
        "docs = loader.load()\n",
        "vectorstore = FAISS.from_documents(docs, embedding=OpenAIEmbeddings())\n",
        "print(f\"{vectorstore.distance_strategy}\\n\")\n",
        "\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "model = ChatOpenAI(model_name='gpt-4o', temperature=0)\n",
        "\n",
        "# LCEL에서 chain_type='map_reduce'로 지정하는 방법 아직 못찾아 냄.\n",
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "#print(chain.invoke(\"이 소설에서 주인공의 이름은?\"))\n",
        "#print(chain.invoke(\"소녀가 대추를 딴 이유는?\"))\n",
        "\n",
        "# 'gpt-4o-mini' 와 'gpt-4o' 의 추론 능력의 차이를 확인할 수 있는 질문\n",
        "print(chain.invoke(\"소설 끝에서 소녀가 어떠한 결말을 맞이한거야? 제시된 context에서 근거를 찾아 설명해줘\"))\n",
        "#chain.invoke(input=\"소설 끝에서 소녀가 어떠한 결말을 맞이한거야? 제시된 context에서 근거를 찾아 설명해줘\", config={'callbacks': [ConsoleCallbackHandler()]})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XyYL7R3cgQo",
        "outputId": "fadf6f4d-f044-4920-b45c-114938e95435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EUCLIDEAN_DISTANCE\n",
            "\n",
            "소설의 끝에서 소녀는 죽음을 맞이합니다. 제시된 문맥에서 이를 확인할 수 있는 근거는 다음과 같습니다:\n",
            "\n",
            "1. **아버지의 대화**:\n",
            "   - \"윤 초시 댁도 말이 아니야, 그 많던 전답을 다 팔아 버리고, 대대로 살아오던 집마저 남의 손에 넘기더니, 또 악상까지 당하는걸 보면…….\"\n",
            "   - 여기서 \"악상\"은 자식이 부모보다 먼저 죽는 것을 의미합니다. 따라서 윤 초시 댁에서 자식이 죽었다는 것을 알 수 있습니다.\n",
            "\n",
            "2. **어머니의 대화**:\n",
            "   - \"증손(曾孫)이라곤 계집애 그 애 하나뿐이었지요?\"\n",
            "   - \"그렇지, 사내 애 둘 있던 건 어려서 잃어버리고 …….\"\n",
            "   - \"어쩌면 그렇게 자식복이 없을까.\"\n",
            "   - 이 대화에서 소녀가 윤 초시의 증손녀임을 확인할 수 있습니다.\n",
            "\n",
            "3. **소녀의 마지막 말**:\n",
            "   - \"글쎄, 죽기 전에 이런 말을 했다지 않아? 자기가 죽거든 자기 입던 옷을 꼭 그대로 입혀서 묻어 달라고 …….\"\n",
            "   - 소녀가 죽기 전에 자신의 옷을 그대로 입혀서 묻어 달라고 말했다는 내용은 소녀가 죽음을 맞이했음을 명확히 보여줍니다.\n",
            "\n",
            "따라서, 소설의 끝에서 소녀는 병으로 인해 죽음을 맞이한 것으로 결말이 맺어집니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **[LangChain]　5. Agent**"
      ],
      "metadata": {
        "id": "uTNxCKs_PEkw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agent의 작동원리 ReAct 개념 예제"
      ],
      "metadata": {
        "id": "Xh1CFmL1bCN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "langchain.verbose = True\n",
        "\n",
        "import pprint\n",
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor, create_react_agent, load_tools\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "tools = load_tools([\"terminal\"], allow_dangerous_tools=True)\n",
        "\n",
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "pprint.pp(prompt.template, indent=4, width=100)  # <=\n",
        "\n",
        "agent = create_react_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "result = agent_executor.invoke({\"input\": \"sample_data 디렉터리에 있는 파일 목록을 알려줘\"})\n",
        "print(result[\"output\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SymzTLXPMSr",
        "outputId": "0e9f49bf-bd04-4a19-bd86-29e00c96afb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Answer the following questions as best you can. You have access to the following tools:\\n'\n",
            " '\\n'\n",
            " '{tools}\\n'\n",
            " '\\n'\n",
            " 'Use the following format:\\n'\n",
            " '\\n'\n",
            " 'Question: the input question you must answer\\n'\n",
            " 'Thought: you should always think about what to do\\n'\n",
            " 'Action: the action to take, should be one of [{tool_names}]\\n'\n",
            " 'Action Input: the input to the action\\n'\n",
            " 'Observation: the result of the action\\n'\n",
            " '... (this Thought/Action/Action Input/Observation can repeat N times)\\n'\n",
            " 'Thought: I now know the final answer\\n'\n",
            " 'Final Answer: the final answer to the original input question\\n'\n",
            " '\\n'\n",
            " 'Begin!\\n'\n",
            " '\\n'\n",
            " 'Question: {input}\\n'\n",
            " 'Thought:{agent_scratchpad}')\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to check the contents of the \"sample_data\" directory to list the files it contains. I'll use the terminal to do this.\n",
            "\n",
            "Action: terminal  \n",
            "Action Input: ls sample_data  \u001b[0mExecuting command:\n",
            " ls sample_data\n",
            "\u001b[36;1m\u001b[1;3manscombe.json\n",
            "california_housing_test.csv\n",
            "california_housing_train.csv\n",
            "mnist_test.csv\n",
            "mnist_train_small.csv\n",
            "README.md\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_community/tools/shell/tool.py:32: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mI now know the final answer, which is the list of files in the \"sample_data\" directory.  \n",
            "Final Answer: The files in the \"sample_data\" directory are: anscombe.json, california_housing_test.csv, california_housing_train.csv, mnist_test.csv, mnist_train_small.csv, README.md.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The files in the \"sample_data\" directory are: anscombe.json, california_housing_test.csv, california_housing_train.csv, mnist_test.csv, mnist_train_small.csv, README.md.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**사용자 정의 Tool 예시 #2**"
      ],
      "metadata": {
        "id": "rhNvh3X0TgqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import Tool\n",
        "from langchain.agents import AgentExecutor, create_react_agent, load_tools\n",
        "\n",
        "def Komifoma_func(param):\n",
        "        return \"박정진\"\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "tools = [\n",
        "    Tool.from_function(\n",
        "        func=Komifoma_func,\n",
        "        name=\"Komifoma_Answer\",\n",
        "        description=\"Komifoma World에 대한 모든 질문에 대한 답\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "\n",
        "agent = create_react_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "result = agent_executor.invoke({\"input\": \"Komifoma를 누가 만들었나요?\"})\n",
        "result = agent_executor.invoke({\"input\": \"Komifoma를 누가 끝장냈나요?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiUkI4ZOQfd8",
        "outputId": "46b7f8f9-618a-4b17-823b-a5820b763373"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to find out who created Komifoma. \n",
            "Action: Komifoma_Answer\n",
            "Action Input: \"Komifoma를 누가 만들었나요?\"\u001b[0m\u001b[36;1m\u001b[1;3m박정진\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.  \n",
            "Final Answer: Komifoma는 박정진에 의해 만들어졌습니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to find out who ended Komifoma. \n",
            "Action: Komifoma_Answer\n",
            "Action Input: \"Komifoma를 누가 끝장냈나요?\"\u001b[0m\u001b[36;1m\u001b[1;3m박정진\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.  \n",
            "Final Answer: 박정진\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**사용자 정의 Tool 예시 #2**"
      ],
      "metadata": {
        "id": "9CWEfQg-TXwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.tools import Tool\n",
        "from langchain.pydantic_v1 import BaseModel, Field\n",
        "from langchain.tools import BaseTool, StructuredTool, tool\n",
        "from langchain.callbacks.manager import (\n",
        "    AsyncCallbackManagerForToolRun,\n",
        "    CallbackManagerForToolRun,\n",
        ")\n",
        "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
        "\n",
        "class WeddingInput(BaseModel):\n",
        "    a: int = Field(description=\"first number\")\n",
        "    b: int = Field(description=\"second number\")\n",
        "\n",
        "def concat(a: int, b: int) -> int:\n",
        "    \"\"\"두 수의 결혼\"\"\"\n",
        "    return f\"{a}{b}\"\n",
        "\n",
        "\n",
        "calculator = StructuredTool.from_function(\n",
        "    func=concat,\n",
        "    name=\"ConCat\",\n",
        "    description=\"두 수의 결혼 결과\",\n",
        "    args_schema=WeddingInput,\n",
        "    return_direct=True,\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "tools = [calculator]\n",
        "\n",
        "print(calculator.name)\n",
        "print(calculator.description)\n",
        "print(calculator.args)\n",
        "\n",
        "agent = create_openai_functions_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "result = agent_executor.invoke({\"input\": \"12와 23이 결혼하면?\"})\n",
        "#result = agent_executor.invoke({\"input\": \"LINE JAPAN의 소유주는?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O379NM-uXiji",
        "outputId": "3fd3509a-c494-47e1-d401-792f1aa2e5a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConCat\n",
            "두 수의 결혼 결과\n",
            "{'a': {'title': 'A', 'description': 'first number', 'type': 'integer'}, 'b': {'title': 'B', 'description': 'second number', 'type': 'integer'}}\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `ConCat` with `{'a': 12, 'b': 23}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m1223\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**사용자 정의 Tool 예시 #3**"
      ],
      "metadata": {
        "id": "IA-hewncYhEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain import LLMChain\n",
        "\n",
        "summarize_template = \"\"\"아래의 글을 결론만 한 마디로 요약해 주세요.\n",
        "\n",
        "{input}\n",
        "\"\"\"\n",
        "summarize_prompt = PromptTemplate(\n",
        "   input_variables=[\"input\"],\n",
        "   template=summarize_template,\n",
        ")\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "summarize_chain = LLMChain(llm=chat, prompt=summarize_prompt)\n",
        "\n",
        "tools = [\n",
        "    Tool.from_function(\n",
        "        func=summarize_chain.run,\n",
        "        name=\"Summarizer\",\n",
        "        description=\"Text summarizer\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "agent = create_react_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "text = \"\"\"다음을 요약해 주세요.\n",
        "\n",
        "안녕하세요! 저는 ChatGPT라고 불리는 AI 언어 모델입니다. OpenAI가 개발한 GPT-3.5 아키텍처를 기반으로 합니다. 저는 자연어 이해와 생성을 전문으로 하며, 다양한 주제에 대한 질문에 답하거나, 대화를 나누는 것을 잘합니다.\n",
        "제 트레이닝 데이터는 2021년 9월까지의 정보를 기반으로 하기 때문에, 그 이후의 사건에 대해서는 지식이 없습니다. 하지만, 가능한 한 도움을 드리기 위해 노력할 것입니다.\n",
        "질문이나 대화, 정보 공유 등, 어떤 도움이든 편하게 말씀해 주세요! 잘 부탁드립니다.\"\"\"\n",
        "\n",
        "result = agent_executor.invoke({\"input\": text})\n",
        "print(result)"
      ],
      "metadata": {
        "id": "mHAuBWqBYU17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# openai_functions_agent\n",
        "from langchain.agents import load_tools\n",
        "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "tools = load_tools([\"ddg-search\"])\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "\n",
        "agent = create_openai_functions_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "result = agent_executor.invoke({\"input\": \"서울과 부산의 날씨를 알려줘\"})\n",
        "print(result[\"output\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsaaimTO4LDT",
        "outputId": "7ad84d8a-876f-43bf-e067-6084acef3782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `duckduckgo_search` with `{'query': '서울 날씨'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mToday's weather forecast for Seoul by the hour. 전국날씨. 기상청 바다예보 데이터가 제공됩니다. 해역별 마커에 표기되는 파고 정보는 현재 시점 기준입니다. 국내 날씨는 기상청, 해외 날씨는 아큐웨더・웨더뉴스・웨더채널 중 1개 제공사의 데이터가 제공됩니다. 국내 날씨는 기상청의 초단기실황, 초단기 ... 서울 (Seoul) ☀ 10일 기간 일기예보, 기상 정보, 웹카메라 화면, 일출 및 일몰, 지역의 풍속 및 강수량 Ventusky: 지도상 일기예보 Premium 날씨 문자 및 기상 조건의 예측: 조금 비 바람: 산들 바람 , 남쪽의 , 속도 3 초당 미터 돌풍: 11 초당 미터 상대 습도: 93% 흐림: 100% 기압: 1001 고전력 증폭기 강수량: 0,4 밀리미터 가시성: 18% 오늘 한낮에 서울 27도, 대전 32도 예상됩니다. 내일과 모레는 비가 잠시 소강상태에 들겠지만 곳곳으로 소나기가 내릴 전망입니다. ... 날씨 기사 ...\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `duckduckgo_search` with `{'query': '부산 날씨'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m부산cc 날씨 컨트리클럽 주간일기예보를 알아보겠습니다. 현재 컨트리클럽 주변의 날씨 상황과 함께 실시간으로 반영되는 날씨 정보를 확인할 수 있으며, 주간 일별날씨예보와 비, 바람, 돌풍, 풍향, 눈 등의 세부적인 기상변화를 확인할 수 있습니다. Wednesday 31 July. 29° / 26°. 0.2 mm. 7 m/s. Open hourly forecast. Updated 10:45. Forecast as PDF Forecast as SVG. Weather forecast for Busan for the next 10 days. [날씨] 부산 내일도 온화해요…내일 아침까지 안개 주의 ... 뉴스7(부산) 온화한 날씨가 이어지고 있습니다. 내일도 마찬가지로 추위로 인한 불편함은 없겠습니다. 아침 기온 부산은 3도 안팎으로, 오늘과 비슷하게 시작하겠고요. [날씨] '부산 호우예비특보' 내일도 비…'슈퍼 블루문' 언제 뜨나? 입력 2023.08.31 (19:45) ... 부산 낮 최고기온 27도 선 예상되고요. 풍랑특보가 내려진 먼바다에선 물결이 최고 5미터까지 매우 높게 일겠습니다. 부산지역은 정체전선의 영향으로 내일(3일) 오후3시까지 돌풍과 함께 천둥.번개를 동반한 강하고 많은 비가 내리는 곳이 있겠습니다. 오늘(2일) 저녁6시부터 9시까지는 소강상태를 보이겠습니다. 내일(3일)까지 부산 예상 강수량은 10~50mm로, 많은 곳은 60mm 이상 되는 곳도 있겠습니다.\u001b[0m\u001b[32;1m\u001b[1;3m서울과 부산의 현재 날씨는 다음과 같습니다:\n",
            "\n",
            "### 서울\n",
            "- **기온**: 오늘 한낮에 27도\n",
            "- **날씨**: 흐림\n",
            "- **기타**: 내일과 모레는 비가 잠시 소강상태에 들겠지만 곳곳으로 소나기가 내릴 전망입니다.\n",
            "\n",
            "### 부산\n",
            "- **기온**: 낮 최고기온 27도\n",
            "- **날씨**: 온화한 날씨가 이어지고 있으며, 내일도 비슷한 기온이 예상됩니다.\n",
            "- **기타**: 정체전선의 영향으로 내일 오후 3시까지 돌풍과 함께 천둥, 번개를 동반한 강하고 많은 비가 내릴 수 있습니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "서울과 부산의 현재 날씨는 다음과 같습니다:\n",
            "\n",
            "### 서울\n",
            "- **기온**: 오늘 한낮에 27도\n",
            "- **날씨**: 흐림\n",
            "- **기타**: 내일과 모레는 비가 잠시 소강상태에 들겠지만 곳곳으로 소나기가 내릴 전망입니다.\n",
            "\n",
            "### 부산\n",
            "- **기온**: 낮 최고기온 27도\n",
            "- **날씨**: 온화한 날씨가 이어지고 있으며, 내일도 비슷한 기온이 예상됩니다.\n",
            "- **기타**: 정체전선의 영향으로 내일 오후 3시까지 돌풍과 함께 천둥, 번개를 동반한 강하고 많은 비가 내릴 수 있습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# openai_tools_agent\n",
        "# agent의 동작 단계를 줄여서 속도 빠름 (LangSmith로 확인)\n",
        "from langchain.agents import load_tools\n",
        "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "tools = load_tools([\"ddg-search\"])\n",
        "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
        "\n",
        "agent = create_openai_tools_agent(llm, tools, prompt)  # <=\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "result = agent_executor.invoke({\"input\": \"서울과 부산의 날씨를 알려줘\"})\n",
        "print(result[\"output\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eidrscupYoPC",
        "outputId": "61479fd4-57f4-4eea-9c4a-4b36a599222f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `duckduckgo_search` with `{'query': 'Seoul weather'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mGet the current and forecast weather for Seoul, South Korea, including temperature, precipitation, wind, pressure, humidity, and more. See radar, satellite, and astronomy data for Seoul and nearby stations. Weather Today Weather Hourly 14 Day Forecast Yesterday/Past Weather Climate (Averages) Now. 70 °F. Clear. Feels Like: 70 °F Forecast: 74 / 64 °F Wind: 5 mph ↑ from West. Location: Seoul / Kimp'O International Airport. Current Time: Jun 7, 2024 at 9:51:33 pm. Seoul. Seoul Weather Forecast. Providing a local hourly Seoul weather forecast of rain, sun, wind, humidity and temperature. The Long-range 12 day forecast also includes detail for Seoul weather today. Live weather reports from Seoul weather stations and weather warnings that include risk of thunder, high UV index and forecast gales. Seoul features a Humid continental, severe dry winter, hot summer (Köppen classification: Dwa), with an average annual temperature of 13.89ºC (57.0ºF), which is about 0.29% higher than the national average for South Korea. Seoul - Weather forecast from Theweather.com. Weather conditions with updates on temperature, humidity, wind speed, snow, pressure, etc. for Seoul, South Korea New York New York State 86\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `duckduckgo_search` with `{'query': 'Busan weather'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mBusan Weather Forecasts. Weather Underground provides local & long-range weather forecasts, weatherreports, maps & tropical weather conditions for the Busan area. Be prepared with the most accurate 10-day forecast for Busan, South Korea with highs, lows, chance of precipitation from The Weather Channel and Weather.com Today's and tonight's Busan, South Korea weather forecast, weather conditions and Doppler radar from The Weather Channel and Weather.com South Korea. Busan. Busan Weather Forecast. Providing a local hourly Busan weather forecast of rain, sun, wind, humidity and temperature. The Long-range 12 day forecast also includes detail for Busan weather today. Live weather reports from Busan weather stations and weather warnings that include risk of thunder, high UV index and forecast gales. Today, in Busan, the weather will be cloudy. The temperature will vary between a maximum of 30°C (86°F) and a minimum of 26°C (78.8°F). The feels-like temperature will vary between the lowest temperature of 30°C (86°F) and the highest temperature of 36°C (96.8°F). The warmest part of the day will be from 13h to 15h.\u001b[0m\u001b[32;1m\u001b[1;3m### 서울 날씨\n",
            "- **현재 날씨**: 맑음\n",
            "- **현재 온도**: 약 21°C (70°F)\n",
            "- **체감 온도**: 약 21°C (70°F)\n",
            "- **최고 온도**: 23°C (74°F)\n",
            "- **최저 온도**: 18°C (64°F)\n",
            "- **풍속**: 서쪽에서 8km/h (5 mph)\n",
            "\n",
            "### 부산 날씨\n",
            "- **현재 날씨**: 흐림\n",
            "- **현재 온도**: 약 30°C (86°F)\n",
            "- **최저 온도**: 26°C (78.8°F)\n",
            "- **체감 온도**: 30°C (86°F)에서 36°C (96.8°F) 사이\n",
            "- **가장 더운 시간대**: 오후 1시에서 3시 사이\n",
            "\n",
            "서울은 맑고 부산은 흐린 날씨를 보이고 있습니다. 부산은 특히 체감 온도가 높아 더운 날씨를 예상할 수 있습니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "### 서울 날씨\n",
            "- **현재 날씨**: 맑음\n",
            "- **현재 온도**: 약 21°C (70°F)\n",
            "- **체감 온도**: 약 21°C (70°F)\n",
            "- **최고 온도**: 23°C (74°F)\n",
            "- **최저 온도**: 18°C (64°F)\n",
            "- **풍속**: 서쪽에서 8km/h (5 mph)\n",
            "\n",
            "### 부산 날씨\n",
            "- **현재 날씨**: 흐림\n",
            "- **현재 온도**: 약 30°C (86°F)\n",
            "- **최저 온도**: 26°C (78.8°F)\n",
            "- **체감 온도**: 30°C (86°F)에서 36°C (96.8°F) 사이\n",
            "- **가장 더운 시간대**: 오후 1시에서 3시 사이\n",
            "\n",
            "서울은 맑고 부산은 흐린 날씨를 보이고 있습니다. 부산은 특히 체감 온도가 높아 더운 날씨를 예상할 수 있습니다.\n"
          ]
        }
      ]
    }
  ]
}